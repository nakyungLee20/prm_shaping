{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leena/anaconda3/envs/prm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:24<00:00,  6.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    GenerationConfig,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizerBase,\n",
    "    BitsAndBytesConfig,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from fractions import Fraction\n",
    "from decimal import Decimal, InvalidOperation\n",
    "from typing import Optional, Sequence, Tuple, List\n",
    "import pprint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-Math-7B-Instruct\"  # \"mistralai/Mathstral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Optional, Tuple, Dict, Union, Iterable\n",
    "import torch\n",
    "\n",
    "def build_chat_messages(question: str,tokenizer,dataset: str, shots: Optional[List[tuple[str, str, str]]] = None,) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are an **expert mathematical‑reasoning assistant**.\\n\\n\"\n",
    "        \"## Format rules\\n\"\n",
    "        \"1. Begin *every* reasoning line with the exact prefix `Step k:` where `k = 1, 2, …`. No other prefix is allowed.\\n\"\n",
    "        \"2. Show *all* intermediate calculations using standard symbols (×, ÷, ±, √).\\n\"\n",
    "        \"3. Conclude with **one** line of the form `Answer: <final numeric result>` and **stop immediately** - no explanations, no closing remarks.\\n\"\n",
    "        \"4. Each step must be concise *yet mathematically rigorous*.\\n\"\n",
    "        \"5. Avoid markdown bullet lists or narrative words such as ‘First’,  ‘Next’, ‘Finally’.\\n\\n\"\n",
    "        \"Follow these rules exactly - evaluations are case- and format‑sensitive.\\n\"\n",
    "        \"Respond *only* in the specified format.\"\n",
    "    )\n",
    "    default_shots: List[tuple[str, str, str]] = [\n",
    "        (\n",
    "            \"gsm8k, math\",\n",
    "            \"Problem: What is the next number in the sequence 2, 4, 8, 16?\",\n",
    "            \"Step 1: Identify the pattern – each term is multiplied by 2.\\n\"\n",
    "            \"Step 2: 16 × 2 = 32\\n\"\n",
    "            \"Answer: 32\",\n",
    "        ),\n",
    "        (\n",
    "            \"gsm8k, math\",\n",
    "            \"Problem: Solve for x: 3x + 7 = 22\",\n",
    "            \"Step 1: Subtract 7 from both sides: 3x = 15\\n\"\n",
    "            \"Step 2: Divide by 3: x = 5\\n\"\n",
    "            \"Answer: 5\",\n",
    "        ),\n",
    "        (\n",
    "            \"olympiad, omni\",\n",
    "            \"Problem: Determine whether v₁ = [1,2] and v₂ = [3,6] are linearly independent.\",\n",
    "            \"Step 1: Observe v₂ = 3 · v₁, so v₂ is a scalar multiple of v₁.\\n\"\n",
    "            \"Step 2: Therefore the vectors are linearly dependent.\\n\"\n",
    "            \"Answer: Dependent\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    if shots is None:\n",
    "        shots = default_shots\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for tag, q, a in shots:\n",
    "        if dataset.lower() in tag.lower():\n",
    "            messages.append({\"role\": \"user\", \"content\": q})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": a})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Problem: {question}\"})\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, add_generation_prompt=True, tokenize=False\n",
    "    )\n",
    "\n",
    "# class StepParser:\n",
    "#     \"\"\"Extract reasoning steps from raw LLM output – robust to messy formats.\"\"\"\n",
    "#     _STEP_RE      = re.compile(r\"^\\s*Step\\s*(\\d+)\\s*[:\\-]\", re.I)\n",
    "#     _ENUM_RE      = re.compile(r\"^\\s*(\\d+)[.)]\\s+\")\n",
    "#     _NARRATIVE_RE = re.compile(r\"^\\s*(First|Second|Third|Fourth|Fifth|Next|Then|After that|Therefore|However|Since|Thus|Finally|Lastly)\\b[,:]?\", re.I)\n",
    "\n",
    "#     def _split(self, text: str) -> List[str]:\n",
    "#         lines = text.splitlines()\n",
    "#         blocks: List[str] = []\n",
    "#         buf: List[str] = []\n",
    "\n",
    "#         def flush():\n",
    "#             if buf:\n",
    "#                 blocks.append(\" \".join(buf).strip())\n",
    "#                 buf.clear()\n",
    "\n",
    "#         for ln in lines:\n",
    "#             if any(p.match(ln) for p in (self._STEP_RE, self._ENUM_RE, self._NARRATIVE_RE)):\n",
    "#                 flush()\n",
    "#             buf.append(ln.strip())\n",
    "#         flush()\n",
    "#         return [b for b in blocks if b]\n",
    "\n",
    "#     # public method ------------------------------------------------------\n",
    "#     def parse(self, text: str) -> List[str]:\n",
    "#         steps = self._split(text)\n",
    "#         if len(steps) >= 2:\n",
    "#             return steps\n",
    "#         # first fallback: coarse split on blank lines (\\n\\n)\n",
    "#         paras = re.split(r\"\\n\\s*\\n\", text)\n",
    "#         steps = [p.strip() for p in paras if p.strip()]\n",
    "#         if len(steps) >= 2:\n",
    "#             return steps\n",
    "#         # second fallback: line‑by‑line\n",
    "#         return [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "class StepParser:\n",
    "    # 1) \"Step n:\" / \"Step One:\" / \"Step IV‑\" …\n",
    "    _STEP_RE = re.compile(\n",
    "        r\"^\\s*Step\\s*(?:\\d+|[IVXLCDM]+|One|Two|Three|Four|Five|Six|Seven|Eight|Nine|Ten)\\b\\s*[:\\-.]\",\n",
    "        re.I,)\n",
    "    # 2) 1. / 1) / 1‑   OR  I. / II) / III‑\n",
    "    _ENUM_RE = re.compile(r\"^\\s*(?:\\d+|[IVXLCDM]+)[.)-]\\s+\", re.I)\n",
    "    # 3) Narrative adverbs\n",
    "    _NARRATIVE_RE = re.compile(\n",
    "        r\"^\\s*(First|Firstly|Second|Secondly|Third|Thirdly|Fourth|Fifth|Sixth|Seventh|Eighth|Ninth|Tenth|Next|Then|After that|Therefore|However|Since|Thus|Finally|Lastly|In conclusion)\\b[,:]?\",\n",
    "        re.I,)\n",
    "    # 4) Bullet mark (dash/asterisk/dot) + space\n",
    "    _BULLET_RE = re.compile(r\"^\\s*[-*•]\\s+\")\n",
    "    _JUNK_RE = re.compile(r\"^(?:<\\|endoftext\\|>\\s*)+\")\n",
    "    _DELIMITERS = (_STEP_RE, _ENUM_RE, _NARRATIVE_RE, _BULLET_RE)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    @classmethod\n",
    "    def _is_delimiter(cls, line: str) -> bool:\n",
    "        return any(r.match(line) for r in cls._DELIMITERS)\n",
    "    \n",
    "    @classmethod\n",
    "    def _clean_line(cls, line: str) -> str:\n",
    "        \"\"\"Strip junk tokens and surrounding whitespace from *line*.\"\"\"\n",
    "        return cls._JUNK_RE.sub(\"\", line).strip()\n",
    "\n",
    "    @classmethod\n",
    "    def _split(cls, text: str) -> List[str]:\n",
    "        \"\"\"Split *text* into tentative step blocks using delimiter lines.\"\"\"\n",
    "        blocks: List[str] = []\n",
    "        buf: List[str] = []\n",
    "\n",
    "        def flush():\n",
    "            if buf:\n",
    "                blocks.append(\" \".join(buf).strip())\n",
    "                buf.clear()\n",
    "\n",
    "        for raw_ln in text.splitlines():\n",
    "            ln = cls._clean_line(raw_ln)\n",
    "            if cls._is_delimiter(ln):\n",
    "                flush()\n",
    "            buf.append(ln)\n",
    "        flush()\n",
    "        return [b for b in blocks if b]\n",
    "    \n",
    "    @classmethod\n",
    "    def _strip_leading_marker(cls, text: str) -> str:\n",
    "        \"\"\"Remove one leading delimiter + junk tokens from *text* if present.\"\"\"\n",
    "        txt = cls._clean_line(text)\n",
    "        for p in cls._DELIMITERS:\n",
    "            m = p.match(txt)\n",
    "            if m:\n",
    "                return txt[m.end():].lstrip()\n",
    "        return txt\n",
    "\n",
    "    @classmethod\n",
    "    def parse(cls, text: str) -> List[str]:\n",
    "        \"\"\"Return **raw** steps (leading markers still present).\"\"\"\n",
    "        steps = cls._split(text)\n",
    "        if len(steps) >= 2:\n",
    "            return steps\n",
    "        # Fallback ①: blank‑line split\n",
    "        sans_junk = \"\\n\".join(cls._clean_line(l) for l in text.splitlines())\n",
    "        paras = re.split(r\"\\n\\s*\\n\", sans_junk)\n",
    "        steps = [p.strip() for p in paras if p.strip()]\n",
    "        if len(steps) >= 2:\n",
    "            return steps\n",
    "        # Fallback ②: line‑by‑line (already cleaned)\n",
    "        return [ln for ln in sans_junk.splitlines() if ln.strip()]\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_clean(cls, obj: Union[str, Iterable[str]]) -> List[str]:\n",
    "        \"\"\"Return list of *clean* steps (leading markers removed).\"\"\"\n",
    "        if isinstance(obj, str):\n",
    "            raw_steps = cls.parse(obj)\n",
    "        else:\n",
    "            raw_steps = list(obj)\n",
    "        return [cls._strip_leading_marker(s) for s in raw_steps]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re, ast\n",
    "from fractions import Fraction\n",
    "from decimal import Decimal, InvalidOperation\n",
    "from typing import Optional, Sequence, Tuple, List\n",
    "import pandas as pd\n",
    "\n",
    "class AnswerExtractor:\n",
    "    \"\"\"\n",
    "    Robust gold/ pred-answer extractor for GSM8K · Math · Omni · OlympiadBench.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.answer_keywords = (\n",
    "            \"answer\", \"final answer\", \"therefore\", \"result\",\n",
    "            \"the final answer is\"\n",
    "        )\n",
    "        self.number_patterns = [\n",
    "            r'(\\d+\\.\\d+)', r'(\\d+\\/\\d+)', r'(\\d+)',\n",
    "            r'(\\d+\\+\\d+)', r'(\\d+\\-\\d+)', r'(\\d+\\*\\d+)'\n",
    "        ]\n",
    "\n",
    "    def extract_gold_answer(self, text: str,dataset: str | None = None) -> Optional[str]:\n",
    "        if text is None:\n",
    "            return None\n",
    "        if isinstance(text, (list, tuple)):\n",
    "            return self._flatten_and_clean(text)\n",
    "\n",
    "        ds  = (dataset or \"\").lower()\n",
    "        txt = str(text).strip()\n",
    "        # 1) GSM8K  #### 정답\n",
    "        if ds == \"gsm8k\" or re.search(r\"\\n####\\s*[^\\n]+\", txt):\n",
    "            m = re.search(r\"\\n####\\s*([^\\n]+)\", txt)\n",
    "            return self._strip(m.group(1)) if m else None\n",
    "        # 2) OlympiadBench  [ '$…$', '$…$' ]\n",
    "        if ds ==\"olympiad\" or ( txt.startswith('[') and txt.endswith(']')):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(txt)\n",
    "                if isinstance(parsed, (list, tuple)):\n",
    "                    return self._flatten_and_clean(parsed)\n",
    "                return self._strip(str(parsed))\n",
    "            except (SyntaxError, ValueError):\n",
    "                return self._strip(txt)\n",
    "        # 3) Omni  (그대로)\n",
    "        if ds == \"omni\":\n",
    "            return self._strip(txt)\n",
    "        # 4) Math 또는 그 밖 → 공통 pred-extract 로 처리\n",
    "        return self.extract_pred_answer(txt)\n",
    "\n",
    "    def extract_pred_answer(self, text: str) -> Optional[str]:\n",
    "        # 1) 마지막 balanced \\boxed{…} / \\fbox{…}\n",
    "        boxed = self._extract_last_boxed(text)\n",
    "        if boxed:\n",
    "            return self._strip(boxed)\n",
    "        # 2) Answer: … / Therefore: … (다음 줄까지 포함)\n",
    "        ans_line = self._extract_answer_line(text)\n",
    "        if ans_line:\n",
    "            return self._strip(ans_line)\n",
    "        # 3) 마지막 줄에서 inline LaTeX\n",
    "        last_expr = self._extract_last_latex(text)\n",
    "        if last_expr:\n",
    "            return self._strip(last_expr)\n",
    "        # 4) 마지막 숫자/수식\n",
    "        num = self._extract_last_number(text)\n",
    "        return self._strip(num) if num else None\n",
    "\n",
    "    # ─────────────────── Internals ───────────────────\n",
    "    def _extract_last_boxed(self, text: str) -> Optional[str]:\n",
    "        start_pat = re.compile(r'(\\\\boxed|\\\\fbox)\\s*\\{')\n",
    "        starts = list(start_pat.finditer(text))\n",
    "        if not starts:\n",
    "            return None\n",
    "        i = starts[-1].end()\n",
    "        depth = 1\n",
    "        while i < len(text) and depth:\n",
    "            ch = text[i]\n",
    "            if ch == '{':\n",
    "                depth += 1\n",
    "            elif ch == '}':\n",
    "                depth -= 1\n",
    "            i += 1\n",
    "        return text[starts[-1].end(): i-1].strip() if depth == 0 else None\n",
    "\n",
    "    def _extract_answer_line(self, text: str) -> Optional[str]:\n",
    "        lines = text.splitlines()\n",
    "        for i, ln in enumerate(lines):\n",
    "            low = ln.lower()\n",
    "            if any(k in low for k in self.answer_keywords):\n",
    "                # 콜론 뒤 같은 줄?\n",
    "                m = re.search(r'[:\\-]\\s*(.+)$', ln)\n",
    "                if m and m.group(1).strip():\n",
    "                    return m.group(1).strip()\n",
    "                # 아니면 다음 비어있지 않은 줄\n",
    "                j = i + 1\n",
    "                while j < len(lines) and not lines[j].strip():\n",
    "                    j += 1\n",
    "                if j < len(lines):\n",
    "                    return lines[j].strip()\n",
    "        return None\n",
    "\n",
    "    def _extract_last_latex(self, text: str) -> Optional[str]:\n",
    "        for ln in reversed(text.splitlines()):\n",
    "            ln = ln.strip()\n",
    "            if not ln:\n",
    "                continue\n",
    "            # $ … $  \\[…\\]  \\(…\\)\n",
    "            m = re.findall(r'\\$(.*?)\\$|\\\\\\((.*?)\\\\\\)|\\\\\\[(.*?)\\\\\\]', ln)\n",
    "            if m:\n",
    "                return [seg for seg in m[-1] if seg][0]\n",
    "            # bare \\frac  \\sqrt …\n",
    "            m2 = re.search(r'(\\\\[a-zA-Z]+(?:\\{[^{}]+\\})+)', ln)\n",
    "            if m2:\n",
    "                return m2.group(1)\n",
    "            break\n",
    "        return None\n",
    "\n",
    "    def _extract_last_number(self, text: str) -> Optional[str]:\n",
    "        for ln in reversed(text.splitlines()):\n",
    "            ln = ln.strip()\n",
    "            if not ln:\n",
    "                continue\n",
    "            for pat in self.number_patterns:\n",
    "                m = re.findall(pat, ln)\n",
    "                if m:\n",
    "                    return m[-1]\n",
    "        return None\n",
    "\n",
    "    def _strip(self, s: str | None) -> str | None:\n",
    "        if s is None:\n",
    "            return None\n",
    "        s = s.strip()\n",
    "        s = re.sub(r'^\\$+\\s*', '', s)            # leading $\n",
    "        s = re.sub(r'\\s*\\$+$', '', s)            # trailing $\n",
    "        s = re.sub(r'^\\\\\\(|\\\\\\)$', '', s)        # \\( … \\)\n",
    "        s = re.sub(r'^\\\\\\[|\\\\\\]$', '', s)        # \\[ … \\]\n",
    "        s = s.replace('\\\\\\\\', '\\\\')              # \\\\ → \\\n",
    "        return s.strip(\" ,;:\")\n",
    "\n",
    "    def _flatten_and_clean(self, seq: List[str]) -> str:\n",
    "        return \", \".join(self._strip(x) for x in seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = AnswerExtractor()\n",
    "test_cases = [\n",
    "    # GSM8K\n",
    "    (\"gsm8k\", \"Prince fought bravely.\\n#### 30 \", \"30\"),\n",
    "    (\"gsm8k\", \"Problem...\\n#### $-1$ \\n\", \"-1\"),\n",
    "    # Math boxed\n",
    "    (\"math\", r\"Compute ... thus we have \\boxed{\\frac{8t}{3}}.\", r\"\\frac{8t}{3}\"),\n",
    "    # Math with Answer:\n",
    "    (\"math\", \"We conclude.\\nAnswer: 52\", \"52\"),\n",
    "    # Math inline latex\n",
    "    (\"math\", \"Finally the value is $2\\\\sqrt{3}$\", r\"2\\sqrt{3}\"),\n",
    "    # Math only number at end\n",
    "    (\"math\", \"Hence the result is\\n40\", \"40\"),\n",
    "    # Omni simple\n",
    "    (\"omni\", \"2500\", \"2500\"),\n",
    "    # Omni latex\n",
    "    (\"omni\", r\"\\frac{5}{6}\", r\"\\frac{5}{6}\"),\n",
    "    # Olympiad list\n",
    "    (\"olympiad\", \"['$2.0 \\\\times 10^{6}$', '$6.5 \\\\times 10^{8}$']\", r\"2.0 \\times 10^{6}, 6.5 \\times 10^{8}\"),\n",
    "    # Olympiad single\n",
    "    (\"olympiad\", \"['$7$']\", \"7\"),\n",
    "    # Raw python list\n",
    "    (\"\", [\"42\"], \"42\"),\n",
    "    # Pred only latex\n",
    "    (\"pred\", r\"$\\frac{1}{27}$\", r\"\\frac{1}{27}\"),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for ds, text, expected in test_cases:\n",
    "    if ds == \"pred\":\n",
    "        got = extractor.extract_pred_answer(text)\n",
    "    else:\n",
    "        got = extractor.extract_gold_answer(text, ds if ds else None)\n",
    "    rows.append({\"dataset\": ds, \"input\": text, \"expected\": expected, \"extracted\": got, \"pass\": expected == got})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"AnswerExtractor test results\")\n",
    "print(\"=\" * 80)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary: {df['pass'].sum()}/{len(df)} tests passed ({df['pass'].mean()*100:.1f}%)\")\n",
    "\n",
    "failed = df[~df['pass']]\n",
    "if not failed.empty:\n",
    "    print(\"\\nFailed Cases:\")\n",
    "    print(failed[['dataset', 'input', 'expected', 'extracted']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answer_matcher import MathAnswerScorer\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "scorer = MathAnswerScorer()\n",
    "tests = [\n",
    "    (\"1/2\", r\"\\frac{1}{2}\", True),\n",
    "    (\"0.5\", \"1/2\", True),\n",
    "    (\"50%\", \"0.5\", True),\n",
    "    (r\"2,3\", r\"3,2\", True),\n",
    "    (r\"(0,1]\", r\"(0,1]\", True),\n",
    "    (r\"{1,2,3}\", r\"{3,2,1}\", True),\n",
    "    (\"30°\", \"30 °\", True),\n",
    "    (\"x+1=0\", \"x=-1\", True),\n",
    "    (r\"\\sin(\\pi/4)\", r\"\\frac{\\sqrt{2}}{2}\", True),\n",
    "    (r\"\\begin{pmatrix}1&2\\\\3&4\\end{pmatrix}\", \"{{1,2},{3,4}}\", True),\n",
    "    (\"3+4i\", \"3+4j\", True),\n",
    "    (\"1000 m\", \"1 km\", True),\n",
    "    (\"Answer: C\", \"C\", True),\n",
    "    (\"Yes\", \"yes.\", True),\n",
    "    (\"1/2\", \"2/3\", False),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for i,(pred,gold,expect) in enumerate(tests,1):\n",
    "    try:\n",
    "        res = scorer.answers_match(pred,gold)\n",
    "    except Exception as e:\n",
    "        res = f\"Error: {e}\"\n",
    "    results.append({\"#\":i,\"pred\":pred,\"gold\":gold,\"expected\":expect,\"result\":res,\"pass\":res==expect})\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Math Answer Scorer Tests\")\n",
    "print(\"=\" * 80)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_tests = len(df)\n",
    "passed_tests = df['pass'].sum()\n",
    "print(f\"\\nSummary: {passed_tests}/{total_tests} tests passed ({passed_tests/total_tests*100:.1f}%)\")\n",
    "\n",
    "failed_tests = df[~df['pass']]\n",
    "if not failed_tests.empty:\n",
    "    print(\"\\nFailed Tests:\")\n",
    "    print(failed_tests[['#', 'pred', 'gold', 'expected', 'result']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English configs found: ['OE_MM_maths_en_COMP', 'OE_MM_physics_en_COMP', 'OE_TO_maths_en_COMP', 'OE_TO_physics_en_COMP', 'TP_MM_maths_en_COMP', 'TP_MM_physics_en_COMP', 'TP_TO_maths_en_COMP', 'TP_TO_physics_en_COMP']\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names, load_dataset, concatenate_datasets\n",
    "\n",
    "gsm8k = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")  # train/test, ['question', 'answer']\n",
    "math = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=\"test\")    # train/test/fewshot, ['problem', 'level', 'type', 'solution']\n",
    "omni = load_dataset(\"KbsdJames/Omni-MATH\", split = \"test\")  # only test (4428), ['domain', 'difficulty', 'problem', 'solution', 'answer', 'source']\n",
    "def load_olympiadbench_english(split: str = \"train\"):\n",
    "    all_cfgs = get_dataset_config_names(\"Hothan/OlympiadBench\")\n",
    "    en_cfgs = [cfg for cfg in all_cfgs if \"_en_\" in cfg or cfg.endswith(\"_en\")]\n",
    "    print(f\"English configs found: {en_cfgs}\")\n",
    "    ds_list = []\n",
    "    for cfg in en_cfgs:\n",
    "        try:\n",
    "            ds = load_dataset(\"Hothan/OlympiadBench\", cfg, split=split)\n",
    "            ds_list.append(ds)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  {cfg} 로드 실패: {e}\")\n",
    "    if len(ds_list) == 0:\n",
    "        raise ValueError(\"Fail to load English configs\")\n",
    "    full_ds = concatenate_datasets(ds_list)\n",
    "    return full_ds\n",
    "\n",
    "olymbench = load_olympiadbench_english(\"train\") # ['id', 'question', 'solution', 'final_answer', 'context', 'image_1', 'image_2', 'image_3', 'image_4', 'image_5', 'image_6', 'image_7', 'image_8', 'image_9', 'modality', 'difficulty', 'is_multiple_answer', 'unit', 'answer_type', 'error', 'question_type', 'subfield', 'subject', 'language'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The largest possible $C$ is $C=\\\\frac{1}{2}$.\\n\\nFor $0<C \\\\leqslant \\\\frac{1}{2}$, Turbo can simply choose an arbitrary point $P$ (different from its starting point) to avoid. When Turbo is at an arbitrary point $A$ different from $P$, the two arcs $A P$ have total length 1; therefore, the larger of the two the arcs (or either arc in case $A$ is diametrically opposite to $P$ ) must have length $\\\\geqslant \\\\frac{1}{2}$. By always choosing this larger arc (or either arc in case $A$ is diametrically opposite to $P$ ), Turbo will manage to avoid the point $P$ forever.\\n\\nFor $C>\\\\frac{1}{2}$, we write $C=\\\\frac{1}{2}+a$ with $a>0$, and we choose the sequence\\n\\n$$\\n\\\\frac{1}{2}, \\\\quad \\\\frac{1+a}{2}, \\\\quad \\\\frac{1}{2}, \\\\quad \\\\frac{1+a}{2}, \\\\quad \\\\frac{1}{2}, \\\\ldots\\n$$\\n\\nIn other words, $c_{i}=\\\\frac{1}{2}$ if $i$ is odd and $c_{i}=\\\\frac{1+a}{2}<C$ when $i$ is even. We claim Turbo must eventually visit all points on the circle. This is clear when it crawls in the same direction two times in a row; after all, we have $c_{i}+c_{i+1}>1$ for all $i$. Therefore, we are left with the case that Turbo alternates crawling clockwise and crawling counterclockwise. If it, without loss of generality, starts by going clockwise, then it will always crawl a distance $\\\\frac{1}{2}$ clockwise followed by a distance $\\\\frac{1+a}{2}$ counterclockwise. The net effect is that it crawls a distance $\\\\frac{a}{2}$ counterclockwise. Because $\\\\frac{a}{2}$ is positive, there exists a positive integer $N$ such that $\\\\frac{a}{2} \\\\cdot N>1$. After $2 N$ crawls, Turbo will have crawled a distance $\\\\frac{a}{2}$ counterclockwise $N$ times, therefore having covered a total distance of $\\\\frac{a}{2} \\\\cdot N>1$, meaning that it must have crawled over all points on the circle.\\n\\nNote: Every sequence of the form $c_{i}=x$ if $i$ is odd, and $c_{i}=y$ if $i$ is even, where $0<x, y<C$, such that $x+y \\\\geqslant 1$, and $x \\\\neq y$ satisfies the conditions with the same argument. There might be even more possible examples.',\n",
       " \"To show that $C\\\\le \\\\frac12$\\n\\nWe consider the following related problem:\\n\\nWe assume instead that the snail Chet is moving left and right on the real line. Find the size $M$ of the smallest (closed) interval, that we cannot force Chet out of, using a sequence of real numbers $d_{i}$ with $0<d_{i}<1$ for all $i$.\\n\\nThen $C=1 / M$. Indeed if for every sequence $c_{1}, c_{2}, \\\\ldots$, with $c_{i}<C$ there exists a point that Turbo can avoid, then the circle can be cut open at the avoided point and mapped to an interval of size $M$ such that Chet can stay inside this interval for any sequence of the from $c_{1} / C, c_{2} / C, \\\\ldots$, see Figure 5 . However, all sequences $d_{1}, d_{2}, \\\\ldots$ with $d_{i}<1$ can be written in this form. Similarly if for every sequence $d_{1}, d_{2}, \\\\ldots$, there exists an interval of length smaller or equal $M$ that we cannot force Chet out of, this projects to a subset of the circle, that we cannot force Turbo out of using any sequence of the form $d_{1} / M, d_{2} / M, \\\\ldots$. These are again exactly all the sequences with elements in $[0, C)$.\\n\\n<img_3381>\\n\\nFigure 5: Chet and Turbo equivalence\\n\\nClaim: $M \\\\geqslant 2$.\\n\\nProof. Suppose not, so $M<2$. Say $M=2-2 \\\\varepsilon$ for some $\\\\varepsilon>0$ and let $[-1+\\\\varepsilon, 1-\\\\varepsilon]$ be a minimal interval, that Chet cannot be forced out of. Then we can force Chet arbitrarily close to $\\\\pm(1-\\\\varepsilon)$. In partiular, we can force Chet out of $\\\\left[-1+\\\\frac{4}{3} \\\\varepsilon, 1-\\\\frac{4}{3} \\\\varepsilon\\\\right]$ by minimality of $M$. This means that there exists a sequence $d_{1}, d_{2}, \\\\ldots$ for which Chet has to leave $\\\\left[-1+\\\\frac{4}{3} \\\\varepsilon, 1-\\\\frac{4}{3} \\\\varepsilon\\\\right]$, which means he ends up either in the interval $\\\\left[-1+\\\\varepsilon,-1+\\\\frac{4}{3} \\\\varepsilon\\\\right)$ or in the interval $\\\\left(1-\\\\frac{4}{3} \\\\varepsilon, 1-\\\\varepsilon\\\\right]$.\\n\\nNow consider the sequence,\\n\\n$$\\nd_{1}, 1-\\\\frac{7}{6} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{7}{6} \\\\varepsilon, d_{2}, 1-\\\\frac{7}{6} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{7}{6} \\\\varepsilon, d_{3}, \\\\ldots\\n$$\\n\\nobtained by adding the sequence $1-\\\\frac{7}{6} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{7}{6} \\\\varepsilon$ in between every two steps. We claim that this sequence forces Chet to leave the larger interval $[-1+\\\\varepsilon, 1-\\\\varepsilon]$. Indeed no two consecutive elements in the sequence $1-\\\\frac{7}{6} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{2}{3} \\\\varepsilon, 1-\\\\frac{7}{6} \\\\varepsilon$ can have the same sign, because the sum of any two consecutive terms is larger than $2-2 \\\\varepsilon$ and Chet would leave the interval $[-1+\\\\varepsilon, 1-\\\\varepsilon]$. It follows that the $\\\\left(1-\\\\frac{7}{6} \\\\varepsilon\\\\right)$ 's and the $\\\\left(1-\\\\frac{2}{3} \\\\varepsilon\\\\right)$ 's cancel out, so the position after $d_{k}$ is the same as before $d_{k+1}$. Hence, the positions after each $d_{k}$ remain the same as in the original sequence. Thus, Chet is also forced to the boundary in the new sequence.\\n\\nIf Chet is outside the interval $\\\\left[-1+\\\\frac{4}{3} \\\\varepsilon, 1-\\\\frac{4}{3} \\\\varepsilon\\\\right]$, then Chet has to move $1-\\\\frac{7}{6} \\\\varepsilon$ towards 0 , and ends in $\\\\left[-\\\\frac{1}{6} \\\\varepsilon, \\\\frac{1}{6} \\\\varepsilon\\\\right]$. Chet then has to move by $1-\\\\frac{2}{3} \\\\varepsilon$, which means that he has to leave the interval $[-1+\\\\varepsilon, 1-\\\\varepsilon]$. Indeed the absolute value of the final position is at least $1-\\\\frac{5}{6} \\\\varepsilon$. This contradicts the assumption, that we cannot force Chet out of $[-1+\\\\varepsilon, 1-\\\\varepsilon]$. Hence $M \\\\geqslant 2$ as needed.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olymbench[0]['solution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Let \\\\(a_i = 10000 + i\\\\epsilon\\\\) for \\\\(i = 0, 1, \\\\ldots, 19\\\\) and some small \\\\(\\\\epsilon > 0\\\\)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = omni[3]['solution'].split(\". \")\n",
    "print(len(steps))\n",
    "steps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== GSM8K ======\n",
      "Problem: Grandma Jones baked 5 apple pies for the fireman's luncheon.  She cut each pie into 8 pieces and set the five pies out on the buffet table for the guests to serve themselves.  At the end of the evening, after the guests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining.  How many pieces were taken by the guests?\n",
      "Gold Answer: To start the evening, there were 5 pies, each with 8 pieces, which is 5*8=<<5*8=40>>40 pieces of pie.\n",
      "If only 14 remained, then 40-14=<<40-14=26>>26 pieces of pie had been taken by guests.\n",
      "#### 26 \n",
      "\n",
      "====== Math ======\n",
      "Problem: Find the sum of all values of $x$ such that $|x-1| = 7$.\n",
      "Gold Answer: We must have either $x-1 = 7$ or $x-1=-7$.  If $x-1=7$, we have $x=8$, and if $x-1 = -7$, we have $x= -6$, so the sum of the possible values of $x$ is $8+(-6) = \\boxed{2}$. \n",
      "\n",
      "====== Omni ======\n",
      "Problem: Call a sequence of positive integers $\\{a_n\\}$ good if for any distinct positive integers $m,n$, one has \n",
      "$$\\gcd(m,n) \\mid a_m^2 + a_n^2 \\text{ and } \\gcd(a_m,a_n) \\mid m^2 + n^2.$$\n",
      "Call a positive integer $a$ to be $k$-good if there exists a good sequence such that $a_k = a$. Does there exists a $k$ such that there are exactly $2019$ $k$-good positive integers?\n",
      "Solution: \n",
      "To determine if there exists a \\( k \\) such that there are exactly 2019 \\( k \\)-good positive integers, we first need to understand the properties of a good sequence \\(\\{a_n\\}\\). A sequence is defined as good if for any distinct positive integers \\( m \\) and \\( n \\), the following conditions hold:\n",
      "\\[ \\gcd(m, n) \\mid a_m^2 + a_n^2 \\quad \\text{and} \\quad \\gcd(a_m, a_n) \\mid m^2 + n^2. \\]\n",
      "\n",
      "We describe all good sequences as those satisfying:\n",
      "\\[ n \\mid a_n^2 \\quad \\text{and} \\quad a_n \\mid n^2 \\]\n",
      "for every integer \\( n \\). This implies that for any prime \\( p \\) and integer \\( n \\), the only constraint is:\n",
      "\\[ \\frac{\\nu_p(n)}{2} \\le \\nu_p(a_n) \\le 2\\nu_p(n). \\]\n",
      "\n",
      "To verify this, we consider the following steps:\n",
      "\n",
      "1. For \\( m = 2n \\), \\( m = 3n \\), and \\( n \\), we get:\n",
      "\\[ n \\mid a_n^2 + a_{2n}^2, \\quad a_{2n}^2 + a_{3n}^2, \\quad \\text{and} \\quad a_n^2 + a_{3n}^2. \\]\n",
      "This implies:\n",
      "\\[ n \\mid 2a_n^2. \\]\n",
      "This is almost the left half of the constraint, except for \\( p = 2 \\) where it is off by one.\n",
      "\n",
      "2. To prove the constraint for any prime \\( p \\) and index \\( n \\), we choose \\( m = p^{2\\nu_p(a_n) + \\nu_p(n) + 1} \\). This ensures:\n",
      "\\[ \\nu_p(m) > \\nu_p(n) \\quad \\text{and} \\quad \\nu_p(a_m) > \\frac{\\nu_p(m) - 1}{2} > \\nu_p(a_n). \\]\n",
      "Thus, we have:\n",
      "\\[ \\nu_p(n) = \\nu_p(\\gcd(m, n)) \\le \\nu_p(a_m^2 + a_n^2) = \\nu_p(a_n^2) \\]\n",
      "and\n",
      "\\[ \\nu_p(a_n) \\le \\nu_p(\\gcd(a_m, a_n)) \\le \\nu_p(m^2 + n^2) = \\nu_p(n^2). \\]\n",
      "This confirms the constraint.\n",
      "\n",
      "Finally, we check if there exists a \\( k \\) such that there are exactly 2019 \\( k \\)-good positive integers. For each prime \\( p \\), there are \\( 2\\nu_p(i) - \\left\\lfloor \\frac{\\nu_p(i)}{2} \\right\\rfloor \\) choices for \\( \\nu_p(a_i) \\). It is straightforward to verify that this number is never divisible by 3, so the product of such numbers cannot equal 2019.\n",
      "\n",
      "Therefore, the answer is no. There does not exist a \\( k \\) such that there are exactly 2019 \\( k \\)-good positive integers.\n",
      "\n",
      "The answer is: \\boxed{\\text{no}}.\n",
      "Gold Answer: \\text{no} \n",
      "\n",
      "====== Olympiad ======\n",
      "Problem: In the diagram, $O A=15, O P=9$ and $P B=4$. Determine the equation of the line through $A$ and $B$. Explain how you got your answer.\n",
      "\n",
      "<image_1>\n",
      "Solution: ['Since $O P=9$, then the coordinates of $P$ are $(9,0)$.\\n\\nSince $O P=9$ and $O A=15$, then by the Pythagorean Theorem,\\n\\n$$\\nA P^{2}=O A^{2}-O P^{2}=15^{2}-9^{2}=144\\n$$\\n\\nso $A P=12$.\\n\\nSince $P$ has coordinates $(9,0)$ and $A$ is 12 units directly above $P$, then $A$ has coordinates $(9,12)$.\\n\\nSince $P B=4$, then $B$ has coordinates $(13,0)$.\\n\\nThe line through $A(9,12)$ and $B(13,0)$ has slope $\\\\frac{12-0}{9-13}=-3$ so, using the point-slope form, has equation $y-0=-3(x-13)$ or $y=-3 x+39$.']\n",
      "Gold Answer: ['$y=-3 x+39$']\n"
     ]
    }
   ],
   "source": [
    "idx = 42\n",
    "dataset = \"gsm8k\"\n",
    "\n",
    "# gsm8k\n",
    "gs_question=gsm8k[idx]['question']\n",
    "gs_answer = gsm8k[idx]['answer']\n",
    "print(\"====== GSM8K ======\")\n",
    "print(\"Problem:\", gs_question)\n",
    "print(\"Gold Answer:\", gs_answer, \"\\n\")\n",
    "\n",
    "# math\n",
    "math_question = math[idx]['problem']\n",
    "math_answer = math[idx]['solution']\n",
    "print(\"====== Math ======\")\n",
    "print(\"Problem:\", math_question)\n",
    "print(\"Gold Answer:\", math_answer, \"\\n\")\n",
    "\n",
    "# omni\n",
    "omni_question = omni[idx]['problem']\n",
    "omni_solution = omni[idx]['solution']\n",
    "omni_answer = omni[idx]['answer']\n",
    "print(\"====== Omni ======\")\n",
    "print(\"Problem:\", omni_question)\n",
    "print(\"Solution:\", omni_solution)\n",
    "print(\"Gold Answer:\", omni_answer, \"\\n\")\n",
    "\n",
    "# olympiad\n",
    "olm_question = olymbench[idx]['question']\n",
    "olm_solution = olymbench[idx]['solution']\n",
    "olm_answer = olymbench[idx]['final_answer']\n",
    "print(\"====== Olympiad ======\")\n",
    "print(\"Problem:\", olm_question)\n",
    "print(\"Solution:\", olm_solution)\n",
    "print(\"Gold Answer:\", olm_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence Step 1: Calculate the total number of pie pieces: 5 pies × 8 pieces per pie = 40 pieces\n",
      "Step 2: Determine the number of pieces taken by the guests: 40 pieces - 14 pieces remaining = 26 pieces\n",
      "Answer: 26\n",
      "Pred Ans: 26\n",
      "Gold Ans: 26\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "conv = build_chat_messages(gs_question, tokenizer, \"gsm8k\")\n",
    "inputs = tokenizer(conv, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "gen_kwargs = dict(\n",
    "    max_new_tokens=400,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    do_sample=False, \n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "decoded_full = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "assistant_text = decoded_full.split(\"<|im_start|>assistant\")[-1]\n",
    "assistant_text = assistant_text.replace(\"<|im_end|>\", \"\").strip()\n",
    "print(\"Generated Sequence\", assistant_text)\n",
    "assistant_text = assistant_text.split(\"Answer:\")[-1]\n",
    "\n",
    "gs_pred_ans = extractor.extract_pred_answer(assistant_text)\n",
    "gs_gold_ans = extractor.extract_gold_answer(gs_answer, \"gsm8k\")\n",
    "print(\"Pred Ans:\", gs_pred_ans)\n",
    "print(\"Gold Ans:\", gs_gold_ans)\n",
    "\n",
    "gs_corr = scorer.answers_match(gs_pred_ans, gs_gold_ans)\n",
    "print(gs_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence Step 1: Solve the absolute value equation by considering two cases.\n",
      "Case 1: \\(x - 1 = 7\\)\n",
      "Step 2: Add 1 to both sides: \\(x = 8\\)\n",
      "Case 2: \\(x - 1 = -7\\)\n",
      "Step 3: Add 1 to both sides: \\(x = -6\\)\n",
      "Step 4: Add the solutions: \\(8 + (-6) = 2\\)\n",
      " Answer: 2\n",
      "Pred Ans: 2\n",
      "Gold Ans: 2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "conv = build_chat_messages(math_question, tokenizer, \"math\")\n",
    "inputs = tokenizer(conv, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "gen_kwargs = dict(\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    do_sample=False, \n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "decoded_full = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "assistant_text = decoded_full.split(\"<|im_start|>assistant\")[-1]\n",
    "assistant_text = assistant_text.replace(\"<|im_end|>\", \"\").strip()\n",
    "print(\"Generated Sequence\", assistant_text)\n",
    "assistant_text = assistant_text.split(\"Answer:\")[-1]\n",
    "\n",
    "math_pred_ans = extractor.extract_pred_answer(assistant_text)\n",
    "math_gold_ans = extractor.extract_gold_answer(math_answer, \"math\")\n",
    "print(\"Pred Ans:\", math_pred_ans)\n",
    "print(\"Gold Ans:\", math_gold_ans)\n",
    "\n",
    "math_corr = scorer.answers_match(math_pred_ans, math_gold_ans)\n",
    "print(math_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OmniMath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence To determine if there exists a \\( k \\) such that there are exactly 2019 \\( k \\)-good positive integers, we need to analyze the properties of the good sequence \\(\\{a_n\\}\\).\n",
      "\n",
      "First, let's consider the conditions given for a good sequence:\n",
      "1. For any distinct positive integers \\( m \\) and \\( n \\), \\(\\gcd(m, n) \\mid a_m^2 + a_n^2\\).\n",
      "2. For any distinct positive integers \\( m \\) and \\( n \\), \\(\\gcd(a_m, a_n) \\mid m^2 + n^2\\).\n",
      "\n",
      "We start by examining the simplest case where \\( m = 1 \\) and \\( n = 2 \\). Let \\( a_1 = a \\) and \\( a_2 = b \\). Then the conditions become:\n",
      "1. \\(\\gcd(1, 2) \\mid a^2 + b^2 \\implies 1 \\mid a^2 + b^2\\), which is always true.\n",
      "2. \\(\\gcd(a, b) \\mid 1^2 + 2^2 \\implies \\gcd(a, b) \\mid 5\\).\n",
      "\n",
      "The possible values for \\(\\gcd(a, b)\\) are 1 and 5. This means that \\( a \\) and \\( b \\) must be coprime or both multiples of 5.\n",
      "\n",
      "Next, let's consider the general case. Suppose \\( a_n = c \\) for all \\( n \\). Then for any distinct positive integers \\( m \\) and \\( n \\):\n",
      "1. \\(\\gcd(m, n) \\mid c^2 + c^2 = 2c^2\\).\n",
      "2. \\(\\gcd(c, c) \\mid m^2 + n^2 \\implies c \\mid m^2 + n^2\\).\n",
      "\n",
      "From the second condition, \\( c \\) must be a divisor of \\( m^2 + n^2 \\) for all distinct positive integers \\( m \\) and \\( n \\). The only positive integer that satisfies this condition is \\( c = 1 \\) (since \\( m^2 + n^2 \\) is always greater than 1 for distinct \\( m \\) and \\( n \\), and the only common divisor of all such sums is 1).\n",
      "\n",
      "Therefore, the only possible value for \\( a_n \\) is 1. This means that for any \\( k \\), there is exactly one \\( k \\)-good positive integer, which is 1.\n",
      "\n",
      "Since there is only one \\( k \\)-good positive integer for any \\( k \\), it is impossible to find a \\( k \\) such that there are exactly 2019 \\( k \\)-good positive integers.\n",
      "\n",
      "The final answer is:\n",
      "\\[\n",
      "\\boxed{\\text{No}}\n",
      "\\]\n",
      "Parsed Sequence To determine if there exists a \\( k \\) such that there are exactly 2019 \\( k \\)-good positive integers, we need to analyze the properties of the good sequence \\(\\{a_n\\}\\).\n",
      "\n",
      "First, let's consider the conditions given for a good sequence:\n",
      "1. For any distinct positive integers \\( m \\) and \\( n \\), \\(\\gcd(m, n) \\mid a_m^2 + a_n^2\\).\n",
      "2. For any distinct positive integers \\( m \\) and \\( n \\), \\(\\gcd(a_m, a_n) \\mid m^2 + n^2\\).\n",
      "\n",
      "We start by examining the simplest case where \\( m = 1 \\) and \\( n = 2 \\). Let \\( a_1 = a \\) and \\( a_2 = b \\). Then the conditions become:\n",
      "1. \\(\\gcd(1, 2) \\mid a^2 + b^2 \\implies 1 \\mid a^2 + b^2\\), which is always true.\n",
      "2. \\(\\gcd(a, b) \\mid 1^2 + 2^2 \\implies \\gcd(a, b) \\mid 5\\).\n",
      "\n",
      "The possible values for \\(\\gcd(a, b)\\) are 1 and 5. This means that \\( a \\) and \\( b \\) must be coprime or both multiples of 5.\n",
      "\n",
      "Next, let's consider the general case. Suppose \\( a_n = c \\) for all \\( n \\). Then for any distinct positive integers \\( m \\) and \\( n \\):\n",
      "1. \\(\\gcd(m, n) \\mid c^2 + c^2 = 2c^2\\).\n",
      "2. \\(\\gcd(c, c) \\mid m^2 + n^2 \\implies c \\mid m^2 + n^2\\).\n",
      "\n",
      "From the second condition, \\( c \\) must be a divisor of \\( m^2 + n^2 \\) for all distinct positive integers \\( m \\) and \\( n \\). The only positive integer that satisfies this condition is \\( c = 1 \\) (since \\( m^2 + n^2 \\) is always greater than 1 for distinct \\( m \\) and \\( n \\), and the only common divisor of all such sums is 1).\n",
      "\n",
      "Therefore, the only possible value for \\( a_n \\) is 1. This means that for any \\( k \\), there is exactly one \\( k \\)-good positive integer, which is 1.\n",
      "\n",
      "Since there is only one \\( k \\)-good positive integer for any \\( k \\), it is impossible to find a \\( k \\) such that there are exactly 2019 \\( k \\)-good positive integers.\n",
      "\n",
      "The final answer is:\n",
      "\\[\n",
      "\\boxed{\\text{No}}\n",
      "\\]\n",
      "Pred Ans: \\text{No}\n",
      "Gold Ans: \\text{no}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "conv = build_chat_messages(omni_question, tokenizer, \"omni\")\n",
    "inputs = tokenizer(conv, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "gen_kwargs = dict(\n",
    "    max_new_tokens=1300,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    do_sample=False, \n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "decoded_full = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "assistant_text = decoded_full.split(\"<|im_start|>assistant\")[-1]\n",
    "assistant_text = assistant_text.replace(\"<|im_end|>\", \"\").strip()\n",
    "print(\"Generated Sequence\", assistant_text)\n",
    "assistant_text = assistant_text.split(\"Answer:\")[-1]\n",
    "print(\"Parsed Sequence\", assistant_text)\n",
    "\n",
    "omni_pred_ans = extractor.extract_pred_answer(assistant_text)\n",
    "omni_gold_ans = extractor.extract_gold_answer(omni_answer, \"omni\")\n",
    "print(\"Pred Ans:\", omni_pred_ans)\n",
    "print(\"Gold Ans:\", omni_gold_ans)\n",
    "\n",
    "omni_corr = scorer.answers_match(omni_pred_ans, omni_gold_ans)\n",
    "print(omni_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OlympiadBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence To determine the equation of the line through points \\(A\\) and \\(B\\), we need to find the slope of the line and then use the point-slope form of the equation of a line.\n",
      "\n",
      "First, let's identify the coordinates of points \\(A\\) and \\(B\\). From the diagram, we can see that point \\(O\\) is the origin \\((0,0)\\), point \\(A\\) is \\((15,0)\\), and point \\(B\\) is \\((19,4)\\).\n",
      "\n",
      "Next, we calculate the slope \\(m\\) of the line passing through points \\(A\\) and \\(B\\). The formula for the slope between two points \\((x_1, y_1)\\) and \\((x_2, y_2)\\) is:\n",
      "\\[\n",
      "m = \\frac{y_2 - y_1}{x_2 - x_1}\n",
      "\\]\n",
      "Substituting the coordinates of points \\(A\\) and \\(B\\):\n",
      "\\[\n",
      "m = \\frac{4 - 0}{19 - 15} = \\frac{4}{4} = 1\n",
      "\\]\n",
      "So, the slope of the line is \\(1\\).\n",
      "\n",
      "Now, we use the point-slope form of the equation of a line, which is:\n",
      "\\[\n",
      "y - y_1 = m(x - x_1)\n",
      "\\]\n",
      "We can use point \\(A\\) \\((15,0)\\) and the slope \\(m = 1\\):\n",
      "\\[\n",
      "y - 0 = 1(x - 15)\n",
      "\\]\n",
      "Simplifying this, we get:\n",
      "\\[\n",
      "y = x - 15\n",
      "\\]\n",
      "Therefore, the equation of the line through points \\(A\\) and \\(B\\) is:\n",
      "\\[\n",
      "\\boxed{y = x - 15}\n",
      "\\]\n",
      "Pred Ans: y = x - 15\n",
      "Gold Ans: y=-3 x+39\n",
      "False\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "conv = build_chat_messages(olm_question, tokenizer, \"olympiad\")\n",
    "inputs = tokenizer(conv, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "gen_kwargs = dict(\n",
    "    max_new_tokens=2400,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    do_sample=False, \n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "decoded_full = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "assistant_text = decoded_full.split(\"<|im_start|>assistant\")[-1]\n",
    "assistant_text = assistant_text.replace(\"<|im_end|>\", \"\").strip()\n",
    "print(\"Generated Sequence\", assistant_text)\n",
    "assistant_text = assistant_text.split(\"Answer:\")[-1]\n",
    "\n",
    "olm_pred_ans = extractor.extract_pred_answer(assistant_text)\n",
    "olm_gold_ans = extractor.extract_gold_answer(olm_answer, \"olympiad\")\n",
    "print(\"Pred Ans:\", olm_pred_ans)\n",
    "print(\"Gold Ans:\", olm_gold_ans)\n",
    "\n",
    "olm_corr = scorer.answers_match(olm_pred_ans, olm_gold_ans)\n",
    "print(olm_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIME 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 90/90 [00:00<00:00, 9046.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# aime = load_dataset(\"HuggingFaceH4/aime_2024\", split=\"train\")\n",
    "aime2224 = load_dataset(\"AI-MO/aimo-validation-aime\", split=\"train\") # [id, problem, solution, answer, url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "FIELD_MAP: Dict[str, Tuple[str, str]] = { # dataset name  : (question_field, answer_field)\n",
    "    \"gsm8k\": (\"question\", \"answer\"),\n",
    "    \"math\": (\"problem\", \"solution\"),\n",
    "    \"omni\": (\"problem\", \"answer\"),\n",
    "    \"olympiad\": (\"question\", \"final_answer\"),\n",
    "}\n",
    "\n",
    "def get_loader(ds_name: str, split: str, batch_size: int):\n",
    "    \"\"\"Return torch DataLoader yielding (idx, question, gold_answer).\"\"\"\n",
    "    if ds_name == \"math\":\n",
    "        ds = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=split)\n",
    "    elif ds_name == \"gsm8k\":\n",
    "        ds = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "    elif ds_name == \"omni\":\n",
    "        ds = load_dataset(\"KbsdJames/Omni-MATH\", split=split)\n",
    "    elif ds_name == \"olympiad\":\n",
    "        ds = load_olympiadbench_english(split)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset {ds_name}\")\n",
    "\n",
    "    q_key, a_key = FIELD_MAP[ds_name]\n",
    "    def collate(indices):\n",
    "        items = [ds[i] for i in indices]\n",
    "        idxs = indices\n",
    "        qs = [item[q_key] for item in items]\n",
    "        golds = [item[a_key] for item in items]\n",
    "        return idxs, qs, golds\n",
    "\n",
    "    return DataLoader(range(len(ds)), batch_size=batch_size, shuffle=False, collate_fn=collate), len(ds)\n",
    "\n",
    "def batched_generate(questions: List[str],tokenizer, model, ds_name: str, gen_kwargs: Dict, parser: StepParser,) -> List[str]:\n",
    "    \"\"\"Greedy decode a batch → return raw answer strings (post‑`Answer:`).\"\"\"\n",
    "    prompts = [build_chat_messages(q, tokenizer, ds_name) for q in questions]\n",
    "    tokenized = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**tokenized, **gen_kwargs)\n",
    "    decoded = tokenizer.batch_decode(out, skip_special_tokens=False)\n",
    "    answers: List[str] = []\n",
    "    for full in decoded:\n",
    "        # isolate assistant chunk\n",
    "        part = full.split(\"<|im_start|>assistant\")[-1].replace(\"<|im_end|>\", \"\").strip()\n",
    "        print(\"Original Generation\", part)\n",
    "        steps = parser.parse(part)\n",
    "        cleaned_steps = parser.parse_clean(steps)\n",
    "        print(\"Parsed Steps:\", len(cleaned_steps))\n",
    "        print(cleaned_steps)\n",
    "        try: ans = cleaned_steps[-1].split(\"Answer:\")[-1].strip()\n",
    "        except: ans = part.split(\"Answer:\")[-1].strip()\n",
    "        answers.append(ans)\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English configs found: ['OE_MM_maths_en_COMP', 'OE_MM_physics_en_COMP', 'OE_TO_maths_en_COMP', 'OE_TO_physics_en_COMP', 'TP_MM_maths_en_COMP', 'TP_MM_physics_en_COMP', 'TP_TO_maths_en_COMP', 'TP_TO_physics_en_COMP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "100%|██████████| 1/1 [00:33<00:00, 33.32s/it, acc=50.000%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Generation To determine the largest constant \\( C > 0 \\) such that Turbo can ensure that there is some point on the circle that it will never visit or crawl across, we need to analyze the behavior of Turbo's crawling pattern.\n",
      "\n",
      "First, let's consider the total distance Turbo crawls. If \\( c_i < C \\) for all \\( i \\), then the total distance \\( D \\) Turbo crawls is:\n",
      "\\[\n",
      "D = c_1 + c_2 + c_3 + \\cdots\n",
      "\\]\n",
      "Since each \\( c_i < C \\), we have:\n",
      "\\[\n",
      "D < C + C + C + \\cdots = C \\cdot \\infty = \\infty\n",
      "\\]\n",
      "However, we need to find a specific value of \\( C \\) such that Turbo can ensure there is a point on the circle that it will never visit or crawl across.\n",
      "\n",
      "To do this, let's consider the circumference of the circle, which is 1. If \\( C \\leq \\frac{1}{2} \\), then each \\( c_i < \\frac{1}{2} \\). This means that Turbo's total distance \\( D \\) will always be less than \\( \\frac{1}{2} \\times \\infty = \\infty \\), but more importantly, it will always be less than 1.\n",
      "\n",
      "If \\( D < 1 \\), then Turbo's total distance is less than the circumference of the circle. This means that Turbo can always choose to crawl in such a way that it never completes a full lap around the circle. Specifically, Turbo can always choose to crawl in a way that it never reaches the point where it would complete a full lap and return to its starting point.\n",
      "\n",
      "Therefore, if \\( C \\leq \\frac{1}{2} \\), Turbo can always ensure that there is some point on the circle that it will never visit or crawl across. If \\( C > \\frac{1}{2} \\), then it is possible for Turbo to crawl a total distance greater than 1, which means it could potentially complete a full lap and return to its starting point, and thus it would visit every point on the circle.\n",
      "\n",
      "Thus, the largest constant \\( C \\) such that Turbo can ensure that there is some point on the circle that it will never visit or crawl across is:\n",
      "\\[\n",
      "\\boxed{\\frac{1}{2}}\n",
      "\\]\n",
      "Parsed Steps: 6\n",
      "[\"To determine the largest constant \\\\( C > 0 \\\\) such that Turbo can ensure that there is some point on the circle that it will never visit or crawl across, we need to analyze the behavior of Turbo's crawling pattern.\", \"let's consider the total distance Turbo crawls. If \\\\( c_i < C \\\\) for all \\\\( i \\\\), then the total distance \\\\( D \\\\) Turbo crawls is: \\\\[ D = c_1 + c_2 + c_3 + \\\\cdots \\\\]\", 'each \\\\( c_i < C \\\\), we have: \\\\[ D < C + C + C + \\\\cdots = C \\\\cdot \\\\infty = \\\\infty \\\\]', \"we need to find a specific value of \\\\( C \\\\) such that Turbo can ensure there is a point on the circle that it will never visit or crawl across.  To do this, let's consider the circumference of the circle, which is 1. If \\\\( C \\\\leq \\\\frac{1}{2} \\\\), then each \\\\( c_i < \\\\frac{1}{2} \\\\). This means that Turbo's total distance \\\\( D \\\\) will always be less than \\\\( \\\\frac{1}{2} \\\\times \\\\infty = \\\\infty \\\\), but more importantly, it will always be less than 1.  If \\\\( D < 1 \\\\), then Turbo's total distance is less than the circumference of the circle. This means that Turbo can always choose to crawl in such a way that it never completes a full lap around the circle. Specifically, Turbo can always choose to crawl in a way that it never reaches the point where it would complete a full lap and return to its starting point.\", 'if \\\\( C \\\\leq \\\\frac{1}{2} \\\\), Turbo can always ensure that there is some point on the circle that it will never visit or crawl across. If \\\\( C > \\\\frac{1}{2} \\\\), then it is possible for Turbo to crawl a total distance greater than 1, which means it could potentially complete a full lap and return to its starting point, and thus it would visit every point on the circle.', 'the largest constant \\\\( C \\\\) such that Turbo can ensure that there is some point on the circle that it will never visit or crawl across is: \\\\[ \\\\boxed{\\\\frac{1}{2}} \\\\]']\n",
      "Original Generation <|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Step 1: Since \\(DE\\) is parallel to \\(BF\\), \\(\\angle ADE = \\angle ABF = 41^\\circ\\) and \\(\\angle CDE = \\angle CBF = 59^\\circ\\).\n",
      "Step 2: Since \\(AE = EC\\), \\(\\triangle AEC\\) is isosceles, and \\(\\angle EAC = \\angle ECA\\).\n",
      "Step 3: The sum of the angles in \\(\\triangle AEC\\) is \\(180^\\circ\\), so \\(\\angle EAC + \\angle ECA + \\angle AEC = 180^\\circ\\).\n",
      "Step 4: Since \\(\\angle AEC = 180^\\circ - \\angle ADE - \\angle CDE = 180^\\circ - 41^\\circ - 59^\\circ = 80^\\circ\\), we have \\(\\angle EAC = \\angle ECA = \\frac{180^\\circ - 80^\\circ}{2} = 50^\\circ\\).\n",
      "Step 5: In \\(\\triangle AEF\\), \\(\\angle AEF = \\angle EAC = 50^\\circ\\) and \\(\\angle AFE = \\angle EFB = 41^\\circ\\).\n",
      "Step 6: The sum of the angles in \\(\\triangle AEF\\) is \\(180^\\circ\\), so \\(\\angle EAF = 180^\\circ - \\angle AEF - \\angle AFE = 180^\\circ - 50^\\circ - 41^\\circ = 89^\\circ\\).\n",
      "Step 7: Since \\(\\triangle AEF\\) is a right triangle with \\(\\angle AEF = 50^\\circ\\) and \\(\\angle AFE = 41^\\circ\\), we can use the Law of Sines to find \\(AE\\):\n",
      "\\[\n",
      "\\frac{AE}{\\sin 41^\\circ} = \\frac{EF}{\\sin 89^\\circ} = \\frac{25}{\\cos 1^\\circ} \\approx 25\n",
      "\\]\n",
      "\\[\n",
      "AE = 25 \\sin 41^\\circ \\approx 25 \\cdot 0.6560 = 16.40\n",
      "\\]\n",
      "Step 8: Therefore, the length of \\(AE\\) is \\(\\boxed{16.40}\\).\n",
      "```\n",
      "The final answer is \\(\\boxed{16.40}\\).\n",
      "Parsed Steps: 8\n",
      "['Since \\\\(DE\\\\) is parallel to \\\\(BF\\\\), \\\\(\\\\angle ADE = \\\\angle ABF = 41^\\\\circ\\\\) and \\\\(\\\\angle CDE = \\\\angle CBF = 59^\\\\circ\\\\).', 'Since \\\\(AE = EC\\\\), \\\\(\\\\triangle AEC\\\\) is isosceles, and \\\\(\\\\angle EAC = \\\\angle ECA\\\\).', 'The sum of the angles in \\\\(\\\\triangle AEC\\\\) is \\\\(180^\\\\circ\\\\), so \\\\(\\\\angle EAC + \\\\angle ECA + \\\\angle AEC = 180^\\\\circ\\\\).', 'Since \\\\(\\\\angle AEC = 180^\\\\circ - \\\\angle ADE - \\\\angle CDE = 180^\\\\circ - 41^\\\\circ - 59^\\\\circ = 80^\\\\circ\\\\), we have \\\\(\\\\angle EAC = \\\\angle ECA = \\\\frac{180^\\\\circ - 80^\\\\circ}{2} = 50^\\\\circ\\\\).', 'In \\\\(\\\\triangle AEF\\\\), \\\\(\\\\angle AEF = \\\\angle EAC = 50^\\\\circ\\\\) and \\\\(\\\\angle AFE = \\\\angle EFB = 41^\\\\circ\\\\).', 'The sum of the angles in \\\\(\\\\triangle AEF\\\\) is \\\\(180^\\\\circ\\\\), so \\\\(\\\\angle EAF = 180^\\\\circ - \\\\angle AEF - \\\\angle AFE = 180^\\\\circ - 50^\\\\circ - 41^\\\\circ = 89^\\\\circ\\\\).', 'Since \\\\(\\\\triangle AEF\\\\) is a right triangle with \\\\(\\\\angle AEF = 50^\\\\circ\\\\) and \\\\(\\\\angle AFE = 41^\\\\circ\\\\), we can use the Law of Sines to find \\\\(AE\\\\): \\\\[ \\\\frac{AE}{\\\\sin 41^\\\\circ} = \\\\frac{EF}{\\\\sin 89^\\\\circ} = \\\\frac{25}{\\\\cos 1^\\\\circ} \\\\approx 25 \\\\] \\\\[ AE = 25 \\\\sin 41^\\\\circ \\\\approx 25 \\\\cdot 0.6560 = 16.40 \\\\]', 'Therefore, the length of \\\\(AE\\\\) is \\\\(\\\\boxed{16.40}\\\\). ``` The final answer is \\\\(\\\\boxed{16.40}\\\\).']\n",
      "Parsed Answers: ['\\\\frac{1}{2}', '16.40']\n",
      "Parsed Golds: ['\\\\frac{1}{2}', '79.67']\n",
      "\n",
      "===========================================\n",
      "Dataset       : olympiad\n",
      "Samples seen  : 2\n",
      "Correct       : 1\n",
      "Accuracy      : 50.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "dataset = \"olympiad\"\n",
    "loader, total = get_loader(dataset, \"test\" if dataset != \"olympiad\" else \"train\", 3)\n",
    "max_n = 2\n",
    "\n",
    "extractor = AnswerExtractor()\n",
    "scorer = MathAnswerScorer()\n",
    "parser_obj = StepParser()\n",
    "gen_kwargs = dict(max_new_tokens=2049, temperature=0.2, top_p=0.9, do_sample=False, pad_token_id=tokenizer.eos_token_id) # greedy decoding\n",
    "\n",
    "## Evaluation loop ##\n",
    "correct = 0\n",
    "seen = 0\n",
    "pbar = tqdm(loader, total= math.ceil(max_n / 3))\n",
    "for idxs, qs, golds in pbar:\n",
    "    # limit sample count\n",
    "    if seen >= max_n:\n",
    "        break\n",
    "    # trim overflow inside batch\n",
    "    lim = min(len(qs), max_n - seen)\n",
    "    qs, golds, idxs = qs[:lim], golds[:lim], idxs[:lim]\n",
    "\n",
    "    preds = batched_generate(qs, tokenizer, model, dataset, gen_kwargs, parser_obj)\n",
    "    # extract structured answers\n",
    "    pred_ans = [extractor.extract_pred_answer(p) for p in preds]\n",
    "    gold_ans = [extractor.extract_gold_answer(g, dataset) for g in golds]\n",
    "    print(\"Parsed Answers:\", pred_ans)\n",
    "    print(\"Parsed Golds:\", gold_ans)\n",
    "\n",
    "    batch_corr = [scorer.answers_match(pa, ga) for pa, ga in zip(pred_ans, gold_ans)]\n",
    "    correct += sum(batch_corr)\n",
    "    seen += lim\n",
    "    pbar.set_postfix(acc=f\"{correct/seen:.3%}\")\n",
    "\n",
    "print(\"\\n===========================================\")\n",
    "print(f\"Dataset       : {dataset}\")\n",
    "print(f\"Samples seen  : {seen}\")\n",
    "print(f\"Correct       : {correct}\")\n",
    "print(f\"Accuracy      : {correct/seen:.3%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(scores: List[float], how: str = \"mean\") -> float:\n",
    "    if not scores:\n",
    "        return 0.0\n",
    "    if how == \"mean\":\n",
    "        return float(sum(scores) / len(scores))\n",
    "    if how == \"last\":\n",
    "        return float(scores[-1])\n",
    "    if how == \"sum\":\n",
    "        return float(sum(scores))\n",
    "    if how == \"median\":\n",
    "        s = sorted(scores)\n",
    "        m = len(s) // 2\n",
    "        return float((s[m] if len(s) % 2 else 0.5*(s[m-1] + s[m])))\n",
    "    return float(sum(scores) / len(scores))\n",
    "\n",
    "STEP_RE = re.compile(r\"^(?:step\\s*\\d+\\s*:\\s*)(.*)$\", re.IGNORECASE)\n",
    "ANSWER_LINE_RE = re.compile(r\"^\\s*answer\\s*:\\s*(.*)$\", re.IGNORECASE)\n",
    "BOXED_RE = re.compile(r\"\\\\boxed\\{([^}]+)\\}\")\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are Qwen-Math, a meticulous math tutor. \"\n",
    "    \"Solve problems with clear, numbered steps and give only ONE final answer line.\"\n",
    ")\n",
    "\n",
    "def split_steps(text: str) -> List[str]:\n",
    "    \"\"\"Parse a model completion into a list of steps (strings).\n",
    "    Priority:\n",
    "      1) Existing <extra_0> separators\n",
    "      2) Blank-line separation (\"\\n\\n\")\n",
    "      3) Lines starting with \"Step k:\" markers\n",
    "      4) Fallback: entire reasoning (before the Answer line) as one step\n",
    "    \"\"\"\n",
    "    if \"<extra_0>\" in text:\n",
    "        parts = [p.strip() for p in text.split(\"<extra_0>\") if p.strip()]\n",
    "    else:\n",
    "        # Cut off after the explicit Answer line if present\n",
    "        lines = text.splitlines()\n",
    "        body_lines: List[str] = []\n",
    "        for ln in lines:\n",
    "            if ANSWER_LINE_RE.match(ln):\n",
    "                break\n",
    "            body_lines.append(ln)\n",
    "        body = \"\\n\".join(body_lines)\n",
    "        # 2) try blank line separation\n",
    "        if \"\\n\\n\" in body:\n",
    "            parts = [p.strip() for p in body.split(\"\\n\\n\") if p.strip()]\n",
    "        else:\n",
    "            # 3) try explicit step markers\n",
    "            parts_tmp: List[str] = []\n",
    "            cur: List[str] = []\n",
    "            for ln in body.splitlines():\n",
    "                if STEP_RE.match(ln):\n",
    "                    if cur:\n",
    "                        parts_tmp.append(\" \".join(cur).strip())\n",
    "                        cur = []\n",
    "                    cur.append(STEP_RE.sub(r\"\\\\1\", ln).strip())\n",
    "                else:\n",
    "                    cur.append(ln.strip())\n",
    "            if cur:\n",
    "                parts_tmp.append(\" \".join(cur).strip())\n",
    "            parts = [p for p in parts_tmp if p]\n",
    "    if not parts:\n",
    "        parts = [text.strip()]\n",
    "    return parts\n",
    "\n",
    "def build_user_prompt(question: str) -> str:\n",
    "    header = (\n",
    "        \"Please reason step by step. Follow this EXACT format:\\n\"\n",
    "        \"Step 1: <short reasoning>\\n\"\n",
    "        \"Step 2: <short reasoning>\\n\"\n",
    "        \"...\\n\"\n",
    "        \"Answer: <final numeric answer>\\n\"\n",
    "        \"Constraints:\\n\"\n",
    "        \"- Keep each step concise, one idea per line.\\n\"\n",
    "        \"- Do not include extra explanations after the final Answer line.\\n\"\n",
    "    )\n",
    "    parts = [header]\n",
    "    parts.append(\"Problem: \" + question.strip())\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "def to_chat_prompt(tokenizer, question: str, assistant:str, eval_style: str = \"default\") -> str:\n",
    "    if eval_style == \"qwen_eval\":\n",
    "        user = f\"{question.strip()}\\n\\nPlease reason step by step, and put your final answer within `Answer: \\\\boxed{{}}`.\"\n",
    "    else:\n",
    "        user = build_user_prompt(question)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",   \"content\": user},\n",
    "        {\"role\": \"assistant\", \"content\": assistant.strip()},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# ------------------------------\n",
    "# (A) 토큰/마스크 보조 함수들\n",
    "# ------------------------------\n",
    "def _encode_ids(tokenizer, text: str):\n",
    "    return tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "def _ensure_token_or_subseq(tokenizer, token_text: str):\n",
    "    \"\"\"token_text가 1 토큰이면 (id, [id]), 아니면 (None, [서브시퀀스 ids]) 리턴\"\"\"\n",
    "    ids = _encode_ids(tokenizer, token_text)\n",
    "    if len(ids) == 1:\n",
    "        return ids[0], ids\n",
    "    # vocab 키 존재 시 바로 id\n",
    "    vocab = tokenizer.get_vocab()\n",
    "    if token_text in vocab:\n",
    "        tid = vocab[token_text]\n",
    "        return tid, [tid]\n",
    "    return None, ids  # 다중 토큰인 서브시퀀스\n",
    "\n",
    "def _find_subseq_positions(seq: List[int], subseq: List[int]) -> List[int]:\n",
    "    \"\"\"seq 안에서 subseq가 등장하는 '끝 인덱스' 목록을 리턴\"\"\"\n",
    "    if not subseq:\n",
    "        return []\n",
    "    out = []\n",
    "    n, m = len(seq), len(subseq)\n",
    "    for i in range(n - m + 1):\n",
    "        if seq[i:i+m] == subseq:\n",
    "            out.append(i + m - 1)  # 끝 위치를 True로 잡자(가독성)\n",
    "    return out\n",
    "\n",
    "def _build_mask_from_token_or_subseq(input_ids_1d: torch.Tensor, token_id: Optional[int], subseq: List[int]) -> torch.Tensor:\n",
    "    \"\"\"token_id가 있으면 == 비교, 없으면 subseq 매칭으로 마스크 구성\"\"\"\n",
    "    if token_id is not None:\n",
    "        return (input_ids_1d == token_id)\n",
    "    # subseq 매칭\n",
    "    ids = input_ids_1d.tolist()\n",
    "    hits = _find_subseq_positions(ids, subseq)\n",
    "    mask = torch.zeros_like(input_ids_1d, dtype=torch.bool)\n",
    "    for idx in hits:\n",
    "        mask[idx] = True\n",
    "    return mask\n",
    "\n",
    "def _print_tokens_with_marks(tokenizer, input_ids_1d: torch.Tensor, mask: torch.Tensor, mark=\"[SEP]\"):\n",
    "    toks = tokenizer.convert_ids_to_tokens(input_ids_1d.tolist())\n",
    "    s = []\n",
    "    for i, (tok, m) in enumerate(zip(toks, mask.tolist())):\n",
    "        if m:\n",
    "            s.append(f\"{tok}{mark}\")\n",
    "        else:\n",
    "            s.append(tok)\n",
    "    print(\"TOKENS:\", \" \".join(s))\n",
    "    print(\"MASK  :\", \" \".join((\"^\" if m else \".\") for m in mask.tolist()))\n",
    "\n",
    "# ------------------------------\n",
    "# (B) 디버그 출력을 담는 자료구조\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class DebugStep:\n",
    "    idx: int\n",
    "    text: str\n",
    "    token_index: int\n",
    "    token_str: str\n",
    "    score: float\n",
    "    extra: dict\n",
    "\n",
    "@dataclass\n",
    "class DebugTrace:\n",
    "    is_reward_model: bool\n",
    "    system_prompt: str\n",
    "    question: str\n",
    "    steps: List[str]\n",
    "    conversation_str_preview: str\n",
    "    input_shape: Tuple[int, int]\n",
    "    logits_shape: Optional[Tuple[int, int, int]]\n",
    "    step_separator: str\n",
    "    step_token_ids: List[int]\n",
    "    step_token_positions: List[int]\n",
    "    step_details: List[DebugStep]\n",
    "    agg: str\n",
    "    agg_score: float\n",
    "\n",
    "# ------------------------------\n",
    "# (C) 핵심: 한 개 후보(cand)에 대한 디버그\n",
    "# ------------------------------\n",
    "def debug_one_candidate(\n",
    "    prm_model,\n",
    "    prm_tokenizer,\n",
    "    system_prompt: str,\n",
    "    question: str,\n",
    "    candidate_text: str,\n",
    "    *,\n",
    "    rw_token: str = \"<RW>\",\n",
    "    sep_token: str = \"<extra_0>\",\n",
    "    agg: str = \"mean\",\n",
    "    show_logits_topk: int = 0,  # 분류형에서 원하면 top-k 로짓 보기\n",
    "    max_preview_chars: int = 800,\n",
    ") -> DebugTrace:\n",
    "    # 모델 유형 판별\n",
    "    is_reward_model = hasattr(prm_model, \"predict_rewards_at_rw\")\n",
    "\n",
    "    # 1) 스텝 파싱\n",
    "    steps = split_steps(candidate_text)\n",
    "    print(\"\\n========== [1] Parsed Steps ==========\")\n",
    "    for i, st in enumerate(steps, 1):\n",
    "        print(f\"Step {i}: {st}\")\n",
    "\n",
    "    # 2) 대화문 구성\n",
    "    if is_reward_model:\n",
    "        print(\"I'm reward model, using RW token for steps.\")\n",
    "        assistant_text = rw_token.join(steps) + rw_token\n",
    "    else:\n",
    "        assistant_text = sep_token.join(steps) + sep_token\n",
    "    \n",
    "    conv_str = to_chat_prompt(prm_tokenizer, question, assistant_text)\n",
    "    print(\"\\n========== [2] Conversation String ==========\")\n",
    "    # print(conv_str if len(conv_str) <= max_preview_chars else conv_str[:max_preview_chars] + \" ... [truncated]\")\n",
    "    print(\"Conversation string:\", conv_str)\n",
    "\n",
    "    # 3) 토크나이징\n",
    "    inputs = prm_tokenizer(conv_str, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attn = inputs.get(\"attention_mask\", torch.ones_like(input_ids))\n",
    "    dev = next(prm_model.parameters()).device\n",
    "    input_ids = input_ids.to(dev)\n",
    "    attn = attn.to(dev)\n",
    "\n",
    "    print(\"\\n========== [3] Tokenization ==========\")\n",
    "    print(\"input_ids shape:\", tuple(input_ids.shape))\n",
    "\n",
    "    # 4) 스텝 구분 토큰 마스크 만들기\n",
    "    if is_reward_model:\n",
    "        step_sep = rw_token\n",
    "    else:\n",
    "        step_sep = sep_token\n",
    "\n",
    "    sep_token_id, sep_subseq = _ensure_token_or_subseq(prm_tokenizer, step_sep)\n",
    "    mask = _build_mask_from_token_or_subseq(input_ids[0], sep_token_id, sep_subseq)\n",
    "\n",
    "    print(f\"Step separator = '{step_sep}' | \"\n",
    "          f\"{'single token id='+str(sep_token_id) if sep_token_id is not None else 'sub-sequence ids='+str(sep_subseq)}\")\n",
    "    _print_tokens_with_marks(prm_tokenizer, input_ids[0], mask, mark=\"[STEP]\")\n",
    "\n",
    "    # 5) Forward & 스코어\n",
    "    step_details = []\n",
    "    logits_shape = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if is_reward_model:\n",
    "            # 커스텀 PRM: predict_rewards_at_rw 사용\n",
    "            rewards_list = prm_model.predict_rewards_at_rw(input_ids=input_ids, attention_mask=attn)  # List[Tensor], len=B\n",
    "            assert len(rewards_list) == 1, f\"Unexpected reward output: {rewards_list}\"\n",
    "            rewards = rewards_list[0].detach().float().cpu()  # (S,)\n",
    "            # <RW> 위치들\n",
    "            rw_id, rw_subseq = _ensure_token_or_subseq(prm_tokenizer, rw_token)\n",
    "            rw_mask = _build_mask_from_token_or_subseq(input_ids[0], rw_id, rw_subseq)\n",
    "            rw_pos = torch.nonzero(rw_mask, as_tuple=False).view(-1).tolist()\n",
    "\n",
    "            # 안전: 스텝 수와 RW 수가 다르면 경고\n",
    "            if len(rw_pos) != len(steps):\n",
    "                print(f\"[WARN] steps({len(steps)}) != RW tokens({len(rw_pos)}). Alignment may be off.\")\n",
    "\n",
    "            toks = prm_tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "            for i, (pos, sc) in enumerate(zip(rw_pos, rewards.tolist()), 1):\n",
    "                tok_str = toks[pos]\n",
    "                step_details.append(DebugStep(\n",
    "                    idx=i, text=steps[i-1], token_index=pos, token_str=tok_str, score=float(sc), extra={}\n",
    "                ))\n",
    "        else:\n",
    "            # 분류형 PRM: <extra_0> 위치의 로짓에서 P(label=1)\n",
    "            outputs = prm_model(input_ids=input_ids, attention_mask=attn)\n",
    "            logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
    "            logits = logits.detach().float()  # (B,T,C)\n",
    "            logits_shape = tuple(logits.shape)\n",
    "            print(\"logits shape:\", logits_shape)\n",
    "            assert logits.dim() == 3 and logits.shape[0] == 1, \"Expect (B=1, T, C)\"\n",
    "\n",
    "            pos_idx = torch.nonzero(mask, as_tuple=False).view(-1)  # (S,)\n",
    "            if pos_idx.numel() == 0:\n",
    "                print(\"[WARN] No step separators found in tokens.\")\n",
    "            # 안전: 이 모델이 바이너리 분류인지 확인\n",
    "            if logits.shape[-1] < 2:\n",
    "                print(f\"[WARN] logits last dim = {logits.shape[-1]} < 2. Expected binary classifier.\")\n",
    "            probs = F.softmax(logits[0, pos_idx, :], dim=-1) if pos_idx.numel() else torch.empty(0,2)\n",
    "            toks = prm_tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "            for i, (pidx, prob_vec) in enumerate(zip(pos_idx.tolist(), probs.tolist()), 1):\n",
    "                pos_prob = float(prob_vec[1]) if len(prob_vec) > 1 else float(\"nan\")\n",
    "                extra = {}\n",
    "                if show_logits_topk > 0:\n",
    "                    # 상위 k 로짓/확률(클래스 차원)\n",
    "                    topk_vals, topk_idx = torch.topk(torch.tensor(prob_vec), k=min(show_logits_topk, len(prob_vec)))\n",
    "                    extra[\"topk_probs\"] = [(int(j), float(v)) for v, j in zip(topk_vals.tolist(), topk_idx.tolist())]\n",
    "                step_details.append(DebugStep(\n",
    "                    idx=i, text=steps[i-1], token_index=int(pidx), token_str=toks[pidx], score=pos_prob, extra=extra\n",
    "                ))\n",
    "\n",
    "    # 6) 집계\n",
    "    scores = [d.score for d in step_details]\n",
    "    agg_score = aggregate(scores, how=agg)\n",
    "\n",
    "    # 7) 표 형태 프린트\n",
    "    print(\"\\n========== [4] Step-wise Scores ==========\")\n",
    "    header = f\"{'i':>2} | {'token@idx':<18} | {'score':>8} | step text\"\n",
    "    print(header)\n",
    "    print(\"-\"*len(header))\n",
    "    for d in step_details:\n",
    "        tok_tag = f\"{d.token_str}@{d.token_index}\"\n",
    "        print(f\"{d.idx:>2} | {tok_tag:<18} | {d.score:>8.5f} | {d.text}\")\n",
    "        if d.extra.get(\"topk_probs\"):\n",
    "            print(f\"     top-k probs: {d.extra['topk_probs']}\")\n",
    "\n",
    "    print(f\"\\nAGG({agg}) = {agg_score:.5f}\")\n",
    "\n",
    "    return DebugTrace(\n",
    "        is_reward_model=is_reward_model,\n",
    "        system_prompt=system_prompt,\n",
    "        question=question,\n",
    "        steps=steps,\n",
    "        conversation_str_preview=conv_str,\n",
    "        input_shape=tuple(input_ids.shape),\n",
    "        logits_shape=logits_shape,\n",
    "        step_separator=step_sep,\n",
    "        step_token_ids=sep_subseq,\n",
    "        step_token_positions=[sd.token_index for sd in step_details],\n",
    "        step_details=step_details,\n",
    "        agg=agg,\n",
    "        agg_score=float(agg_score),\n",
    "    )\n",
    "\n",
    "# ------------------------------\n",
    "# (D) 여러 후보 대비 래퍼 (BoN/다중 후보 확인용)\n",
    "# ------------------------------\n",
    "def debug_candidates_with_prm(\n",
    "    prm_model,\n",
    "    prm_tokenizer,\n",
    "    system_prompt: str,\n",
    "    question: str,\n",
    "    candidates: List[str],\n",
    "    *,\n",
    "    rw_token: str = \"<RW>\",\n",
    "    sep_token: str = \"<extra_0>\",\n",
    "    agg: str = \"mean\",\n",
    "):\n",
    "    traces = []\n",
    "    for k, cand in enumerate(candidates):\n",
    "        print(\"\\n\\n\" + \"=\"*80)\n",
    "        print(f\"[Candidate {k}]\")\n",
    "        trace = debug_one_candidate(\n",
    "            prm_model, prm_tokenizer, system_prompt, question, cand,\n",
    "            rw_token=rw_token, sep_token=sep_token, agg=agg\n",
    "        )\n",
    "        traces.append(trace)\n",
    "    # 최적 후보 출력\n",
    "    best_idx = max(range(len(traces)), key=lambda i: traces[i].agg_score)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"[BEST by AGG({agg})] cand={best_idx} | score={traces[best_idx].agg_score:.5f}\")\n",
    "    return best_idx, traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leena/.conda/envs/ccc/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] resize_token_embeddings: base 152064 -> tok 151666\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/leena/prm_shaping/inference/')\n",
    "\n",
    "from wrapper import PRMRewardWrapper\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "path = \"/home/leena/prm_shaping/checkpoints/mi_loo/final_model\"\n",
    "prm_tokenizer = AutoTokenizer.from_pretrained(path, use_fast=False)\n",
    "prm_model = PRMRewardWrapper.from_pretrained(path, tokenizer=prm_tokenizer).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== [1] Parsed Steps ==========\n",
      "Step 1: To find out how many more pink plastic flamingos were out than white plastic flamingos at noon on Sunday, we can break down the problem into steps. First, on Friday, the neighbors start with 18 pink plastic flamingos.\n",
      "Step 2: On Saturday, they take back one third of the flamingos. Since there were 18 flamingos, (1/3 \\times 18 = 6) flamingos are taken back. So, they have (18 - 6 = 12) flamingos left in their possession. Then, they paint these 6 flamingos white and put them back out on Sue's front yard. Now, Sue has the original 12 pink flamingos plus the 6 new white ones. Thus, by the end of Saturday, Sue has (12 + 6 = 18) pink flamingos and 6 white flamingos.\n",
      "Step 3: On Sunday, the neighbors add another 18 pink plastic flamingos to Sue's front yard. By the end of Sunday morning, Sue has (18 + 18 = 36) pink flamingos and still 6 white flamingos.\n",
      "Step 4: To find the difference, subtract the number of white flamingos from the number of pink flamingos: (36 - 6 = 30). Therefore, at noon on Sunday, there were 30 more pink plastic flamingos out than white plastic flamingos. The answer is (\\boxed{30}).\n",
      "I'm reward model, using RW token for steps.\n",
      "\n",
      "========== [2] Conversation String ==========\n",
      "Conversation string: <|im_start|>system\n",
      "You are Qwen-Math, a meticulous math tutor. Solve problems with clear, numbered steps and give only ONE final answer line.<|im_end|>\n",
      "<|im_start|>user\n",
      "Please reason step by step. Follow this EXACT format:\n",
      "Step 1: <short reasoning>\n",
      "Step 2: <short reasoning>\n",
      "...\n",
      "Answer: <final numeric answer>\n",
      "Constraints:\n",
      "- Keep each step concise, one idea per line.\n",
      "- Do not include extra explanations after the final Answer line.\n",
      "\n",
      "Problem: Sue lives in a fun neighborhood.  One weekend, the neighbors decided to play a prank on Sue.  On Friday morning, the neighbors placed 18 pink plastic flamingos out on Sue's front yard.  On Saturday morning, the neighbors took back one third of the flamingos, painted them white, and put these newly painted white flamingos back out on Sue's front yard.  Then, on Sunday morning, they added another 18 pink plastic flamingos to the collection. At noon on Sunday, how many more pink plastic flamingos were out than white plastic flamingos?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "To find out how many more pink plastic flamingos were out than white plastic flamingos at noon on Sunday, we can break down the problem into steps. First, on Friday, the neighbors start with 18 pink plastic flamingos.<RW>On Saturday, they take back one third of the flamingos. Since there were 18 flamingos, (1/3 \\times 18 = 6) flamingos are taken back. So, they have (18 - 6 = 12) flamingos left in their possession. Then, they paint these 6 flamingos white and put them back out on Sue's front yard. Now, Sue has the original 12 pink flamingos plus the 6 new white ones. Thus, by the end of Saturday, Sue has (12 + 6 = 18) pink flamingos and 6 white flamingos.<RW>On Sunday, the neighbors add another 18 pink plastic flamingos to Sue's front yard. By the end of Sunday morning, Sue has (18 + 18 = 36) pink flamingos and still 6 white flamingos.<RW>To find the difference, subtract the number of white flamingos from the number of pink flamingos: (36 - 6 = 30). Therefore, at noon on Sunday, there were 30 more pink plastic flamingos out than white plastic flamingos. The answer is (\\boxed{30}).<RW><|im_end|>\n",
      "\n",
      "\n",
      "========== [3] Tokenization ==========\n",
      "input_ids shape: (1, 528)\n",
      "Step separator = '<RW>' | single token id=151665\n",
      "TOKENS: <|im_start|> system Ċ You Ġare ĠQ wen -M ath , Ġa Ġmeticulous Ġmath Ġtutor . ĠSolve Ġproblems Ġwith Ġclear , Ġnumbered Ġsteps Ġand Ġgive Ġonly ĠONE Ġfinal Ġanswer Ġline . <|im_end|> Ċ <|im_start|> user Ċ Please Ġreason Ġstep Ġby Ġstep . ĠFollow Ġthis ĠEX ACT Ġformat :Ċ Step Ġ 1 : Ġ< short Ġreasoning >Ċ Step Ġ 2 : Ġ< short Ġreasoning >Ċ ...Ċ Answer : Ġ< final Ġnumeric Ġanswer >Ċ Constraints :Ċ - ĠKeep Ġeach Ġstep Ġconcise , Ġone Ġidea Ġper Ġline .Ċ - ĠDo Ġnot Ġinclude Ġextra Ġexplanations Ġafter Ġthe Ġfinal ĠAnswer Ġline .ĊĊ Problem : ĠSue Ġlives Ġin Ġa Ġfun Ġneighborhood . Ġ ĠOne Ġweekend , Ġthe Ġneighbors Ġdecided Ġto Ġplay Ġa Ġprank Ġon ĠSue . Ġ ĠOn ĠFriday Ġmorning , Ġthe Ġneighbors Ġplaced Ġ 1 8 Ġpink Ġplastic Ġflaming os Ġout Ġon ĠSue 's Ġfront Ġyard . Ġ ĠOn ĠSaturday Ġmorning , Ġthe Ġneighbors Ġtook Ġback Ġone Ġthird Ġof Ġthe Ġflaming os , Ġpainted Ġthem Ġwhite , Ġand Ġput Ġthese Ġnewly Ġpainted Ġwhite Ġflaming os Ġback Ġout Ġon ĠSue 's Ġfront Ġyard . Ġ ĠThen , Ġon ĠSunday Ġmorning , Ġthey Ġadded Ġanother Ġ 1 8 Ġpink Ġplastic Ġflaming os Ġto Ġthe Ġcollection . ĠAt Ġnoon Ġon ĠSunday , Ġhow Ġmany Ġmore Ġpink Ġplastic Ġflaming os Ġwere Ġout Ġthan Ġwhite Ġplastic Ġflaming os ? <|im_end|> Ċ <|im_start|> assistant Ċ To Ġfind Ġout Ġhow Ġmany Ġmore Ġpink Ġplastic Ġflaming os Ġwere Ġout Ġthan Ġwhite Ġplastic Ġflaming os Ġat Ġnoon Ġon ĠSunday , Ġwe Ġcan Ġbreak Ġdown Ġthe Ġproblem Ġinto Ġsteps . ĠFirst , Ġon ĠFriday , Ġthe Ġneighbors Ġstart Ġwith Ġ 1 8 Ġpink Ġplastic Ġflaming os . <RW>[STEP] On ĠSaturday , Ġthey Ġtake Ġback Ġone Ġthird Ġof Ġthe Ġflaming os . ĠSince Ġthere Ġwere Ġ 1 8 Ġflaming os , Ġ( 1 / 3 Ġ\\ times Ġ 1 8 Ġ= Ġ 6 ) Ġflaming os Ġare Ġtaken Ġback . ĠSo , Ġthey Ġhave Ġ( 1 8 Ġ- Ġ 6 Ġ= Ġ 1 2 ) Ġflaming os Ġleft Ġin Ġtheir Ġpossession . ĠThen , Ġthey Ġpaint Ġthese Ġ 6 Ġflaming os Ġwhite Ġand Ġput Ġthem Ġback Ġout Ġon ĠSue 's Ġfront Ġyard . ĠNow , ĠSue Ġhas Ġthe Ġoriginal Ġ 1 2 Ġpink Ġflaming os Ġplus Ġthe Ġ 6 Ġnew Ġwhite Ġones . ĠThus , Ġby Ġthe Ġend Ġof ĠSaturday , ĠSue Ġhas Ġ( 1 2 Ġ+ Ġ 6 Ġ= Ġ 1 8 ) Ġpink Ġflaming os Ġand Ġ 6 Ġwhite Ġflaming os . <RW>[STEP] On ĠSunday , Ġthe Ġneighbors Ġadd Ġanother Ġ 1 8 Ġpink Ġplastic Ġflaming os Ġto ĠSue 's Ġfront Ġyard . ĠBy Ġthe Ġend Ġof ĠSunday Ġmorning , ĠSue Ġhas Ġ( 1 8 Ġ+ Ġ 1 8 Ġ= Ġ 3 6 ) Ġpink Ġflaming os Ġand Ġstill Ġ 6 Ġwhite Ġflaming os . <RW>[STEP] To Ġfind Ġthe Ġdifference , Ġsubtract Ġthe Ġnumber Ġof Ġwhite Ġflaming os Ġfrom Ġthe Ġnumber Ġof Ġpink Ġflaming os : Ġ( 3 6 Ġ- Ġ 6 Ġ= Ġ 3 0 ). ĠTherefore , Ġat Ġnoon Ġon ĠSunday , Ġthere Ġwere Ġ 3 0 Ġmore Ġpink Ġplastic Ġflaming os Ġout Ġthan Ġwhite Ġplastic Ġflaming os . ĠThe Ġanswer Ġis Ġ(\\ boxed { 3 0 }). <RW>[STEP] <|im_end|> Ċ\n",
      "MASK  : . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ^ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ^ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ^ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ^ . .\n",
      "\n",
      "========== [4] Step-wise Scores ==========\n",
      " i | token@idx          |    score | step text\n",
      "----------------------------------------------\n",
      " 1 | <RW>@271           | -0.48993 | To find out how many more pink plastic flamingos were out than white plastic flamingos at noon on Sunday, we can break down the problem into steps. First, on Friday, the neighbors start with 18 pink plastic flamingos.\n",
      " 2 | <RW>@407           | -0.23658 | On Saturday, they take back one third of the flamingos. Since there were 18 flamingos, (1/3 \\times 18 = 6) flamingos are taken back. So, they have (18 - 6 = 12) flamingos left in their possession. Then, they paint these 6 flamingos white and put them back out on Sue's front yard. Now, Sue has the original 12 pink flamingos plus the 6 new white ones. Thus, by the end of Saturday, Sue has (12 + 6 = 18) pink flamingos and 6 white flamingos.\n",
      " 3 | <RW>@460           | -0.41580 | On Sunday, the neighbors add another 18 pink plastic flamingos to Sue's front yard. By the end of Sunday morning, Sue has (18 + 18 = 36) pink flamingos and still 6 white flamingos.\n",
      " 4 | <RW>@525           | -0.75573 | To find the difference, subtract the number of white flamingos from the number of pink flamingos: (36 - 6 = 30). Therefore, at noon on Sunday, there were 30 more pink plastic flamingos out than white plastic flamingos. The answer is (\\boxed{30}).\n",
      "\n",
      "AGG(mean) = -0.47451\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"system\": \"Please reason step by step, and put your final answer within \\\\boxed{}.\",\n",
    "    \"query\": \"Sue lives in a fun neighborhood.  One weekend, the neighbors decided to play a prank on Sue.  On Friday morning, the neighbors placed 18 pink plastic flamingos out on Sue's front yard.  On Saturday morning, the neighbors took back one third of the flamingos, painted them white, and put these newly painted white flamingos back out on Sue's front yard.  Then, on Sunday morning, they added another 18 pink plastic flamingos to the collection. At noon on Sunday, how many more pink plastic flamingos were out than white plastic flamingos?\",\n",
    "    \"response\": [\n",
    "      \"To find out how many more pink plastic flamingos were out than white plastic flamingos at noon on Sunday, we can break down the problem into steps. First, on Friday, the neighbors start with 18 pink plastic flamingos.\",\n",
    "      \"On Saturday, they take back one third of the flamingos. Since there were 18 flamingos, (1/3 \\\\times 18 = 6) flamingos are taken back. So, they have (18 - 6 = 12) flamingos left in their possession. Then, they paint these 6 flamingos white and put them back out on Sue's front yard. Now, Sue has the original 12 pink flamingos plus the 6 new white ones. Thus, by the end of Saturday, Sue has (12 + 6 = 18) pink flamingos and 6 white flamingos.\",\n",
    "      \"On Sunday, the neighbors add another 18 pink plastic flamingos to Sue's front yard. By the end of Sunday morning, Sue has (18 + 18 = 36) pink flamingos and still 6 white flamingos.\",\n",
    "      \"To find the difference, subtract the number of white flamingos from the number of pink flamingos: (36 - 6 = 30). Therefore, at noon on Sunday, there were 30 more pink plastic flamingos out than white plastic flamingos. The answer is (\\\\boxed{30}).\"\n",
    "    ]\n",
    "}\n",
    "candidate = \"\\n\\n\".join(data[\"response\"])  # 의도적으로 줄바꿈 포함 (split_steps가 알아서 처리)\n",
    "\n",
    "trace = debug_one_candidate(\n",
    "    prm_model, prm_tokenizer,\n",
    "    system_prompt=data[\"system\"],\n",
    "    question=data[\"query\"],\n",
    "    candidate_text=candidate,\n",
    "    rw_token=\"<RW>\",           # 커스텀 PRM이면 \"<RW>\" 유지, 분류형이면 무시됨\n",
    "    # sep_token=\"<extra_0>\",     # 분류형에서 스텝 구분용\n",
    "    agg=\"mean\",\n",
    "    show_logits_topk=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
