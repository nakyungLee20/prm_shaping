{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Project‑level helpers \n",
    "from utils import _sanitize, _numeric_equiv, _strip_markup, _to_float, system_prompt\n",
    "from ..prm_dataset.config import PRMConfig\n",
    "\n",
    "class MCReward:\n",
    "    STEP_PATTERN = re.compile(\n",
    "    r\"\"\"^[\\s>#*\\-]*          # optional markdown/bullet symbols\n",
    "        Step\\s*              # word 'Step' (case-insensitive)\n",
    "        (\\d+)                # capture step number\n",
    "        \\s*[:.\\-]            # separator (: . or -)\n",
    "    \"\"\",\n",
    "    re.IGNORECASE | re.VERBOSE,\n",
    "    )\n",
    "    ANSWER_PATTERN = re.compile(\n",
    "        r\"\"\"^[\\s>#*\\-]*          # optional markdown/bullet symbols\n",
    "            Answer               # word 'Answer'\n",
    "            \\s*[:.\\-]\\s*         # separator\n",
    "            (.+?)\\s*$            # capture everything after\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.MULTILINE | re.VERBOSE,\n",
    "    )\n",
    "    ## Masked rewards ##\n",
    "    OP_TOKENS = [\"add\", \"plus\", \"sum\", \"subtract\", \"minus\",\n",
    "             \"multiply\", \"times\", \"product\", \"divide\", \"quotient\"]\n",
    "    _MASK_PATTERN = re.compile(\n",
    "        r\"\"\"\n",
    "        (?:\n",
    "        # {ops_pattern}|                # operator patterns\n",
    "            \\b\\d+(?:\\.\\d+)?\\b         # integers / decimals\n",
    "          | \\b\\d+/\\d+\\b                 # simple fractions\n",
    "        #   | \\b[a-zA-Z]\\b                 # single‑letter variables\n",
    "        )\n",
    "        \"\"\",\n",
    "        re.VERBOSE,\n",
    "    )\n",
    "\n",
    "    def __init__(self, config: \"PRMConfig\", model, tokenizer):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    # Function to generate one or more step-by-step solutions for a given question.\n",
    "    def gsm8k_solutions(self, question: str, gold_solution: str):\n",
    "        # 1. Split lines *before* the final answer marker (#### …)\n",
    "        lines: List[str] = []\n",
    "        gold_answer: str = \"\"\n",
    "        _ANSWER_RE = re.compile(r\"####\\s*(.+?)\\s*$\")\n",
    "\n",
    "        for raw_ln in gold_solution.splitlines():\n",
    "            ln = raw_ln.strip()\n",
    "            if not ln:\n",
    "                continue  # skip empty\n",
    "            ans_match = _ANSWER_RE.match(ln)\n",
    "            if ans_match:\n",
    "                gold_answer = ans_match.group(1).strip()\n",
    "                break  # everything after #### is ignored\n",
    "            lines.append(ln)\n",
    "\n",
    "        if not gold_answer:\n",
    "            raise ValueError(\"Could not find final answer marker '#### <answer>' in gold_solution.\")\n",
    "\n",
    "        # 2. Prefix each explanatory line with \"Step i:\"\n",
    "        solution_steps = [f\"Step {i + 1}: {txt}\" for i, txt in enumerate(lines)]\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"solution\": solution_steps,\n",
    "            \"gold_answer\": gold_answer,\n",
    "        }\n",
    "\n",
    "    # Function to parse a solution text into steps and final answer.\n",
    "    def _extract_answer(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Try multiple heuristics / regexes to pull out an answer string.\"\"\"\n",
    "        # Primary regex (robust to Answer:, Answer ‑, etc.)\n",
    "        match = self.ANSWER_PATTERN.search(text)\n",
    "        if match:\n",
    "            return _sanitize(match.group(1))\n",
    "        \n",
    "        # Fallback 1: last non‑empty line if it looks simple / numeric\n",
    "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "        if lines:\n",
    "            candidate = lines[-1]\n",
    "            if re.search(r\"\\d\", candidate):  # contains digit\n",
    "                return _sanitize(candidate)\n",
    "\n",
    "        # Fallback 2: look for last line that starts with 'Answer'\n",
    "        for line in reversed(text.splitlines()):\n",
    "            if line.strip().lower().startswith(\"answer\"):\n",
    "                return _sanitize(line.split(\"Answer\", 1)[-1])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def parse_solution(self, solution_text: str):\n",
    "        \"\"\"Split each step to start with 'Step X:' and the answer to start with 'Answer:'.\"\"\"\n",
    "        steps = []\n",
    "        # Split by lines to identify steps and answer\n",
    "        for line in solution_text.splitlines():\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if self.STEP_PATTERN.match(line):\n",
    "                cleaned = re.sub(r'^[\\s>#*\\-]+', '', line)\n",
    "                steps.append(cleaned)\n",
    "            answer = self._extract_answer(solution_text)\n",
    "        return steps, answer\n",
    "    \n",
    "    # Function to estimate intermediate rewards for each step via rollouts.\n",
    "    def compute_step_rewards(self, question, sys_prompt, steps, gold_answer):\n",
    "        \"\"\"\n",
    "        For each prefix ending at a given step in 'steps', generate rollouts and compute the reward \n",
    "        (fraction of rollouts ending in the correct answer). Returns a list of reward values corresponding to each step.\n",
    "        \"\"\"\n",
    "        rewards = []\n",
    "        total_steps = len(steps)\n",
    "\n",
    "        # Pre‑encode static prefix (sys_prompt + question) once for efficiency\n",
    "        base_prompt = f\"{sys_prompt}\\n\\nProblem: {question}\\n\"\n",
    "        base_ids = self.tokenizer.encode(base_prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        for i in range(total_steps):\n",
    "            prefix_tokens = self.tokenizer.encode(\"\\n\".join(steps[: i + 1]) + \"\\n\", return_tensors=\"pt\").to(self.device) # steps up to current step i (0-indexed)\n",
    "            # Decide how to prompt the next part:\n",
    "            if i < total_steps - 1:\n",
    "                next_label = f\"Step {i + 2}:\"\n",
    "            else:\n",
    "                next_label = \"Answer:\"\n",
    "            cont_ids = self.tokenizer.encode(next_label, return_tensors=\"pt\").to(self.device)\n",
    "            # Build full prefix ids (avoid Python concat inefficiency by cat)\n",
    "            prefix_ids = torch.cat([base_ids, prefix_tokens, cont_ids], dim=-1)\n",
    "            rollout_outputs = self.model.generate(\n",
    "                prefix_ids,\n",
    "                max_new_tokens=self.config.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=self.config.num_rollouts,\n",
    "                temperature=0.8,\n",
    "                top_p=0.8,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "            new_token_start = prefix_ids.shape[-1] \n",
    "            # Check each rollout's final answer against the gold answer\n",
    "            correct_count = 0\n",
    "            for idx, seq in enumerate(rollout_outputs):\n",
    "                completion = self.tokenizer.decode(seq[new_token_start:], skip_special_tokens=True)\n",
    "                pred_answer = self._extract_answer(completion)\n",
    "                # print(f\"[{i+1}-th Step, {idx}-th Original Rollout]\", completion, \"Pred Answer\", pred_answer)\n",
    "                if pred_answer is not None and _numeric_equiv(pred_answer, gold_answer):\n",
    "                    correct_count += 1\n",
    "            reward = correct_count / float(self.config.num_rollouts)\n",
    "            rewards.append(reward)\n",
    "        return rewards\n",
    "    \n",
    "    # Masked solution paths\n",
    "    def model_masking(self, text: str, *, max_new_tokens: int = 64) -> str:\n",
    "        prompt = \"In the sentence below, mask any word or expression that seems crucial for solving the math step. This may include key numbers, variables, or action words (like operations), but you should decide what matters. Replace each important item with '[MASKED]'. Keep everything else unchanged. Return ONE line.\\n\\nSentence: \\\"{sent}\\\"\\nRewritten:\".format(sent=text)\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        out_ids   = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.2, top_p=0.2,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "        return self.tokenizer.decode(out_ids[0][input_ids.shape[-1]:],\n",
    "                                     skip_special_tokens=True).strip()\n",
    "\n",
    "    def perturbed_step_rewards(self, question: str, sys_prompt: str, steps: List[str], gold_answer: str, use_llm: bool = True) -> List[float]:\n",
    "        \"\"\"Compute MC correctness rates *after masking* the current step.\n",
    "        Each step `i` is replaced with a *perturbed* version where important tokens (numbers, fractions, single‑letter variables) are substituted by the literal string ``[MASKED]``. All preceding steps remain intact.\n",
    "        \"\"\"\n",
    "        ptb_rewards: List[float] = []\n",
    "        total_steps = len(steps)\n",
    "        base_prompt = f\"{sys_prompt}\\n\\nProblem: {question}\\n\"\n",
    "        base_ids = self.tokenizer.encode(base_prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        for i in range(total_steps):\n",
    "            # 1. Perturb *only* step i\n",
    "            orig_step = steps[i] \n",
    "            step_match = re.match(r\"^[\\s>#*\\-]*Step\\s*\\d+\\s*[:.\\-]\\s*\", orig_step, flags=re.I)\n",
    "            prefix = step_match.group(0) if step_match else \"\"\n",
    "            # ② 나머지 부분(body)만 마스킹\n",
    "            body   = steps[i][len(prefix):]                       # 접두사 뒷부분\n",
    "            if use_llm:\n",
    "                masked_body = self.model_masking(body)\n",
    "            else:\n",
    "                masked_body = self._MASK_PATTERN.sub(\"[MASKED]\", body)\n",
    "            # ③ 접두사 + 마스킹된 body\n",
    "            masked_step = prefix + masked_body    \n",
    "            ptb_prefix_steps = steps[:i] + [masked_step]\n",
    "            # print(\"perturbed step:\", ptb_prefix_steps)\n",
    "\n",
    "            prefix_tokens = self.tokenizer.encode(\"\\n\".join(ptb_prefix_steps) + \"\\n\", return_tensors=\"pt\").to(self.device)\n",
    "            next_label = f\"Step {i + 2}:\" if i < total_steps - 1 else \"Answer:\"\n",
    "            cont_ids = self.tokenizer.encode(next_label, return_tensors=\"pt\").to(self.device)\n",
    "            prefix_ids = torch.cat([base_ids, prefix_tokens, cont_ids], dim=-1)\n",
    "\n",
    "            rollout_outputs = self.model.generate(\n",
    "                prefix_ids,\n",
    "                max_new_tokens=self.config.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=self.config.num_rollouts,\n",
    "                temperature=0.8,\n",
    "                top_p=0.8,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "            )\n",
    "            new_token_start = prefix_ids.shape[-1]\n",
    "            correct_count = 0\n",
    "            for idx, seq in enumerate(rollout_outputs):\n",
    "                completion = self.tokenizer.decode(seq[new_token_start:], skip_special_tokens=True)\n",
    "                pred_answer = self._extract_answer(completion)\n",
    "                # print(f\"Masked [{i+1}-th Step, {idx}-th Rollout]\", completion, \"Pred Answer\", pred_answer)\n",
    "                if pred_answer is not None and _numeric_equiv(pred_answer, gold_answer):\n",
    "                    correct_count += 1\n",
    "            ptb_rewards.append(correct_count / float(self.config.num_rollouts))\n",
    "        return ptb_rewards\n",
    "\n",
    "    def _generate_rollouts(self, prompt: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        vLLM 에서 동일 프롬프트를 n번(=num_rollouts) 샘플링해서 텍스트만 반환\n",
    "        \"\"\"\n",
    "        outs = self.llm.generate([prompt], self.sparams)   # 배치 길이 1\n",
    "        return [o.outputs[ri].text for o in outs for ri in range(len(o.outputs))]\n",
    "\n",
    "    # Build datasets based on input datas\n",
    "    def build_datasets_gsm8k(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        _ANSWER_RE = re.compile(r\"####\\s*(.+?)\\s*$\")\n",
    "\n",
    "        rollout_pr = system_prompt(\"rollout\")\n",
    "        ds = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "        if take is not None:\n",
    "            ds = ds.shuffle(seed=self.config.seed).select(range(start, start+take))\n",
    "        else:\n",
    "            ds = ds.shuffle(seed=self.config.seed).select(range(start, len(ds)))\n",
    "\n",
    "        csr, psr   = self.compute_step_rewards, self.perturbed_step_rewards\n",
    "        sanitize   = _sanitize\n",
    "        use_llm    = self.config.use_llm\n",
    "        dataset    = []\n",
    "        \n",
    "        for sample in tqdm(ds, desc=\"Building GSM-8K reward-dataset\"):\n",
    "            # ── (1) extract step solutions ──────────────────────────────────────────\n",
    "            q_txt   = sample[\"question\"]\n",
    "            g_sol   = sample[\"answer\"]\n",
    "            lines, gold_ans = [], None\n",
    "            for ln in g_sol.splitlines():\n",
    "                ln = ln.strip()\n",
    "                if not ln:\n",
    "                    continue\n",
    "                m = _ANSWER_RE.match(ln)\n",
    "                if m:\n",
    "                    gold_ans = sanitize(m.group(1))\n",
    "                    break\n",
    "                lines.append(ln)\n",
    "            if gold_ans is None:\n",
    "                raise ValueError(\"gold answer not found for sample\")\n",
    "            steps = [f\"Step {i+1}: {t}\" for i, t in enumerate(lines)]\n",
    "\n",
    "            # ── (2) compute rewards ───────────────────────────────────────────────────\n",
    "            ori = csr(q_txt, rollout_pr, steps, gold_ans)\n",
    "            ptb = psr(q_txt, rollout_pr, steps, gold_ans, use_llm)\n",
    "            if len(ptb) != len(ori):\n",
    "                ptb = ptb[: len(ori)]\n",
    "            contrib = [round(o - p, 4) for o, p in zip(ori, ptb)]\n",
    "\n",
    "            #  ── (3) Append entry ───────────────────────────────────────────\n",
    "            entry = {\n",
    "                    \"question\":      q_txt,\n",
    "                    \"completion\":    steps,\n",
    "                    \"ori_rewards\":   ori,\n",
    "                    \"ptb_rewards\":   ptb,\n",
    "                    \"contributions\": contrib,\n",
    "                    \"answer\":        gold_ans,\n",
    "                    \"gold_answer\":   gold_ans,\n",
    "                }\n",
    "            dataset.append(entry)\n",
    "            # print(entry)\n",
    "        return dataset\n",
    "\n",
    "    def build_datasets_math(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        boxed_re   = re.compile(r'\\\\boxed\\{(.+?)\\}', re.S)\n",
    "        sent_split = re.compile(r'\\.(?!\\d)(?=\\s|$)')   # 소수점·수식 내부 마침표 무시\n",
    "\n",
    "        rollout_prompt = system_prompt(\"rollout\")\n",
    "        ds = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=split)\n",
    "\n",
    "        # shuffle & take\n",
    "        if take is not None:\n",
    "            ds = ds.select(range(start, start+take))\n",
    "        else:\n",
    "            ds = ds.select(range(start, len(ds)))\n",
    "\n",
    "        # (alias) time optimize\n",
    "        csr, psr   = self.compute_step_rewards, self.perturbed_step_rewards\n",
    "        sanitize   = _sanitize\n",
    "        use_llm    = self.config.use_llm\n",
    "        dataset    = []\n",
    "\n",
    "        for sample in tqdm(ds, desc=\"Building MATH reward-dataset\"):\n",
    "            # ── (1) extract step solutions ──────────────────────────────────────────\n",
    "            full_sol   = sample[\"solution\"]\n",
    "            m          = boxed_re.search(full_sol)\n",
    "            gold_ans   = sanitize(m.group(1)) if m else None\n",
    "            sol_wo_box = boxed_re.sub(\"\", full_sol)\n",
    "            raw_steps  = [s.strip() for s in sent_split.split(sol_wo_box) if s.strip()]\n",
    "            steps      = [f\"Step {i+1}: {s}\" for i, s in enumerate(raw_steps)]\n",
    "\n",
    "            # ── (2) compute rewards ───────────────────────────────────────────────────\n",
    "            ori = csr(sample[\"problem\"], rollout_prompt, steps, gold_ans)\n",
    "            ptb = psr(sample[\"problem\"], rollout_prompt, steps, gold_ans, use_llm)\n",
    "            if len(ptb) != len(ori):\n",
    "                ptb = ptb[: len(ori)]\n",
    "            contrib = [round(o - p, 4) for o, p in zip(ori, ptb)]\n",
    "\n",
    "            # ── (3) Append entry ───────────────────────────────────────────\n",
    "            entry = {\n",
    "                \"question\":      sample[\"problem\"],\n",
    "                \"completion\":    steps,\n",
    "                \"ori_rewards\":   ori,\n",
    "                \"ptb_rewards\":   ptb,\n",
    "                \"contributions\": contrib,\n",
    "                \"answer\":        gold_ans,\n",
    "                \"gold_answer\":   gold_ans,\n",
    "                \"level\":         sample[\"level\"],\n",
    "                \"type\":          sample[\"type\"],\n",
    "            }\n",
    "            dataset.append(entry)\n",
    "            print(entry)\n",
    "        return dataset\n",
    "\n",
    "    def _sequence_nll(self, prompt: str, target: str) -> float:\n",
    "        with torch.no_grad():\n",
    "            full = prompt + target\n",
    "            inputs = tokenizer(full, return_tensors=\"pt\").to(device)\n",
    "            prompt_len = len(tokenizer(prompt)[\"input_ids\"])\n",
    "            \n",
    "            # Mask out the prompt tokens so loss is only on the target\n",
    "            labels = inputs[\"input_ids\"].clone()\n",
    "            labels[:, :prompt_len] = -100          # ignore index\n",
    "            logits = model(**inputs).logits\n",
    "            loss   = F.cross_entropy(\n",
    "                        logits.view(-1, logits.size(-1)),\n",
    "                        labels.view(-1),\n",
    "                        reduction=\"none\"\n",
    "                    )\n",
    "            # keep only target positions\n",
    "            target_loss = loss[labels.view(-1) != -100]\n",
    "            return (target_loss.sum() / torch.log(torch.tensor(2.0))).item()  # bits\n",
    "        \n",
    "    def _info_gain(self, context, step, answer):\n",
    "        no_step = self._sequence_nll(context, answer)\n",
    "        with_step = self._sequence_nll(context + step, answer)\n",
    "        return no_step - with_step\n",
    "\n",
    "    def _step_entropy(self, context, step):\n",
    "        \"\"\"Cross-entropy of a step sequence (bits).\"\"\"\n",
    "        return self._sequence_nll(context, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "# MODEL_NAME = \"Qwen/Qwen1.5-7B-Chat\"      # or your qwen2.5-math-7b path\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def sequence_nll_ver1(prompt: str, target: str) -> float:\n",
    "    \"\"\"Cross-entropy (in bits) of 'target' tokens given the 'prompt'.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        prefix, value = target.split(\"Answer:\")\n",
    "        ans_prefix, ans_value = \"Answer: \", value.lstrip()\n",
    "        prompt = prompt + ans_prefix\n",
    "        full = prompt + ans_value\n",
    "\n",
    "        # full = prompt + target\n",
    "        inputs = tokenizer(full, return_tensors=\"pt\").to(device)\n",
    "        prompt_len = len(tokenizer(prompt)[\"input_ids\"])\n",
    "        \n",
    "        # Mask out the prompt tokens so loss is only on the target\n",
    "        labels = inputs[\"input_ids\"].clone()\n",
    "        labels[:, :prompt_len] = -100          # ignore index\n",
    "        \n",
    "        # 디버그: 정답 부분만 확인\n",
    "        answer_part = labels[0, prompt_len:]\n",
    "        valid_tokens = answer_part[answer_part != -100]\n",
    "        print(f\"Answer tokens: {tokenizer.decode(valid_tokens)}\")\n",
    "        print(f\"Answer token count: {len(valid_tokens)}\")\n",
    "        \n",
    "        logits = model(**inputs).logits\n",
    "        loss   = F.cross_entropy(\n",
    "                    logits.view(-1, logits.size(-1)),\n",
    "                    labels.view(-1),\n",
    "                    reduction=\"none\"\n",
    "                 )\n",
    "        # keep only target positions\n",
    "        target_loss = loss[labels.view(-1) != -100]\n",
    "        print(f\"Per-token losses: {target_loss.tolist()}\")\n",
    "\n",
    "        for i, tok_id in enumerate(valid_tokens):\n",
    "            tok = tokenizer.decode([tok_id])\n",
    "            prob = torch.softmax(logits[0, -len(valid_tokens)+i], dim=-1)[tok_id].item()\n",
    "            print(f\"{tok!r}  p={prob:.3e},  -ln p={-math.log(prob):.3f}\")\n",
    "\n",
    "        return (target_loss.sum() / torch.log(torch.tensor(2.0))).item()  # bits\n",
    "\n",
    "def sequence_nll(prompt: str, target: str):\n",
    "    \"\"\"NLL(bits) of `target` given `prompt`. The prompt **does not** contain the target portion.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        prefix, value = target.split(\"Answer:\")\n",
    "        ans_prefix, ans_value = \"Answer: \", value.lstrip()\n",
    "        prompt = prompt + ans_prefix\n",
    "        full = prompt + ans_value\n",
    "        # full = prompt + target\n",
    "        full_ids    = tokenizer(full, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "        prompt_len  = len(tokenizer(prompt, add_special_tokens=False)[\"input_ids\"])\n",
    "\n",
    "        labels = full_ids.clone()\n",
    "        labels[:, :prompt_len] = -100          # ignore prompt tokens\n",
    "\n",
    "        logits = model(full_ids).logits\n",
    "        loss   = F.cross_entropy(\n",
    "                    logits.view(-1, logits.size(-1)),\n",
    "                    labels.view(-1),\n",
    "                    reduction=\"sum\"             # total bits, not mean\n",
    "                 ) / math.log(2)                # nats → bits\n",
    "        return loss.item()\n",
    "\n",
    "def info_gain(context, step, answer):\n",
    "    \"\"\"I(S;A|c) = H(A|c) - H(A|c,S).\"\"\"\n",
    "    no_step = sequence_nll(context, answer)\n",
    "    with_step = sequence_nll(context + step, answer)\n",
    "    return no_step - with_step\n",
    "\n",
    "def step_entropy(context, step):\n",
    "    \"\"\"Cross-entropy of a step sequence (bits).\"\"\"\n",
    "    return sequence_nll(context, step)\n",
    "\n",
    "def show_topk(prompt, k=5):\n",
    "    ids = tokenizer(prompt, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        logits = model(ids).logits[0, -1]\n",
    "    probs, idx = torch.topk(torch.softmax(logits, dim=-1), k)\n",
    "    print([ (tokenizer.decode([i]), float(p)) for p,i in zip(probs, idx) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(Answer|context) ≈ 25.375 bits\n",
      "H(Answer|context+Step1) ≈ 28.5 bits\n",
      "H(Answer|context+Step1+Step2) ≈ 30.875 bits\n",
      "H(Answer|context+Step1+Step2+Step3) ≈ 25.25 bits\n",
      "Information gain of Step1: -3.125 bits\n",
      "Information gain of Step2: -2.375 bits\n",
      "Information gain of Step3: 5.625 bits\n"
     ]
    }
   ],
   "source": [
    "# context = \"\"\"Solve the given problem with step by step reasoning and write final answer in the format of \"Answer: <answer>\". Problem: What is the sum of the digits of the number 84?\\n\"\"\"\n",
    "# step1   = \"Step 1: The tens digit of 84 is 8.\\n\"\n",
    "# step2   = \"Step 2: The ones digit of 84 is 4.\\n\"\n",
    "# step3   = \"Step 3: Add the digits: 8 + 4 = 12.\\n\"\n",
    "# answer  = \"\\nAnswer:\\n12\"\n",
    "\n",
    "context = \"\"\"Solve the given problem with step by step reasoning and write final answer in the format of \"Answer: <answer>\". Problem: What is (5 + 3) × 2 - 4?\\n\"\"\"\n",
    "step1   = \"Step 1: Compute inside the parentheses first: 5 + 3 = 8.\\n\"\n",
    "step2   = \"Step 2: Multiply the result by 2: 8 × 2 = 16.\\n\"\n",
    "step3   = \"Step 3: Subtract 4: 16 - 4 = 12.\\n\"\n",
    "# step3   = \"Step 3: What should I do next?\\n\"\n",
    "answer  = \"Answer: 12\"\n",
    "\n",
    "# context = \"\"\"Solve the given problem with step by step reasoning and write final answer in the format of \"Answer: <answer>\". Problem: What is 1/2 + 1/4 + 1/4?\\n\"\"\"\n",
    "# step1   = \"Step 1: Add 1/4 and 1/4 first: 1/4 + 1/4 = 1/2.\\n\"\n",
    "# step2   = \"Step 2: Now add 1/2 + 1/2 = 1.\\n\"\n",
    "# step3   = \"Step 3: Final result is 1.\\n\"\n",
    "# answer  = \"Answer: 1\"\n",
    "\n",
    "# print(\"Answer tokenized:\", tokenizer.tokenize(answer))\n",
    "# print(\"Answer IDs:\", tokenizer.encode(answer, add_special_tokens=False))\n",
    "# show_topk(context)                  # before any step\n",
    "# show_topk(context + step1)          # after Step 1\n",
    "# show_topk(context + step1 + step2)  # etc.\n",
    "# show_topk(context + step1 + step2 + step3) \n",
    "\n",
    "print(\"H(Answer|context) ≈\", step_entropy(context, answer), \"bits\")\n",
    "print(\"H(Answer|context+Step1) ≈\", step_entropy(context + step1, answer), \"bits\")\n",
    "print(\"H(Answer|context+Step1+Step2) ≈\", step_entropy(context + step1 + step2, answer), \"bits\")\n",
    "print(\"H(Answer|context+Step1+Step2+Step3) ≈\", step_entropy(context + step1 + step2 + step3, answer), \"bits\")\n",
    "print(\"Information gain of Step1:\", info_gain(context, step1, answer), \"bits\")\n",
    "print(\"Information gain of Step2:\", info_gain(context + step1, step2, answer), \"bits\")\n",
    "print(\"Information gain of Step3:\", info_gain(context + step1 + step2, step3, answer), \"bits\")\n",
    "\n",
    "# prompt_ids = tokenizer(context + step1 + step2, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "# out = model.generate(\n",
    "#         prompt_ids,\n",
    "#         max_new_tokens=30,\n",
    "#         return_dict_in_generate=True,\n",
    "#         output_scores=True,\n",
    "#         temperature=0.2,     # deterministic\n",
    "#         do_sample=True\n",
    "#      )\n",
    "\n",
    "# gen_ids   = out.sequences[0, prompt_ids.size(-1):]  # 생성된 부분\n",
    "# scores    = out.scores                              # 길이 = #gen_tokens\n",
    "\n",
    "# # 토큰별 −log2 p 계산\n",
    "# nll_bits = 0.0\n",
    "# for t, (logits, tok_id) in enumerate(zip(scores, gen_ids)):\n",
    "#     probs = logits.squeeze(0).softmax(dim=-1)\n",
    "#     tok_id = tok_id.item()\n",
    "#     p     = probs[tok_id].item()\n",
    "#     nll_bits += -math.log2(p)\n",
    "#     print(f\"{t:02d}  {tokenizer.decode([tok_id])}  p={p:.3e}  −log2 p={-math.log2(p):.3f}\")\n",
    "\n",
    "# print(f\"Total NLL(bits) for generated segment = {nll_bits:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(A|c)        = 16.8074 bits\n",
      "H(A|c,S1)     = 20.7748 bits   →  I(S1;A|c) = -3.9674 bits\n",
      "H(A|c,S1,S2)  = 16.3746 bits   →  I(S2;A|c,S1) = 4.4002 bits (increment)\n",
      "H(A|c,S1,S2,S3)= 18.2501 bits   →  I(S3;A|c,S1,S2)= -1.8755 bits\n"
     ]
    }
   ],
   "source": [
    "def nll_bits(prompt: str, target: str) -> float:\n",
    "    \"\"\"Average NLL of 'target' given 'prompt', in **bits** per target token.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        full   = prompt + target\n",
    "        inputs = tokenizer(full, return_tensors=\"pt\").to(device)\n",
    "        Lp     = len(tokenizer(prompt)[\"input_ids\"])\n",
    "\n",
    "        labels = inputs[\"input_ids\"].clone()\n",
    "        labels[:, :Lp] = -100          # ignore prompt tokens\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            labels.view(-1),\n",
    "            reduction=\"sum\"            # total nll (nats)\n",
    "        )\n",
    "        ntoks = (labels != -100).sum()\n",
    "        nll_nats = loss.item() / ntoks\n",
    "        return nll_nats / math.log(2)  # nats → bits\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "context = \"Solve the given problem with step by step reasoning and write final answer in the format of \\\"Answer: <answer>\\\". Problem: What is (5 + 3) × 2 - 4?\\n\"\n",
    "step1   = \"Step 1: Compute inside the parentheses first: 5 + 3 = 8.\\n\"\n",
    "step2   = \"Step 2: Multiply the result by 2: 8 × 2 = 10.\\n\"\n",
    "step3   = \"Step 3: Subtract 4: 10 - 4 = 6.\\n\"\n",
    "answer  = \"Answer: 12\"\n",
    "\n",
    "# 1) 엔트로피(=평균 NLL) 계산\n",
    "nll0 = nll_bits(context, answer)\n",
    "nll1 = nll_bits(context + step1,                 answer)\n",
    "nll2 = nll_bits(context + step1 + step2,         answer)\n",
    "nll3 = nll_bits(context + step1 + step2 + step3, answer)\n",
    "\n",
    "# 2) mutual information\n",
    "mi1 = nll0 - nll1\n",
    "mi2 = nll1 - nll2\n",
    "mi3 = nll2 - nll3\n",
    "\n",
    "print(f\"H(A|c)        = {nll0:.4f} bits\")\n",
    "print(f\"H(A|c,S1)     = {nll1:.4f} bits   →  I(S1;A|c) = {mi1:.4f} bits\")\n",
    "print(f\"H(A|c,S1,S2)  = {nll2:.4f} bits   →  I(S2;A|c,S1) = {mi2:.4f} bits (increment)\")\n",
    "print(f\"H(A|c,S1,S2,S3)= {nll3:.4f} bits   →  I(S3;A|c,S1,S2)= {mi3:.4f} bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Monte-Carlo (k=5) ===\n",
      "H(A|c)          = 0.6414 bits\n",
      "H(A|c,S1)       = 0.0133 bits   →  I(S1;A|c)          = +0.6282\n",
      "H(A|c,S1,S2)    = 0.4116 bits   →  ΔI(S2|prev)        = -0.3983\n",
      "H(A|c,S1,S2,S3) = 0.1660 bits   →  ΔI(S3|prev)        = +0.2455\n",
      "\n",
      "=== Exact token-entropy ===\n",
      "H(A|c)          = 1.2748 bits\n",
      "H(A|c,S1)       = 0.7583 bits   →  I(S1;A|c)          = +0.5165\n",
      "H(A|c,S1,S2)    = 0.7090 bits   →  ΔI(S2|prev)        = +0.0492\n",
      "H(A|c,S1,S2,S3) = 0.5144 bits   →  ΔI(S3|prev)        = +0.1946\n"
     ]
    }
   ],
   "source": [
    "import math, torch, random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "LOG2E = 1 / math.log(2)\n",
    "\n",
    "# ─────────────────────── 1. 기본 NLL 함수 ─────────────────────\n",
    "def nll_bits(prompt: str, target: str, avg=True) -> float:\n",
    "    \"\"\"\n",
    "    NLL(prompt→target) in bits.\n",
    "    If avg=True, return *average* bits / target-token,\n",
    "    else return *total* bits of the sequence.\n",
    "    \"\"\"\n",
    "    full   = prompt + target\n",
    "    inputs = tokenizer(full, return_tensors=\"pt\").to(device)\n",
    "    Lp     = len(tokenizer(prompt)[\"input_ids\"])\n",
    "\n",
    "    labels = inputs[\"input_ids\"].clone()\n",
    "    labels[:, :Lp] = -100\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            labels.view(-1),\n",
    "            reduction=\"sum\"          # total nats\n",
    "        )\n",
    "    ntoks = (labels != -100).sum()\n",
    "    bits  = loss.item() * LOG2E      # total bits\n",
    "    return bits / ntoks if avg else bits\n",
    "\n",
    "# ─────────────────────── 2-A. MC Sampling 방식 ─────────────────────\n",
    "def entropy_bits_mc(prompt: str, k: int = 5, max_new: int = 4, temperature: float = 0.7, top_p: float = 0.9) -> float:\n",
    "    \"\"\"\n",
    "    Monte-Carlo estimate of H(A|prompt) [bits per token].\n",
    "    Generates k continuations, then 평균[-log₂ p(sample | prompt)].\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device).input_ids\n",
    "    BITS = []\n",
    "    for _ in range(k):\n",
    "        out_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )[0][input_ids.size(1):]           # strip prompt\n",
    "\n",
    "        sample = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
    "        BITS.append(entropy_bits_exact(prompt, sample))\n",
    "    return sum(BITS) / k                  # bits/token\n",
    "\n",
    "# ─────────────────────── 2-B. Exact 토큰-엔트로피 ─────────────────────\n",
    "def entropy_bits_exact(prompt: str, target: str) -> float:\n",
    "    \"\"\"True H(A|prompt) in bits/token, by ∑_t H(p_t). Memory-intensive: stores full probs tensor.\"\"\"\n",
    "    full   = prompt + target\n",
    "    inputs = tokenizer(full, return_tensors=\"pt\").to(device)\n",
    "    Lp     = len(tokenizer(prompt)[\"input_ids\"])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits.float()      # [1,L,V]\n",
    "\n",
    "    probs = logits.softmax(-1)                      # [...,V]\n",
    "    token_H = -(probs * probs.log()).sum(-1) * LOG2E  # bits/token\n",
    "\n",
    "    mask = torch.zeros_like(inputs[\"input_ids\"], dtype=torch.bool)\n",
    "    mask[:, Lp:] = True                             # answer tokens\n",
    "    return token_H[mask].sum().item() / mask.sum().item()\n",
    "\n",
    "# ─────────────────────── 3. 프롬프트 정의 ─────────────────────\n",
    "context = \"\"\"Solve the given problem with step by step reasoning in the format of \"Step k: <k-th rationale>\" and write final answer in the format of \"Answer: <answer>\". Problem: What is the sum of the digits of the number 84?\\n\"\"\"\n",
    "step1   = \"Step 1: The tens digit of 84 is 8.\\n\"\n",
    "step2   = \"Step 2: The ones digit of 84 is 4.\\n\"\n",
    "step3   = \"Step 3: Add the digits: 8 + 4 = 12.\\n\"\n",
    "answer  = \"Answer: 12\"\n",
    "\n",
    "# ─────────────────────── 4. 엔트로피 & MI 계산 ─────────────────────\n",
    "def mi_report(entropy_fn, label: str):\n",
    "    H0 = entropy_fn(context,                  answer)            # H(A|c)\n",
    "    H1 = entropy_fn(context+step1,            answer)            # H(A|c,S1)\n",
    "    H2 = entropy_fn(context+step1+step2,      answer)            # H(A|c,S1,S2)\n",
    "    H3 = entropy_fn(context+step1+step2+step3,answer)            # ...\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    print(f\"H(A|c)          = {H0:.4f} bits\")\n",
    "    print(f\"H(A|c,S1)       = {H1:.4f} bits   →  I(S1;A|c)          = {H0-H1:+.4f}\")\n",
    "    print(f\"H(A|c,S1,S2)    = {H2:.4f} bits   →  ΔI(S2|prev)        = {H1-H2:+.4f}\")\n",
    "    print(f\"H(A|c,S1,S2,S3) = {H3:.4f} bits   →  ΔI(S3|prev)        = {H2-H3:+.4f}\")\n",
    "\n",
    "# 4-A. MC 샘플링 (k 줄이려면 30~50 도 OK)\n",
    "mi_report(lambda p,t: entropy_bits_mc(p), \"Monte-Carlo (k=5)\")\n",
    "\n",
    "# 4-B. Exact  (target이 2-토큰이므로 메모리 부담 ↓)\n",
    "mi_report(entropy_bits_exact, \"Exact token-entropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: I want to find the largest positive integer that divides both $20 !$ and $200,\\!000$ evenly.\n",
      "Step 2: One way to do this is to factor both numbers into prime factors and look for the common ones.\n",
      "Step 3: I know that $200,\\!000 = 2^5\\cdot 10^4 = 2^9\\cdot 5^4$.\n",
      "Step 4: To find the prime factorization of $20 !$, I can use the fact that it is the product of all the positive integers from $1$ to $20$.\n",
      "Step 5: For each prime number $p$ between $1$ and $20$, I can count how many multiples of $p$ are in that range.\n",
      "Step 6: For example, there are $10$ multiples of $2$ between $1$ and $20$, namely $2, 4, 6, \\dots, 20$.\n",
      "Step 7: But there are also $5$ multiples of $4$, which is $2^2$, and $2$ multiples of $8$, which is $2^3$, and $1$ multiple of $16$, which is $2^4$.\n",
      "Step 8: So, the total power of $2$ in $20 !$ is $10 + 5 + 2 + 1 = 18$.\n",
      "Step 9: Similarly, there are $4$ multiples of $5$, namely $5, 10, 15, 20$, so the power of $5$ in $20 !$ is $4$.\n",
      "Step 10: There are $6$ multiples of $3$, namely $3, 6, 9, \\dots, 18$, but there are also $2$ multiples of $9$, which is $3^2$, so the power of $3$ in $20 !$ is $6 + 2 = 8$.\n",
      "Step 11: There are $2$ multiples of $7$, namely $7$ and $14$, so the power of $7$ in $20 !$ is $2$.\n",
      "Step 12: There are $1$ multiple of each of the other prime numbers $11, 13, 17$, and $19$, so the powers of those primes in $20 !$ are $1$ each.\n",
      "Step 13: Therefore, the prime factorization of $20 !$ is $2^{18}\\cdot 3^8\\cdot 5^4\\cdot 7^2\\cdot 11\\cdot 13\\cdot 17\\cdot 19$.\n",
      "Step 14: To find the greatest common factor of $20 !$ and $200,\\!000$, I need to take the lowest power of each common prime factor.\n",
      "Step 15: The only common prime factors are $2$ and $5$, and the lowest powers are $9$ and $4$, respectively.\n",
      "Step 16: So, the greatest common factor is $2^9\\cdot 5^4 = 512\\cdot 625 = 320,\\!000$.\n",
      "\n",
      "# Answer\n",
      "\n",
      "320,000\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"Solve the given problem with step by step reasoning and write final answer in the format of \"Answer: <answer>\". Probelm: What is the greatest common factor of $20 !$ and $200,\\\\!000$?  (Reminder: If $n$ is a positive integer, then $n!$ stands for the product $1\\\\cdot 2\\\\cdot 3\\\\cdot \\\\cdots \\\\cdot (n-1)\\\\cdot n$.)\"\"\"\n",
    "steps = [\n",
    "      \"I want to find the largest positive integer that divides both $20 !$ and $200,\\\\!000$ evenly.\",\n",
    "      \"One way to do this is to factor both numbers into prime factors and look for the common ones.\",\n",
    "      \"I know that $200,\\\\!000 = 2^5\\\\cdot 10^4 = 2^9\\\\cdot 5^4$.\",\n",
    "      \"To find the prime factorization of $20 !$, I can use the fact that it is the product of all the positive integers from $1$ to $20$.\",\n",
    "      \"For each prime number $p$ between $1$ and $20$, I can count how many multiples of $p$ are in that range.\",\n",
    "      \"For example, there are $10$ multiples of $2$ between $1$ and $20$, namely $2, 4, 6, \\\\dots, 20$.\",\n",
    "      \"But there are also $5$ multiples of $4$, which is $2^2$, and $2$ multiples of $8$, which is $2^3$, and $1$ multiple of $16$, which is $2^4$.\",\n",
    "      \"So, the total power of $2$ in $20 !$ is $10 + 5 + 2 + 1 = 18$.\",\n",
    "      \"Similarly, there are $4$ multiples of $5$, namely $5, 10, 15, 20$, so the power of $5$ in $20 !$ is $4$.\",\n",
    "      \"There are $6$ multiples of $3$, namely $3, 6, 9, \\\\dots, 18$, but there are also $2$ multiples of $9$, which is $3^2$, so the power of $3$ in $20 !$ is $6 + 2 = 8$.\",\n",
    "      \"There are $2$ multiples of $7$, namely $7$ and $14$, so the power of $7$ in $20 !$ is $2$.\",\n",
    "      \"There are $1$ multiple of each of the other prime numbers $11, 13, 17$, and $19$, so the powers of those primes in $20 !$ are $1$ each.\",\n",
    "      \"Therefore, the prime factorization of $20 !$ is $2^{18}\\\\cdot 3^8\\\\cdot 5^4\\\\cdot 7^2\\\\cdot 11\\\\cdot 13\\\\cdot 17\\\\cdot 19$.\",\n",
    "      \"To find the greatest common factor of $20 !$ and $200,\\\\!000$, I need to take the lowest power of each common prime factor.\",\n",
    "      \"The only common prime factors are $2$ and $5$, and the lowest powers are $9$ and $4$, respectively.\",\n",
    "      \"So, the greatest common factor is $2^9\\\\cdot 5^4 = 512\\\\cdot 625 = 320,\\\\!000$.\\n\\n# Answer\\n\\n320,000\"\n",
    "    ]\n",
    "\n",
    "num_steps = []\n",
    "for i, step in enumerate(steps):\n",
    "    numbering = f\"Step {i+1}: \" + step\n",
    "    num_steps.append(numbering)\n",
    "\n",
    "for idx in range(len(num_steps)):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOG2E = torch.log2(torch.tensor(2.718281828459045))\n",
    "\n",
    "def next_token_probs(prompt: str, temperature: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"softmax(logits/τ) over the full vocab, shape (|V|,)\"\"\"\n",
    "    ids = tokenizer(prompt, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        logits = model(ids).logits[0, -1] / temperature\n",
    "    return torch.softmax(logits.float(), dim=-1)          # full-vocab probs\n",
    "\n",
    "def info_gain_kl(context: str, step: str, temperature: float = 1.0) -> float:\n",
    "    \"\"\" I≈KL( P(·|c,step) || P(·|c) ) measured on the distribution of the *first* next token (Answer: 직후). 결과 단위: bits \"\"\"\n",
    "    p = next_token_probs(context, temperature)\n",
    "    q = next_token_probs(context + step, temperature)\n",
    "\n",
    "    kl_nat = torch.sum(q * (q.log() - p.log()))           # nats\n",
    "    kl_bits = (kl_nat / _LOG2E).item()                    # convert nats→bits\n",
    "    return kl_bits                                        # ≥ 0 by definition\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) Monte-Carlo 샘플링 기반 정보 이득  (엔트로피 근사)\n",
    "# ---------------------------------------------------------------------\n",
    "def sequence_nll(prompt: str, target: str) -> float:\n",
    "    \"\"\" Cross-entropy (bits) of `target` given `prompt`.\"\"\"\n",
    "    full = prompt + target\n",
    "    inputs = tokenizer(full, return_tensors=\"pt\").to(device)\n",
    "    p_len  = len(tokenizer(prompt)[\"input_ids\"])\n",
    "\n",
    "    labels = inputs[\"input_ids\"].clone()\n",
    "    labels[:, :p_len] = -100                      # ignore prompt tokens\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        loss   = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), reduction=\"none\")\n",
    "    target_loss = loss[labels.view(-1) != -100]\n",
    "    return (target_loss.sum() / torch.log(torch.tensor(2.0))).item()  # bits\n",
    "\n",
    "def sample_answers(prompt: str,\n",
    "                   k: int = 8,\n",
    "                   max_new_tokens: int = 56,\n",
    "                   temperature: float = 0.8) -> list[str]:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=temperature,\n",
    "                top_p=0.9,\n",
    "                num_return_sequences=k,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "              )\n",
    "    # 잘라서 답변 부분만 디코딩\n",
    "    answer_tokens = outs[:, inputs[\"input_ids\"].shape[1]:]\n",
    "    return tokenizer.batch_decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "def entropy_mc(prompt: str, k: int = 16, max_new_tokens: int = 32, temperature: float = 0.8) -> float:\n",
    "    \"\"\"Monte-Carlo estimate of H(A|prompt) in bits.\"\"\"\n",
    "    samples = sample_answers(prompt, k, max_new_tokens, temperature)\n",
    "    nlls = [sequence_nll(prompt, ans) for ans in samples]\n",
    "    return sum(nlls) / len(nlls)\n",
    "\n",
    "def info_gain_mc(context: str, step: str, k: int = 16, max_new_tokens: int = 32, temperature: float = 0.8) -> float:\n",
    "    \"\"\" I ≈ Ĥ(A|c) – Ĥ(A|c,step) via MC sampling. 단위 bits (양수가 정보 이득, 음수면 정보 손실) \"\"\"\n",
    "    h_no  = entropy_mc(context, k, max_new_tokens, temperature)\n",
    "    h_yes = entropy_mc(context + step, k, max_new_tokens, temperature)\n",
    "    return h_no - h_yes\n",
    "\n",
    "def answer_token(prompt: str) -> int:\n",
    "    \"\"\"\n",
    "    returns token id of the *first* token the model produces right after 'Answer:'.\n",
    "    여기선 숫자 한 글자(예: '12' → 'Ġ12' 토큰)라고 가정.\n",
    "    \"\"\"\n",
    "    # 'Answer:' 까지 디코딩 후 generate 1토큰\n",
    "    ids = tokenizer(prompt, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(ids, max_new_tokens=1, do_sample=False)   # greedy\n",
    "    return int(out[0, -1])\n",
    "\n",
    "def info_gain_answer_kl(context: str,step: str, correct_answer: str, temperature: float = 1.0) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    (1) KL over full vocab  (≥0)\n",
    "    (2) Δ log2-prob of *gold answer token*  (= contribution sign)\n",
    "    \"\"\"\n",
    "    # 준비: Answer:  프롬프트\n",
    "    base = context + \"Answer:\"\n",
    "    base_with = context + step + \"Answer:\"\n",
    "\n",
    "    # 전체 분포\n",
    "    p = next_token_probs(base, temperature)      # (|V|)\n",
    "    q = next_token_probs(base_with, temperature)\n",
    "\n",
    "    # 1) KL  (nats→bits)\n",
    "    kl_bits = torch.sum(q * (q.log() - p.log())) / _LOG2E\n",
    "\n",
    "    # 2) 정답 토큰 확률 변화\n",
    "    # gold_id = answer_token(base)                 # 모델이 '정답'이라고 보는 토큰\n",
    "    # delta_log2 = (q[gold_id].log2() - p[gold_id].log2()).item()\n",
    "\n",
    "    gold_id = tokenizer(correct_answer, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    delta_log2 = (q[gold_id].log2() - p[gold_id].log2()).item()\n",
    "\n",
    "    return kl_bits.item(), delta_log2\n",
    "\n",
    "\n",
    "def kl_and_delta_nll(context: str, step: str, answer: str, temperature: float = 1.0) -> tuple[float, float]:\n",
    "    \"\"\"Returns (KL_bits_full_answer , Δ-NLL_bits_full_answer)\n",
    "    • KL = Σ_t  KL( p_with(·|prefix_t) || p_no(·|prefix_t) ) ≥ 0\n",
    "    • Δ-NLL =  NLL_no − NLL_with   (정답 확률 ↑ → 양수)\"\"\"\n",
    "    # pre-encode once to speed up\n",
    "    prompt_no   = context + \"Answer:\"\n",
    "    prompt_with = context + step + \"Answer:\"\n",
    "    ans_ids     = tokenizer(answer, return_tensors=\"pt\").to(device)[\"input_ids\"][0]     # (T,)\n",
    "\n",
    "    # holders\n",
    "    total_kl_nat   = 0.0\n",
    "    total_dlog2    = 0.0            # Δ-log2P over the whole answer\n",
    "\n",
    "    # build running prefixes for with / no prompts\n",
    "    ids_no   = tokenizer(prompt_no,   return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "    ids_with = tokenizer(prompt_with, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "\n",
    "    for next_id in ans_ids:          # iterate over answer tokens\n",
    "        with torch.no_grad():\n",
    "            # logits for next token distribution\n",
    "            logit_no   = model(ids_no).logits[0, -1] / temperature\n",
    "            logit_with = model(ids_with).logits[0, -1] / temperature\n",
    "\n",
    "        p_with = torch.softmax(logit_with.float(), dim=-1)            # (|V|)\n",
    "        p_no   = torch.softmax(logit_no.float(),   dim=-1)\n",
    "\n",
    "        # ----- KL( p_with || p_no )  (using p_with as 'true' dist) -----\n",
    "        kl_nat = torch.sum(p_with * (torch.log(p_with) - torch.log(p_no)))\n",
    "        total_kl_nat += kl_nat.item()\n",
    "\n",
    "        # ----- Δ log2 P(next_id)  (direction) -----\n",
    "        log2_with = ( torch.log(p_with[next_id]).item() ) / _LOG2E\n",
    "        log2_no   = ( torch.log(p_no  [next_id]).item() ) / _LOG2E\n",
    "        total_dlog2 += (log2_with - log2_no)          # >0 ⇒ 정답 확률↑\n",
    "\n",
    "        # teacher-force next_id into both prefixes\n",
    "        ids_no   = torch.cat([ids_no,   next_id.view(1,1)], dim=1)\n",
    "        ids_with = torch.cat([ids_with, next_id.view(1,1)], dim=1)\n",
    "\n",
    "    kl_bits   = total_kl_nat / _LOG2E           # nats→bits\n",
    "    delta_nll = -total_dlog2                  # NLL_no − NLL_with  (bits)\n",
    "\n",
    "    return kl_bits, delta_nll                 # (≥0 , ±)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step1: KL= 1.770 bits,  Δ-NLL=+3.046 bits (↑⇒help)\n",
      "Step2: KL= 4.294 bits,  Δ-NLL=-3.089 bits (↓⇒hurt)\n",
      "Step3: KL= 0.458 bits,  Δ-NLL=+1.046 bits (↑⇒help)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step1 KL=0.483, Δlog₂P(ans)=+0.288\n",
      "Step2 KL=0.221, Δlog₂P(ans)=+0.023\n",
      "Step3 KL=0.373, Δlog₂P(ans)=-0.752\n"
     ]
    }
   ],
   "source": [
    "# context = \"Problem: What is (5 + 3) × 2 - 4?\\n\\n\"\n",
    "# step1   = \"Step 1: Compute inside the parentheses first: 5 + 3 = 8.\\n\"\n",
    "# step2   = \"Step 2: Multiply the result by 2: 8 × 2 = 16.\\n\"\n",
    "# step3   = \"Step 3: Subtract 4: 16 - 4 = 12.\\n\"\n",
    "# answer  = \"Answer: 12.\"\n",
    "\n",
    "context = \"Problem: What is 1/2 + 1/4 + 1/4?\\n\\n\"\n",
    "step1   = \"Step 1: Add 1/4 and 1/4 first: 1/4 + 1/4 = 1/2.\\n\"\n",
    "step2   = \"Step 2: Now add 1/2 + 1/2 = 1.\\n\"\n",
    "step3   = \"Step 3: All sum of the proabability is 1.\\n\"\n",
    "answer  = \" 1.\"\n",
    "\n",
    "# context = \"Problem: What is the sum of the digits of the number 84?\\n\\n\"\n",
    "# step1   = \"Step 1: The tens digit of 84 is 8.\\n\"\n",
    "# step2   = \"Step 2: The ones digit of 84 is 4.\\n\"\n",
    "# step3   = \"Step 3: The subtraction of 8-4 is 4.\\n\"\n",
    "# step4   = \"Step 4: Add the digits: 8 + 4 = 12.\\n\"\n",
    "# answer  = \" 12.\"\n",
    "\n",
    "\n",
    "for i,(s,ctx) in enumerate([(step1, context),\n",
    "                            (step2, context+step1),\n",
    "                            (step3, context+step1+step2),\n",
    "                            # (step4, context+step1+step2+step3)\n",
    "                            ], 1):\n",
    "    kl, dnll = kl_and_delta_nll(ctx, s, answer)\n",
    "    sign = \"↑\" if dnll>0 else \"↓\"\n",
    "    print(f\"Step{i}: KL={kl:6.3f} bits,  Δ-NLL={dnll:+6.3f} bits ({sign}⇒{'help' if dnll>0 else 'hurt'})\")\n",
    "\n",
    "kl1, d1 = info_gain_answer_kl(context, step1)\n",
    "kl2, d2 = info_gain_answer_kl(context+step1, step2)\n",
    "kl3, d3 = info_gain_answer_kl(context+step1+step2, step3)\n",
    "# kl4, d4 = info_gain_answer_kl(context+step1+step2+step3, step4)\n",
    "\n",
    "print(f\"Step1 KL={kl1:.3f}, Δlog₂P(ans)={d1:+.3f}\")\n",
    "print(f\"Step2 KL={kl2:.3f}, Δlog₂P(ans)={d2:+.3f}\")\n",
    "print(f\"Step3 KL={kl3:.3f}, Δlog₂P(ans)={d3:+.3f}\")\n",
    "# print(f\"Step4 KL={kl4:.3f}, Δlog₂P(ans)={d4:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rectangle area (5 cm × 3 cm) ===\n",
      "Step  1: KL=  2.52 bits,  Δ-NLL= -1.22 bits   hurt ❌\n",
      "Step  2: KL=  6.95 bits,  Δ-NLL= +5.48 bits   help ✅\n",
      "Step  3: KL=  3.25 bits,  Δ-NLL= -7.73 bits   hurt ❌\n",
      "→ Answer: 15 cm^2.\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Solve for x (3x + 9 = 18) ===\n",
      "Step  1: KL=  3.51 bits,  Δ-NLL= -1.52 bits   hurt ❌\n",
      "Step  2: KL=  1.56 bits,  Δ-NLL= +3.23 bits   help ✅\n",
      "Step  3: KL=  0.47 bits,  Δ-NLL= -3.28 bits   hurt ❌\n",
      "Step  4: KL=  4.04 bits,  Δ-NLL= -0.38 bits   hurt ❌\n",
      "→ Answer: 3.\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Prime factorization (60) ===\n",
      "Step  1: KL=  1.95 bits,  Δ-NLL= -4.33 bits   hurt ❌\n",
      "Step  2: KL=  0.82 bits,  Δ-NLL= +3.37 bits   help ✅\n",
      "Step  3: KL=  0.33 bits,  Δ-NLL= +1.60 bits   help ✅\n",
      "Step  4: KL=  0.86 bits,  Δ-NLL= -3.30 bits   hurt ❌\n",
      "Step  5: KL=  3.05 bits,  Δ-NLL= +3.88 bits   help ✅\n",
      "→ Answer: 2^2 × 3 × 5.\n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Simplify fraction (24/36) ===\n",
      "Step  1: KL=  1.54 bits,  Δ-NLL= -0.83 bits   hurt ❌\n",
      "Step  2: KL=  2.57 bits,  Δ-NLL= -3.89 bits   hurt ❌\n",
      "Step  3: KL=  1.30 bits,  Δ-NLL= +1.55 bits   help ✅\n",
      "Step  4: KL=  2.72 bits,  Δ-NLL= -0.41 bits   hurt ❌\n",
      "→ Answer: 2/3.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    # EXAMPLE 1  ──────────────────────────────────────────────────────────\n",
    "    # {\n",
    "    #     \"name\": \"Sum-of-digits (84)\",\n",
    "    #     \"context\": \"Problem: What is the sum of the digits of the number 84?\\n\\n\",\n",
    "    #     \"steps\": [\n",
    "    #         \"Step 1: The tens digit of 84 is 8.\\n\",                       # ✅\n",
    "    #         \"Step 2: The ones digit of 84 is 4.\\n\",                      # ✅\n",
    "    #         \"Step 3: The subtraction of 8-4 is 4.\\n\",                    # ❌ (irrelevant)\n",
    "    #         \"Step 4: Add the digits: 8 + 4 = 12.\\n\"                      # ✅\n",
    "    #     ],\n",
    "    #     \"answer\": \"Answer: 12.\"\n",
    "    # },\n",
    "    # EXAMPLE 2  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Rectangle area (5 cm × 3 cm)\",\n",
    "        \"context\": \"Problem: A rectangle has length 5 cm and width 3 cm. What is its area?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The area of a rectangle is length × width.\\n\",      # ✅\n",
    "            \"Step 2: Add the dimensions: 5 + 3 = 8.\\n\",                  # ❌ (wrong op)\n",
    "            \"Step 3: Multiply: 5 × 3 = 15 square centimetres.\\n\"         # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 15 cm^2.\"\n",
    "    },\n",
    "    # EXAMPLE 3  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Solve for x (3x + 9 = 18)\",\n",
    "        \"context\": \"Problem: Solve for x: 3x + 9 = 18.\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: Subtract 9 from both sides: 3x = 9.\\n\",             # ✅\n",
    "            \"Step 2: Divide both sides by 3: x = 3.\\n\",                  # ✅\n",
    "            \"Step 3: Check: 3(3) + 9 = 18, so x = 3 is correct.\\n\",      # ✅\n",
    "            \"Step 4: Therefore, x = 6.\\n\"                                # ❌ (contradict)\n",
    "        ],\n",
    "        \"answer\": \"Answer: 3.\"\n",
    "    },\n",
    "    # EXAMPLE 4  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Prime factorization (60)\",\n",
    "        \"context\": \"Problem: What is the prime factorization of 60?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: 60 = 6 × 10.\\n\",                                    # ✅\n",
    "            \"Step 2: 6 = 2 × 3.\\n\",                                      # ✅\n",
    "            \"Step 3: 10 = 2 × 5.\\n\",                                     # ✅\n",
    "            \"Step 4: So 60 = 2 × 2 × 3 × 5.\\n\",                          # ✅\n",
    "            \"Step 5: Combine two 2's into 4, so 60 = 4 × 3 × 5.\\n\"       # ❌ (not prime factors)\n",
    "        ],\n",
    "        \"answer\": \"Answer: 2^2 × 3 × 5.\"\n",
    "    },\n",
    "    # EXAMPLE 5  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Simplify fraction (24/36)\",\n",
    "        \"context\": \"Problem: Simplify the fraction 24/36.\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The GCD of 24 and 36 is 12.\\n\",                     # ✅\n",
    "            \"Step 2: Divide numerator by 6: 24 ÷ 6 = 4.\\n\",              # ❌ (wrong divisor)\n",
    "            \"Step 3: Divide numerator and denominator by 12: 24/12 = 2, 36/12 = 3.\\n\",  # ✅\n",
    "            \"Step 4: The simplified fraction is 2/3.\\n\"                 # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 2/3.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for ex in examples:\n",
    "    print(f\"\\n=== {ex['name']} ===\")\n",
    "    ctx = ex[\"context\"]\n",
    "    for idx, step in enumerate(ex[\"steps\"], 1):\n",
    "        kl, dnll = kl_and_delta_nll(ctx, step, ex[\"answer\"], 0.8)\n",
    "        label = \"help ✅\" if dnll > 0 else \"hurt ❌\"\n",
    "        print(f\"Step {idx:>2}: KL={kl:6.2f} bits,  Δ-NLL={dnll:+6.2f} bits   {label}\")\n",
    "        ctx += step  # 다음 스텝 컨텍스트에 누적\n",
    "\n",
    "    print(f\"→ {ex['answer']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mi perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88f8b31910b4ccbbec78a34c996e795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "\n",
    "model_name = \"mistralai/Mathstral-7B-v0.1\" # Qwen/QwQ-32B, mistralai/Mathstral-7B-v0.1, Qwen/Qwen2.5-Math-7B-Instruct\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,            # enable 4-bit (QLoRA-style) weights\n",
    "    bnb_4bit_quant_type=\"nf4\",    # NF4 gives the best accuracy for most LLMs\n",
    "    bnb_4bit_use_double_quant=True, # optional: second quantisation pass to save ~0.4 bits/param\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # faster matmuls on recent GPUs; fall back to float16 if needed\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",      # let Accelerate split layers across all visible GPUs\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=\"auto\",     # keeps non-linear layers in their original dtype\n",
    "    trust_remote_code=True  # Qwen models need their custom code\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRMConfig:\n",
    "    # MC config\n",
    "    model_name:             str = \"Qwen/Qwen2.5-Math-7B-Instruct\"    # \"Qwen/Qwen2.5-Math-7B\", \"Qwen/Qwen2.5-Math-7B-Instruct\" , \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\", \"meta-llama/Llama-3.1-8B\"\n",
    "    max_new_tokens:         int = 512\n",
    "    num_rollouts:           int = 8      \n",
    "    use_llm:                bool = True  # Use llm for masking\n",
    "    reward_type:            str = \"contri\"  # ori, contri, mi, naive, norm\n",
    "    # PRM Model config \n",
    "    hidden_size:        int = 512      # 256-1024 범위에서 적절\n",
    "    num_layers:         int = 3        # 2-4 범위에서 적절\n",
    "    dropout:            float = 0.2    # 0.1-0.3 범위에서 적절\n",
    "    # PRMTrainer config \n",
    "    batch_size:         int = 16       # 12 → 16으로 증가 (더 안정적)\n",
    "    learning_rate:      float = 3e-4   # 5e-4 → 3e-4로 감소 (더 안정적)\n",
    "    num_workers:        int = 4        # 적절\n",
    "    weight_decay:       float = 1e-2   # 적절\n",
    "    lr_scheduler:       str = \"cosine\" # 적절\n",
    "    dataset_size:       int = 0\n",
    "    warmup_steps:       int = 40       # 22 → 50으로 증가 (더 안정적)\n",
    "    grad_clip:          float = 1.0    # 적절\n",
    "    epochs:             int = 20       # 25 → 15로 감소 (early stopping 고려)\n",
    "    # Misc config\n",
    "    use_wandb:          bool = True\n",
    "    wandb_project:      str = \"mc_prm\"\n",
    "    run_name:           str = \"test_400_0715\"\n",
    "    checkpoint_dir:     str = \"./checkpoints/0715/contri\"\n",
    "    seed:               int = 42\n",
    "    # Inference config\n",
    "    num_candidates:     int = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sympy as sp\n",
    "import re\n",
    "from typing import Optional, List, Tuple\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from utils import system_prompt, _sanitize_enhanced, _numeric_equiv_enhanced, _extract_boxed_answer\n",
    "\n",
    "class MIReward:\n",
    "    ANSWER_PATTERN = re.compile(\n",
    "        r\"\"\"^[\\s>#*\\-]*          # optional markdown/bullet symbols\n",
    "            Answer               # word 'Answer'\n",
    "            \\s*[:.\\-]\\s*         # separator\n",
    "            (.+?)\\s*$            # capture everything after\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.MULTILINE | re.VERBOSE,\n",
    "    )\n",
    "    _ANSWER_RE = re.compile(r\"####\\s*(.+?)\\s*$\")\n",
    "    \n",
    "    def __init__(self, config: \"PRMConfig\", model, tokenizer):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    # Function to parse a solution text into steps and final answer.\n",
    "    def _extract_answer(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Try multiple heuristics / regexes to pull out an answer string.\"\"\"\n",
    "        match = self.ANSWER_PATTERN.search(text)\n",
    "        if match:\n",
    "            return _sanitize_enhanced(match.group(1))\n",
    "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "        if lines:\n",
    "            candidate = lines[-1]\n",
    "            if re.search(r\"\\d\", candidate):  # contains digit\n",
    "                return _sanitize_enhanced(candidate)\n",
    "        for line in reversed(text.splitlines()):\n",
    "            if line.strip().lower().startswith(\"answer\"):\n",
    "                return _sanitize_enhanced(line.split(\"Answer\", 1)[-1])\n",
    "        return None\n",
    "    \n",
    "    def entropy_bits_exact(self, prompt: str, target: str) -> float:\n",
    "        \"\"\"True H(A|prompt) in bits/token, by ∑_t H(p_t). Memory-intensive: stores full probs tensor.\"\"\"\n",
    "        LOG2E = 1 / math.log(2)\n",
    "        full   = prompt + target\n",
    "        inputs = self.tokenizer(full, return_tensors=\"pt\", add_special_tokens=False).to(self.device)\n",
    "        Lp     = len(self.tokenizer(prompt, add_special_tokens=False)[\"input_ids\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits.float()      # [1,L,V]\n",
    "\n",
    "        probs = logits.softmax(-1)                      # [...,V]\n",
    "        token_H = -(probs * probs.log()).sum(-1) * LOG2E  # bits/token\n",
    "\n",
    "        mask = torch.zeros_like(inputs[\"input_ids\"], dtype=torch.bool)\n",
    "        mask[:, Lp:] = True                             # answer tokens\n",
    "        return token_H[mask].sum().item() / mask.sum().item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _entropy_bits_total(self, prompt: str, target: str) -> Tuple[float, float, int]:\n",
    "        \"\"\"\n",
    "        Return (H_total_bits, H_bits_per_token, target_len) for H(A | prompt).\n",
    "        - H_total_bits: sum_t H(p_t) over target tokens, in bits\n",
    "        - H_bits_per_token: H_total_bits / target_len (0 if target_len==0)\n",
    "        - target_len: # of target tokens included in conditional entropy\n",
    "        \"\"\"\n",
    "        # Build the exact concatenated string used by the model\n",
    "        full = prompt + target\n",
    "        # Tokenize full (with specials) and target (NO specials so it matches suffix)\n",
    "        full_enc = self.tokenizer(full, return_tensors=\"pt\", add_special_tokens=True).to(self.device)\n",
    "        tgt_ids  = self.tokenizer(target, add_special_tokens=False)[\"input_ids\"]\n",
    "        L_full   = full_enc[\"input_ids\"].shape[1]\n",
    "        L_tgt    = len(tgt_ids)\n",
    "        if L_tgt == 0:\n",
    "            return 0.0, 0.0, 0\n",
    "        # Target token region is the suffix of FULL\n",
    "        Lp = L_full - L_tgt  # start idx of target tokens inside FULL\n",
    "        # Forward pass: logits [1, L, V]\n",
    "        logits = self.model(**full_enc).logits.float()\n",
    "        # H(p) = -sum_j p_j log p_j ; use log_softmax for stability\n",
    "        LOG2E = 1.0 / math.log(2.0)\n",
    "        H_bits_sum = 0.0\n",
    "        # Iterate only target time steps\n",
    "        for t in range(Lp, L_full):\n",
    "            lp = torch.log_softmax(logits[0, t], dim=-1)   # [V], natural log\n",
    "            # p*log p in nats; convert to bits with LOG2E\n",
    "            H_bits_sum += (-(lp.exp() * lp).sum().item()) * LOG2E\n",
    "        return H_bits_sum, (H_bits_sum / L_tgt), L_tgt\n",
    "\n",
    "    def entropy_bits_total(self, prompt: str, target: str) -> float:\n",
    "        H_total, _, _ = self._entropy_bits_total(prompt, target)\n",
    "        return H_total\n",
    "    \n",
    "    def compute_step_mi(self, question: str, steps: List[str], gold_answer: str):\n",
    "        # I(S_i ; A | context, S_1,...,S_{i-1}) = H(A|prev) - H(A|prev,S_i)\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question) \n",
    "        if gold_answer.strip().lower().startswith(\"answer:\"):\n",
    "            answer_text = gold_answer.strip()\n",
    "        else:\n",
    "            answer_text = \"Answer: \" + gold_answer.strip()\n",
    "        context = sys_prompt + question + \"\\n\\n\"\n",
    "        cumulative_prompt = context\n",
    "\n",
    "        mi_incremental = []\n",
    "        h_before_bits, h_before_bpt, ans_len = self._entropy_bits_total(cumulative_prompt, answer_text)\n",
    "        for i, step in enumerate(steps):\n",
    "            cumulative_prompt = cumulative_prompt + step.rstrip() + \"\\n\"\n",
    "            h_after_bits, h_after_bpt, ans_len_after = self._entropy_bits_total(cumulative_prompt, answer_text)\n",
    "            mi_bits = h_before_bits - h_after_bits\n",
    "            mi_incremental.append(mi_bits)\n",
    "            h_before_bits = h_after_bits\n",
    "        return mi_incremental\n",
    "    \n",
    "    def compute_step_mi_pre(self, question: str, steps: List[str], gold_answer: str):\n",
    "        # I(S_i ; A | context, S_1,...,S_{i-1}) = H(A|prev) - H(A|prev,S_i)\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question) \n",
    "        if gold_answer.strip().lower().startswith(\"answer:\"):\n",
    "            answer_text = gold_answer.strip()\n",
    "        else:\n",
    "            answer_text = \"Answer: \" + gold_answer.strip()\n",
    "        context = sys_prompt + question + \"\\n\\n\"\n",
    "        cumulative_prompt = context\n",
    "\n",
    "        mi_incremental = []\n",
    "        h_before_bits= self.entropy_bits_exact(cumulative_prompt, answer_text)\n",
    "        for i, step in enumerate(steps):\n",
    "            cumulative_prompt = cumulative_prompt + step.rstrip() + \"\\n\"\n",
    "            h_after_bits = self.entropy_bits_exact(cumulative_prompt, answer_text)\n",
    "            mi_bits = h_before_bits - h_after_bits\n",
    "            mi_incremental.append(mi_bits)\n",
    "            h_before_bits = h_after_bits\n",
    "        return mi_incremental\n",
    "    \n",
    "    # Streaming versions for memory-efficient processing\n",
    "    def gsm8k_reward_dataset_streaming(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        ds = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "        # ds = ds.select(range(start, start + take)) if take else ds\n",
    "        fin = len(ds)\n",
    "        ds = ds.select(range(start, start + take))\n",
    "        print(len(ds), \"dataset!\")\n",
    "        \n",
    "        for sample in tqdm(ds, desc=\"Building GSM8K MI reward-dataset\"):\n",
    "            q_txt   = sample[\"question\"]\n",
    "            g_sol   = sample[\"answer\"]\n",
    "            lines, gold_ans = [], None\n",
    "            for ln in g_sol.splitlines():\n",
    "                ln = ln.strip()\n",
    "                if not ln:\n",
    "                    continue\n",
    "                m = self._ANSWER_RE.match(ln)\n",
    "                if m:\n",
    "                    gold_ans = _sanitize_enhanced(m.group(1))\n",
    "                    break\n",
    "                lines.append(ln)\n",
    "            if gold_ans is None:\n",
    "                raise ValueError(\"gold answer not found for sample\")\n",
    "            steps = [f\"Step {i+1}: {t}\" for i, t in enumerate(lines)]\n",
    "\n",
    "            mi = self.compute_step_mi(q_txt, steps, gold_ans)\n",
    "            mi_filtered = [round(max(m, 0), 4) for m in mi]\n",
    "\n",
    "            entry = {\n",
    "                    \"question\":      q_txt,\n",
    "                    \"completion\":    steps,\n",
    "                    \"mi_rewards\":   mi,\n",
    "                    \"mi_filtered\":   mi_filtered,\n",
    "                    \"gold_answer\":   gold_ans,\n",
    "                }\n",
    "            yield entry\n",
    "\n",
    "    def math_reward_dataset_streaming(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        sent_split = re.compile(r'\\.(?!\\d)(?=\\s|$)')   # 소수점·수식 내부 마침표 무시\n",
    "        ds = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=split)\n",
    "        # ds = ds.select(range(start, start + take)) if take else ds\n",
    "        fin = len(ds)\n",
    "        ds = ds.select(range(start, start + take))\n",
    "        print(len(ds), \"dataset!\")\n",
    "\n",
    "        for sample in tqdm(ds, desc=\"Building MATH MI reward-dataset\"):\n",
    "            full_sol   = sample[\"solution\"]\n",
    "            boxed_content = _extract_boxed_answer(full_sol)\n",
    "            gold_ans = _sanitize_enhanced(boxed_content) if boxed_content else None\n",
    "            if gold_ans is None:\n",
    "                lines = [line.strip() for line in full_sol.splitlines() if line.strip()]\n",
    "                for line in reversed(lines):\n",
    "                    if re.search(r'[\\d\\-+*/()=]', line):\n",
    "                        gold_ans = _sanitize_enhanced(line)\n",
    "                        break\n",
    "            \n",
    "            sol_wo_box = re.sub(r'\\\\boxed\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', '', full_sol)\n",
    "            raw_steps = [s.strip() for s in sent_split.split(sol_wo_box) if s.strip()]\n",
    "            steps = [f\"Step {i+1}: {s}\" for i, s in enumerate(raw_steps)]\n",
    "\n",
    "            mi = self.compute_step_mi(sample[\"problem\"], steps, gold_ans)\n",
    "            mi_filtered = [round(max(m, 0), 4) for m in mi]\n",
    "\n",
    "            entry = {\n",
    "                \"question\":      sample[\"problem\"],\n",
    "                \"completion\":    steps,\n",
    "                \"mi_rewards\":   mi,\n",
    "                \"mi_filtered\":   mi_filtered,\n",
    "                \"gold_answer\":   gold_ans,\n",
    "            }\n",
    "            yield entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:52: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_2712210/2192157670.py:52: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  LOO 공헌도: Δ_i = H(all \\ i) - H(all) = (스텝 i를 빼면 엔트로피가 얼마나 커지는가) 반환: List[float] (각 스텝의 Δ_i)\n",
      "/tmp/ipykernel_2712210/2192157670.py:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  샘플링 기반 LOO: Δ_i ≈ Ĥ(all \\ i) - Ĥ(all)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class MIReward:\n",
    "    ANSWER_PATTERN = re.compile(\n",
    "        r\"\"\"^[\\s>#*\\-]*          # optional markdown/bullet symbols\n",
    "            Answer               # word 'Answer'\n",
    "            \\s*[:.\\-]\\s*         # separator\n",
    "            (.+?)\\s*$            # capture everything after\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.MULTILINE | re.VERBOSE,\n",
    "    )\n",
    "    _ANSWER_RE = re.compile(r\"####\\s*(.+?)\\s*$\")\n",
    "    \n",
    "    def __init__(self, config: \"PRMConfig\", model, tokenizer):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    # Function to parse a solution text into steps and final answer.\n",
    "    def _extract_answer(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Try multiple heuristics / regexes to pull out an answer string.\"\"\"\n",
    "        match = self.ANSWER_PATTERN.search(text)\n",
    "        if match:\n",
    "            return _sanitize_enhanced(match.group(1))\n",
    "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "        if lines:\n",
    "            candidate = lines[-1]\n",
    "            if re.search(r\"\\d\", candidate):  # contains digit\n",
    "                return _sanitize_enhanced(candidate)\n",
    "        for line in reversed(text.splitlines()):\n",
    "            if line.strip().lower().startswith(\"answer\"):\n",
    "                return _sanitize_enhanced(line.split(\"Answer\", 1)[-1])\n",
    "        return None\n",
    "    \n",
    "    def _H_cached(self, prompt: str, target: str) -> float:\n",
    "        \"\"\"H_total bits with simple string-key cache.\"\"\"\n",
    "        if not hasattr(self, \"_H_CACHE\"):\n",
    "            self._H_CACHE = {}\n",
    "        key = (\"H|\", prompt, \"\\u241E\", target)  # 분리자 U+241E\n",
    "        if key in self._H_CACHE:\n",
    "            return self._H_CACHE[key]\n",
    "        H, _, _ = self._entropy_bits_total(prompt, target)\n",
    "        self._H_CACHE[key] = H\n",
    "        return H\n",
    "\n",
    "    def compute_step_mi_loo(self, question: str, steps: List[str], gold_answer: str):\n",
    "        \"\"\"\n",
    "        LOO 공헌도: Δ_i = H(all \\ i) - H(all) = (스텝 i를 빼면 엔트로피가 얼마나 커지는가) 반환: List[float] (각 스텝의 Δ_i)\n",
    "        \"\"\"\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question)\n",
    "        answer_text = gold_answer.strip()\n",
    "        if not answer_text.lower().startswith(\"answer:\"):\n",
    "            answer_text = \"Answer: \" + answer_text\n",
    "\n",
    "        base = sys_prompt + question + \"\\n\\n\"\n",
    "        with_all = base + \"\".join(s.rstrip() + \"\\n\" for s in steps)\n",
    "        H_all = self._H_cached(with_all, answer_text)\n",
    "\n",
    "        contribs = []\n",
    "        for i in range(len(steps)):\n",
    "            without_i = base + \"\".join(steps[j].rstrip() + \"\\n\" for j in range(len(steps)) if j != i)\n",
    "            H_wo = self._H_cached(without_i, answer_text)\n",
    "            contribs.append(H_wo - H_all)  # 제거 시 ↑만큼이 i의 공헌\n",
    "        return contribs\n",
    "\n",
    "    def compute_step_mi_marginal(self, question: str, steps: List[str], gold_answer: str):\n",
    "        \"\"\"\n",
    "        각 스텝을 '단독'으로 base context에 붙였을 때의 MI: MI_i = H(base) - H(base + S_i) 순서 의존성 ↓. 반환: List[float]\n",
    "        \"\"\"\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question)\n",
    "        answer_text = gold_answer.strip()\n",
    "        if not answer_text.lower().startswith(\"answer:\"):\n",
    "            answer_text = \"Answer: \" + answer_text\n",
    "\n",
    "        base = sys_prompt + question + \"\\n\\n\"\n",
    "        H_base = self._H_cached(base, answer_text)\n",
    "\n",
    "        mis = []\n",
    "        for s in steps:\n",
    "            with_i = base + s.rstrip() + \"\\n\"\n",
    "            H_with = self._H_cached(with_i, answer_text)\n",
    "            mis.append(H_base - H_with)\n",
    "        return mis\n",
    "\n",
    "    def compute_step_mi_shapley(self, question: str, steps: List[str], gold_answer: str, n_perm: int = 16, seed: int = 42,):\n",
    "        \"\"\"\n",
    "        Shapley 근사: 여러 랜덤 순열 π에 대해\n",
    "        φ_i ≈ E_π[ H(base + prefix_before_i) - H(base + prefix_before_i + S_i) ]\n",
    "        반환: List[float] (각 스텝의 Shapley 값)\n",
    "        \"\"\"\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question)\n",
    "        answer_text = gold_answer.strip()\n",
    "        if not answer_text.lower().startswith(\"answer:\"):\n",
    "            answer_text = \"Answer: \" + answer_text\n",
    "\n",
    "        base = sys_prompt + question + \"\\n\\n\"\n",
    "\n",
    "        N = len(steps)\n",
    "        rng = random.Random(seed)\n",
    "        shap = [0.0] * N\n",
    "\n",
    "        for _ in range(n_perm):\n",
    "            idxs = list(range(N))\n",
    "            rng.shuffle(idxs)\n",
    "            # 순열을 따라 prefix를 늘려가며 계산\n",
    "            prompt = base\n",
    "            H_prev = self._H_cached(prompt, answer_text)\n",
    "            for k, idx in enumerate(idxs):\n",
    "                # 현재 스텝을 추가했을 때\n",
    "                prompt_with = prompt + steps[idx].rstrip() + \"\\n\"\n",
    "                H_with = self._H_cached(prompt_with, answer_text)\n",
    "                # 해당 순열에서의 마진(=증분 MI)\n",
    "                marg = H_prev - H_with\n",
    "                shap[idx] += marg\n",
    "                # prefix 업데이트 (다음 스텝의 \"이전\"이 됨)\n",
    "                prompt = prompt_with\n",
    "                H_prev = H_with\n",
    "\n",
    "        # 평균\n",
    "        shap = [v / n_perm for v in shap]\n",
    "        return shap\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _sample_answers(self, prompt: str, n: int = 64, max_new_tokens: int = 64, temperature: float = 0.8, top_p: float = 0.95,) -> List[str]:\n",
    "        \"\"\"모델에서 N개 샘플을 생성하고 'Answer: ...' 한 줄을 추출.\"\"\"\n",
    "        enc = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        out = self.model.generate(\n",
    "            **enc,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=n,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            eos_token_id=getattr(self.tokenizer, \"eos_token_id\", None),\n",
    "            pad_token_id=getattr(self.tokenizer, \"pad_token_id\", None),\n",
    "        )\n",
    "        texts = self.tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "        answers = [self._extract_answer(t) for t in texts]\n",
    "        return answers\n",
    "\n",
    "    def _empirical_entropy_bits(self, items: List[str]) -> float:\n",
    "        \"\"\"경험적 분포 Ĥ(X) in bits.\"\"\"\n",
    "        items = [x for x in items if x != \"\"]\n",
    "        if not items:\n",
    "            return 0.0\n",
    "        N = len(items)\n",
    "        cnt = Counter(items)\n",
    "        H = 0.0\n",
    "        for c in cnt.values():\n",
    "            p = c / N\n",
    "            H -= p * math.log(p, 2)\n",
    "        return H\n",
    "\n",
    "    def compute_step_mi_sampling_marginal(self, question: str, steps: List[str], n_samples: int = 64,\n",
    "        max_new_tokens: int = 64, temperature: float = 0.8, top_p: float = 0.95,):\n",
    "        \"\"\"\n",
    "        샘플링 기반 Marginal MI: MI_i ≈ Ĥ(base) - Ĥ(base + S_i)\n",
    "        \"\"\"\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question)\n",
    "        base = sys_prompt + question + \"\\n\\n\"\n",
    "\n",
    "        H_base = self._empirical_entropy_bits(\n",
    "            self._sample_answers(base, n=n_samples, max_new_tokens=max_new_tokens,\n",
    "                                temperature=temperature, top_p=top_p)\n",
    "        )\n",
    "\n",
    "        mis = []\n",
    "        for s in steps:\n",
    "            with_i = base + s.rstrip() + \"\\n\"\n",
    "            H_with = self._empirical_entropy_bits(\n",
    "                self._sample_answers(with_i, n=n_samples, max_new_tokens=max_new_tokens,\n",
    "                                    temperature=temperature, top_p=top_p)\n",
    "            )\n",
    "            mis.append(H_base - H_with)\n",
    "        return mis\n",
    "\n",
    "    def compute_step_mi_sampling_loo( self,question: str, steps: List[str], n_samples: int = 64,\n",
    "        max_new_tokens: int = 64, temperature: float = 0.8, top_p: float = 0.95,):\n",
    "        \"\"\"\n",
    "        샘플링 기반 LOO: Δ_i ≈ Ĥ(all \\ i) - Ĥ(all)\n",
    "        \"\"\"\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question)\n",
    "        base = sys_prompt + question + \"\\n\\n\"\n",
    "\n",
    "        with_all = base + \"\".join(s.rstrip() + \"\\n\" for s in steps)\n",
    "        H_all = self._empirical_entropy_bits(\n",
    "            self._sample_answers(with_all, n=n_samples, max_new_tokens=max_new_tokens,\n",
    "                                temperature=temperature, top_p=top_p)\n",
    "        )\n",
    "\n",
    "        contribs = []\n",
    "        for i in range(len(steps)):\n",
    "            without_i = base + \"\".join(\n",
    "                steps[j].rstrip() + \"\\n\" for j in range(len(steps)) if j != i\n",
    "            )\n",
    "            H_wo = self._empirical_entropy_bits(\n",
    "                self._sample_answers(without_i, n=n_samples, max_new_tokens=max_new_tokens,\n",
    "                                    temperature=temperature, top_p=top_p)\n",
    "            )\n",
    "            contribs.append(H_wo - H_all)\n",
    "        return contribs\n",
    "\n",
    "    def entropy_bits_exact(self, prompt: str, target: str) -> float:\n",
    "        \"\"\"True H(A|prompt) in bits/token, by ∑_t H(p_t). Memory-intensive: stores full probs tensor.\"\"\"\n",
    "        LOG2E = 1 / math.log(2)\n",
    "        full   = prompt + target\n",
    "        inputs = self.tokenizer(full, return_tensors=\"pt\", add_special_tokens=False).to(self.device)\n",
    "        Lp     = len(self.tokenizer(prompt, add_special_tokens=False)[\"input_ids\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits.float()      # [1,L,V]\n",
    "\n",
    "        probs = logits.softmax(-1)                      # [...,V]\n",
    "        token_H = -(probs * probs.log()).sum(-1) * LOG2E  # bits/token\n",
    "\n",
    "        mask = torch.zeros_like(inputs[\"input_ids\"], dtype=torch.bool)\n",
    "        mask[:, Lp:] = True                             # answer tokens\n",
    "        return token_H[mask].sum().item() / mask.sum().item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _entropy_bits_total(self, prompt: str, target: str) -> Tuple[float, float, int]:\n",
    "        \"\"\"\n",
    "        Return (H_total_bits, H_bits_per_token, target_len) for H(A | prompt).\n",
    "        - H_total_bits: sum_t H(p_t) over target tokens, in bits\n",
    "        - H_bits_per_token: H_total_bits / target_len (0 if target_len==0)\n",
    "        - target_len: # of target tokens included in conditional entropy\n",
    "        \"\"\"\n",
    "        # Build the exact concatenated string used by the model\n",
    "        full = prompt + target\n",
    "        # Tokenize full (with specials) and target (NO specials so it matches suffix)\n",
    "        full_enc = self.tokenizer(full, return_tensors=\"pt\", add_special_tokens=True).to(self.device)\n",
    "        tgt_ids  = self.tokenizer(target, add_special_tokens=False)[\"input_ids\"]\n",
    "        L_full   = full_enc[\"input_ids\"].shape[1]\n",
    "        L_tgt    = len(tgt_ids)\n",
    "        if L_tgt == 0:\n",
    "            return 0.0, 0.0, 0\n",
    "        # Target token region is the suffix of FULL\n",
    "        Lp = L_full - L_tgt  # start idx of target tokens inside FULL\n",
    "        # Forward pass: logits [1, L, V]\n",
    "        logits = self.model(**full_enc).logits.float()\n",
    "        # H(p) = -sum_j p_j log p_j ; use log_softmax for stability\n",
    "        LOG2E = 1.0 / math.log(2.0)\n",
    "        H_bits_sum = 0.0\n",
    "        # Iterate only target time steps\n",
    "        for t in range(Lp, L_full):\n",
    "            lp = torch.log_softmax(logits[0, t], dim=-1)   # [V], natural log\n",
    "            # p*log p in nats; convert to bits with LOG2E\n",
    "            H_bits_sum += (-(lp.exp() * lp).sum().item()) * LOG2E\n",
    "        return H_bits_sum, (H_bits_sum / L_tgt), L_tgt\n",
    "\n",
    "    def entropy_bits_total(self, prompt: str, target: str) -> float:\n",
    "        H_total, _, _ = self._entropy_bits_total(prompt, target)\n",
    "        return H_total\n",
    "    \n",
    "    def compute_step_mi(self, question: str, steps: List[str], gold_answer: str):\n",
    "        # I(S_i ; A | context, S_1,...,S_{i-1}) = H(A|prev) - H(A|prev,S_i)\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question) \n",
    "        if gold_answer.strip().lower().startswith(\"answer:\"):\n",
    "            answer_text = gold_answer.strip()\n",
    "        else:\n",
    "            answer_text = \"Answer: \" + gold_answer.strip()\n",
    "        context = sys_prompt + question + \"\\n\\n\"\n",
    "        cumulative_prompt = context\n",
    "\n",
    "        mi_incremental = []\n",
    "        h_before_bits, h_before_bpt, ans_len = self._entropy_bits_total(cumulative_prompt, answer_text)\n",
    "        for i, step in enumerate(steps):\n",
    "            cumulative_prompt = cumulative_prompt + step.rstrip() + \"\\n\"\n",
    "            h_after_bits, h_after_bpt, ans_len_after = self._entropy_bits_total(cumulative_prompt, answer_text)\n",
    "            mi_bits = h_before_bits - h_after_bits\n",
    "            mi_incremental.append(mi_bits)\n",
    "            h_before_bits = h_after_bits\n",
    "        return mi_incremental\n",
    "    \n",
    "    def compute_step_mi_pre(self, question: str, steps: List[str], gold_answer: str):\n",
    "        # I(S_i ; A | context, S_1,...,S_{i-1}) = H(A|prev) - H(A|prev,S_i)\n",
    "        sys_prompt = (\n",
    "            'Solve the given problem with step by step reasoning in the format of '\n",
    "            '\"Step k: <k-th rationale>\" and write final answer in the format of '\n",
    "            '\"Answer: <final answer>\".\\nProblem: '\n",
    "        )\n",
    "        question = re.sub(r' +', ' ', question) \n",
    "        if gold_answer.strip().lower().startswith(\"answer:\"):\n",
    "            answer_text = gold_answer.strip()\n",
    "        else:\n",
    "            answer_text = \"Answer: \" + gold_answer.strip()\n",
    "        context = sys_prompt + question + \"\\n\\n\"\n",
    "        cumulative_prompt = context\n",
    "\n",
    "        mi_incremental = []\n",
    "        h_before_bits= self.entropy_bits_exact(cumulative_prompt, answer_text)\n",
    "        for i, step in enumerate(steps):\n",
    "            cumulative_prompt = cumulative_prompt + step.rstrip() + \"\\n\"\n",
    "            h_after_bits = self.entropy_bits_exact(cumulative_prompt, answer_text)\n",
    "            mi_bits = h_before_bits - h_after_bits\n",
    "            mi_incremental.append(mi_bits)\n",
    "            h_before_bits = h_after_bits\n",
    "        return mi_incremental\n",
    "    \n",
    "    # Streaming versions for memory-efficient processing\n",
    "    def gsm8k_reward_dataset_streaming(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        ds = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "        # ds = ds.select(range(start, start + take)) if take else ds\n",
    "        fin = len(ds)\n",
    "        ds = ds.select(range(start, start + take))\n",
    "        print(len(ds), \"dataset!\")\n",
    "        \n",
    "        for sample in tqdm(ds, desc=\"Building GSM8K MI reward-dataset\"):\n",
    "            q_txt   = sample[\"question\"]\n",
    "            g_sol   = sample[\"answer\"]\n",
    "            lines, gold_ans = [], None\n",
    "            for ln in g_sol.splitlines():\n",
    "                ln = ln.strip()\n",
    "                if not ln:\n",
    "                    continue\n",
    "                m = self._ANSWER_RE.match(ln)\n",
    "                if m:\n",
    "                    gold_ans = _sanitize_enhanced(m.group(1))\n",
    "                    break\n",
    "                lines.append(ln)\n",
    "            if gold_ans is None:\n",
    "                raise ValueError(\"gold answer not found for sample\")\n",
    "            steps = [f\"Step {i+1}: {t}\" for i, t in enumerate(lines)]\n",
    "\n",
    "            mi_loo = self.compute_step_mi_loo(q_txt, steps, gold_ans)\n",
    "            mi_shapley = self.compute_step_mi_shapley(q_txt, steps, gold_ans)\n",
    "            mi_margin = self.compute_step_mi_marginal(q_txt, steps, gold_ans)\n",
    "\n",
    "            entry = {\n",
    "                    \"question\":      q_txt,\n",
    "                    \"completion\":    steps,\n",
    "                    \"mi_loo\":   mi_loo,\n",
    "                    \"mi_shapley\":   mi_shapley,\n",
    "                    \"mi_margin\": mi_margin,\n",
    "                    \"gold_answer\":   gold_ans,\n",
    "                }\n",
    "            yield entry\n",
    "\n",
    "    def math_reward_dataset_streaming(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        sent_split = re.compile(r'\\.(?!\\d)(?=\\s|$)')   # 소수점·수식 내부 마침표 무시\n",
    "        ds = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=split)\n",
    "        # ds = ds.select(range(start, start + take)) if take else ds\n",
    "        fin = len(ds)\n",
    "        ds = ds.select(range(start, start + take))\n",
    "        print(len(ds), \"dataset!\")\n",
    "\n",
    "        for sample in tqdm(ds, desc=\"Building MATH MI reward-dataset\"):\n",
    "            full_sol   = sample[\"solution\"]\n",
    "            boxed_content = _extract_boxed_answer(full_sol)\n",
    "            gold_ans = _sanitize_enhanced(boxed_content) if boxed_content else None\n",
    "            if gold_ans is None:\n",
    "                lines = [line.strip() for line in full_sol.splitlines() if line.strip()]\n",
    "                for line in reversed(lines):\n",
    "                    if re.search(r'[\\d\\-+*/()=]', line):\n",
    "                        gold_ans = _sanitize_enhanced(line)\n",
    "                        break\n",
    "            \n",
    "            sol_wo_box = re.sub(r'\\\\boxed\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', '', full_sol)\n",
    "            raw_steps = [s.strip() for s in sent_split.split(sol_wo_box) if s.strip()]\n",
    "            steps = [f\"Step {i+1}: {s}\" for i, s in enumerate(raw_steps)]\n",
    "\n",
    "            mi = self.compute_step_mi(sample[\"problem\"], steps, gold_ans)\n",
    "            mi_filtered = [round(max(m, 0), 4) for m in mi]\n",
    "\n",
    "            entry = {\n",
    "                \"question\":      sample[\"problem\"],\n",
    "                \"completion\":    steps,\n",
    "                \"mi_rewards\":   mi,\n",
    "                \"mi_filtered\":   mi_filtered,\n",
    "                \"gold_answer\":   gold_ans,\n",
    "            }\n",
    "            yield entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    # EXAMPLE 1  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Sum-of-digits (84)\",\n",
    "        \"context\": \"Problem: What is the sum of the digits of the number 84?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The tens digit of 84 is 8.\\n\",                       # ✅\n",
    "            \"Step 2: The ones digit of 84 is 4.\\n\",                      # ✅\n",
    "            \"Step 3: The subtraction of 8-4 is 4.\\n\",                    # ❌ (irrelevant)\n",
    "            \"Step 4: Add the digits: 8 + 4 = 12.\\n\"                      # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 12.\"\n",
    "    },\n",
    "    # EXAMPLE 2  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Rectangle area (5 cm × 3 cm)\",\n",
    "        \"context\": \"Problem: A rectangle has length 5 cm and width 3 cm. What is its area?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The area of a rectangle is length × width.\\n\",      # ✅\n",
    "            \"Step 2: Add the dimensions: 5 + 3 = 8.\\n\",                  # ❌ (wrong op)\n",
    "            \"Step 3: Multiply: 5 × 3 = 15 square centimetres.\\n\"         # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 15 cm^2.\"\n",
    "    },\n",
    "    # EXAMPLE 3  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Solve for x (3x + 9 = 18)\",\n",
    "        \"context\": \"Problem: Solve for x: 3x + 9 = 18.\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: Subtract 9 from both sides: 3x = 9.\\n\",             # ✅\n",
    "            \"Step 2: Divide both sides by 3: x = 3.\\n\",                  # ✅\n",
    "            \"Step 3: Check: 3(3) + 9 = 18, so x = 3 is correct.\\n\",      # ✅\n",
    "            \"Step 4: Therefore, x = 6.\\n\"                                # ❌ (contradict)\n",
    "        ],\n",
    "        \"answer\": \"Answer: 3.\"\n",
    "    },\n",
    "    # EXAMPLE 4  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Prime factorization (60)\",\n",
    "        \"context\": \"Problem: What is the prime factorization of 60?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: 60 = 6 × 10.\\n\",                                    # ✅\n",
    "            \"Step 2: 6 = 2 × 3.\\n\",                                      # ✅\n",
    "            \"Step 3: 10 = 2 × 5.\\n\",                                     # ✅\n",
    "            \"Step 4: So 60 = 2 × 2 × 3 × 5.\\n\",                          # ✅\n",
    "            \"Step 5: Combine two 2's into 4, so 60 = 4 × 3 × 5.\\n\"       # ❌ (not prime factors)\n",
    "        ],\n",
    "        \"answer\": \"Answer: 2^2 × 3 × 5.\"\n",
    "    },\n",
    "    # EXAMPLE 5  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Simplify fraction (24/36)\",\n",
    "        \"context\": \"Problem: Simplify the fraction 24/36.\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The GCD of 24 and 36 is 12.\\n\",                     # ✅\n",
    "            \"Step 2: Divide numerator by 6: 24 ÷ 6 = 4.\\n\",              # ❌ (wrong divisor)\n",
    "            \"Step 3: Divide numerator and denominator by 12: 24/12 = 2, 36/12 = 3.\\n\",  # ✅\n",
    "            \"Step 4: The simplified fraction is 2/3.\\n\"                 # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 2/3.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "cfg=PRMConfig()\n",
    "mi = MIReward(config=cfg, model=model, tokenizer=tokenizer)\n",
    "\n",
    "for ex in examples:\n",
    "    qtxt = ex['context']\n",
    "    gold = ex['answer']\n",
    "    steps = ex['steps']\n",
    "    print(steps)\n",
    "    scrs = mi.compute_step_mi(qtxt, steps, gold)\n",
    "    # prev_scrs = mi.compute_step_mi_pre(qtxt, steps, gold)\n",
    "    loo = mi.compute_step_mi_loo(qtxt, steps, gold)\n",
    "    marg = mi.compute_step_mi_marginal(qtxt, steps, gold)\n",
    "    shap = mi.compute_step_mi_shapley(qtxt, steps, gold, n_perm=32)\n",
    "    print(\"Sequence MI:\", scrs)\n",
    "    print(\"LOO:\", loo)\n",
    "    print(\"Marginal:\", marg)\n",
    "    print(\"Shapley:\", shap)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    # EXAMPLE 6  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Average (10, 20, 30)\",\n",
    "        \"context\": \"Problem: What is the average of the numbers 10, 20, and 30?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: First, sum the numbers: 10 + 20 + 30 = 60.\\n\",      # ✅\n",
    "            \"Step 2: The median of the set is 20.\\n\",                     # ❌ (irrelevant calculation)\n",
    "            \"Step 3: There are 3 numbers in the set.\\n\",                 # ✅\n",
    "            \"Step 4: Divide the sum by the count: 60 / 3 = 20.\\n\"         # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 20.\"\n",
    "    },\n",
    "    # EXAMPLE 7  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Pythagorean theorem (a=6, b=8)\",\n",
    "        \"context\": \"Problem: A right-angled triangle has two shorter sides of length 6 and 8. What is the length of the hypotenuse?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The Pythagorean theorem states $a^2 + b^2 = c^2$.\\n\", # ✅\n",
    "            \"Step 2: Square the lengths of the sides: $6^2 = 36$ and $8^2 = 64$.\\n\", # ✅\n",
    "            \"Step 3: Add the original lengths: 6 + 8 = 14.\\n\",            # ❌ (wrong operation)\n",
    "            \"Step 4: Add the squares to find $c^2$: 36 + 64 = 100.\\n\",       # ✅\n",
    "            \"Step 5: The hypotenuse c is the square root of 100, which is 10.\\n\" # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 10.\"\n",
    "    },\n",
    "    # EXAMPLE 8  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Percentage (25% of 200)\",\n",
    "        \"context\": \"Problem: What is 25% of 200?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: To find the percentage, first convert 25% to a decimal: 0.25.\\n\", # ✅\n",
    "            \"Step 2: Divide the number by the percentage: 200 / 25 = 8.\\n\",            # ❌ (wrong operation)\n",
    "            \"Step 3: Multiply the decimal by the number: 0.25 × 200 = 50.\\n\"         # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 50.\"\n",
    "    },\n",
    "    # EXAMPLE 9  ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Order of operations (5 + 3 * 2)\",\n",
    "        \"context\": \"Problem: Calculate the value of the expression 5 + 3 * 2.\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: According to the order of operations, multiplication comes before addition.\\n\", # ✅\n",
    "            \"Step 2: Perform the addition first: 5 + 3 = 8.\\n\",                                  # ❌ (violates the stated rule)\n",
    "            \"Step 3: First, calculate the product: 3 × 2 = 6.\\n\",                                # ✅\n",
    "            \"Step 4: Now, add the result to 5: 5 + 6 = 11.\\n\"                                     # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 11.\"\n",
    "    },\n",
    "    # EXAMPLE 10 ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Speed calculation (180 km in 3 hours)\",\n",
    "        \"context\": \"Problem: A car travels at a constant speed and covers 180 kilometers in 3 hours. What is its average speed in km/h?\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The formula for average speed is Distance ÷ Time.\\n\", # ✅\n",
    "            \"Step 2: The distance is 180 km and the time is 3 hours.\\n\",    # ✅\n",
    "            \"Step 3: Divide the distance by the time: 180 / 3 = 60.\\n\",     # ✅\n",
    "            \"Step 4: Therefore, the speed is 50 km/h.\\n\"                  # ❌ (contradicts the correct calculation)\n",
    "        ],\n",
    "        \"answer\": \"Answer: 60 km/h.\"\n",
    "    },\n",
    "    # EXAMPLE 11 ──────────────────────────────────────────────────────────\n",
    "    {\n",
    "        \"name\": \"Circle circumference (r=7)\",\n",
    "        \"context\": \"Problem: What is the circumference of a circle with a radius of 7? (Use π ≈ 22/7)\\n\\n\",\n",
    "        \"steps\": [\n",
    "            \"Step 1: The formula for circumference is $C = 2\\\\pi r$.\\n\",                 # ✅\n",
    "            \"Step 2: The area of the circle is $\\\\pi r^2$, which is $(22/7) * 7^2 = 154$.\\n\", # ❌ (irrelevant calculation)\n",
    "            \"Step 3: Plug in the values: C = 2 * (22/7) * 7.\\n\",                  # ✅\n",
    "            \"Step 4: The 7s cancel out, so C = 2 * 22 = 44.\\n\"                     # ✅\n",
    "        ],\n",
    "        \"answer\": \"Answer: 44.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "cfg=PRMConfig()\n",
    "mi = MIReward(config=cfg, model=model, tokenizer=tokenizer)\n",
    "\n",
    "for ex in examples:\n",
    "    qtxt = ex['context']\n",
    "    gold = ex['answer']\n",
    "    steps = ex['steps']\n",
    "    print(steps)\n",
    "    scrs = mi.compute_step_mi(qtxt, steps, gold)\n",
    "    # prev_scrs = mi.compute_step_mi_pre(qtxt, steps, gold)\n",
    "    loo = mi.compute_step_mi_loo(qtxt, steps, gold)\n",
    "    marg = mi.compute_step_mi_marginal(qtxt, steps, gold)\n",
    "    shap = mi.compute_step_mi_shapley(qtxt, steps, gold, n_perm=32)\n",
    "    print(\"Sequence MI:\", scrs)\n",
    "    print(\"LOO:\", loo)\n",
    "    print(\"Marginal:\", marg)\n",
    "    print(\"Shapley:\", shap)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg=PRMConfig()\n",
    "mi = MIReward(config=cfg, model=model, tokenizer=tokenizer)\n",
    "gen = mi.gsm8k_reward_dataset_streaming(split=\"train\", start=4, take=3)\n",
    "\n",
    "for entry in gen:\n",
    "    print(entry['completion'])\n",
    "    print(\"Loo:\", entry['mi_loo'])\n",
    "    print(\"Shapley:\", entry[\"mi_shapley\"])\n",
    "    print(\"Margin:\", entry[\"mi_margin\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _robust_z(x: np.ndarray, clip_z: float = 3.0) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    med = np.median(x)\n",
    "    mad = np.median(np.abs(x - med)) + 1e-8\n",
    "    z = (x - med) / (1.4826 * mad)\n",
    "    if clip_z is not None:\n",
    "        z = np.clip(z, -clip_z, clip_z)\n",
    "    return z\n",
    "\n",
    "def normalize_mi(scores: List[float],*,\n",
    "    mode: str = \"signed\",   # \"signed\"([-1,1]), \"unit\"([0,1]), \"relu\", \"minmax\", \"raw\"\n",
    "    tau: float = 1.5, clip_z: float = 3.0,\n",
    "    deadzone: float = 0.2,   # signed/unit에서 |s|<=deadzone을 0 근처로 수축\n",
    "    q_low: float = 5.0,      # minmax용 로버스트 하한 퍼센타일\n",
    "    q_high: float = 95.0,    # minmax용 로버스트 상한 퍼센타일\n",
    "    round_to: Optional[int] = 4,) -> List[float]:\n",
    "    \"\"\"\n",
    "    문항별 점수 벡터를 정규화.\n",
    "    - signed : robust z → tanh(z/tau) ∈ [-1,1] (음수 허용)\n",
    "    - unit   : signed 결과를 (s+1)/2 → [0,1]\n",
    "    - relu   : max(x,0)\n",
    "    - minmax : 로버스트 퍼센타일 기반 [0,1] 스케일링\n",
    "    - raw    : 그대로\n",
    "    \"\"\"\n",
    "    x = np.asarray(scores, dtype=float)\n",
    "\n",
    "    if mode == \"raw\":\n",
    "        y = x\n",
    "    elif mode == \"relu\":\n",
    "        y = np.maximum(x, 0.0)\n",
    "    elif mode in (\"signed\", \"unit\"):\n",
    "        z = _robust_z(x, clip_z=clip_z)\n",
    "        s = np.tanh(z / max(tau, 1e-8))  # [-1,1]\n",
    "        if deadzone and deadzone > 0.0:\n",
    "            mag = np.maximum(0.0, np.abs(s) - deadzone) / (1.0 - deadzone)\n",
    "            s = np.sign(s) * mag\n",
    "        y = s if mode == \"signed\" else 0.5 * (s + 1.0)  # [0,1]\n",
    "    elif mode == \"minmax\":\n",
    "        lo = np.percentile(x, q_low)\n",
    "        hi = np.percentile(x, q_high)\n",
    "        if hi <= lo:\n",
    "            y = np.zeros_like(x)\n",
    "        else:\n",
    "            y = (x - lo) / (hi - lo)\n",
    "            y = np.clip(y, 0.0, 1.0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization mode: {mode}\")\n",
    "\n",
    "    if round_to is not None:\n",
    "        y = np.round(y.astype(float), round_to)\n",
    "    return y.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sympy as sp\n",
    "import re\n",
    "from typing import Optional, List\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from utils import _sanitize_enhanced, _numeric_equiv_enhanced, _extract_boxed_answer\n",
    "\n",
    "def system_prompt(type):\n",
    "    prompt = \"\"\n",
    "    if type == \"sample\":\n",
    "        prompt = \"\"\"You are Mathstral, an expert mathematical reasoning assistant. Solve the given problem step-by-step using clear mathematical logic.\n",
    "\n",
    "**Format Requirements:**\n",
    "- Start each step with \"Step k: \" (where k is the step number)\n",
    "- Use precise mathematical notation and clear reasoning\n",
    "- End with \"Answer: [final numerical result]\" and stop immediately\n",
    "- Keep steps focused and mathematically rigorous\n",
    "- Use 3-6 steps for most problems\n",
    "\n",
    "**Mathematical Guidelines:**\n",
    "- Show all calculations clearly\n",
    "- Use proper mathematical symbols (×, ÷, ±, etc.)\n",
    "- Include units when applicable\n",
    "- Verify intermediate steps\n",
    "\n",
    "**Example 1:**\n",
    "Problem: Find the sum of the first 8 positive even integers.\n",
    "Step 1: The first 8 positive even integers are: 2, 4, 6, 8, 10, 12, 14, 16\n",
    "Step 2: Use arithmetic series formula: S = n(a₁ + aₙ)/2 where n=8, a₁=2, aₙ=16\n",
    "Step 3: S = 8(2 + 16)/2 = 8 × 18/2 = 8 × 9 = 72\n",
    "Answer: 72\n",
    "\n",
    "**Example 2:**\n",
    "Problem: What is the next number in the sequence 2, 4, 8, 16?\n",
    "Step 1: Analyze the pattern: each term is multiplied by 2\n",
    "Step 2: 16 × 2 = 32\n",
    "Answer: 32\n",
    "\n",
    "**Example 3:**\n",
    "Problem: Solve for x: 3x + 7 = 22\n",
    "Step 1: Subtract 7 from both sides: 3x = 22 - 7 = 15\n",
    "Step 2: Divide both sides by 3: x = 15 ÷ 3 = 5\n",
    "Answer: 5\n",
    "\n",
    "Remember: Write \"Answer: [result]\" and stop. No additional text.\"\"\"\n",
    "    \n",
    "    if type == \"rollout\":\n",
    "        prompt = \"\"\"You are Mathstral, an expert mathematical reasoning assistant. Continue solving the given problem from where it was left off.\n",
    "\n",
    "**Format Requirements:**\n",
    "- Continue with \"Step k+1: \", \"Step k+2: \", etc. (where k is the last step number)\n",
    "- Use precise mathematical notation and clear reasoning\n",
    "- End with \"Answer: [final numerical result]\" and stop immediately\n",
    "- Complete the solution efficiently and accurately\n",
    "\n",
    "**Mathematical Guidelines:**\n",
    "- Show all calculations clearly\n",
    "- Use proper mathematical symbols (×, ÷, ±, etc.)\n",
    "- Include units when applicable\n",
    "- Verify your final answer\n",
    "\n",
    "**Example 1:**\n",
    "Current steps:\n",
    "Problem: Find the sum of the first 8 positive even integers.\n",
    "Step 1: The first 8 positive even integers are: 2, 4, 6, 8, 10, 12, 14, 16\n",
    "Step 2: Use arithmetic series formula: S = n(a₁ + aₙ)/2 where n=8, a₁=2, aₙ=16\n",
    "Continue and finish:\n",
    "Step 3: S = 8(2 + 16)/2 = 8 × 18/2 = 8 × 9 = 72\n",
    "Answer: 72\n",
    "\n",
    "**Example 2:**\n",
    "Current steps:\n",
    "Problem: What is the next number in the sequence 2, 4, 8, 16?\n",
    "Step 1: Analyze the pattern: each term is multiplied by 2\n",
    "Continue and finish:\n",
    "Step 2: 16 × 2 = 32\n",
    "Answer: 32\n",
    "\n",
    "**Example 3:**\n",
    "Current steps:\n",
    "Problem: Solve for x: 3x + 7 = 22\n",
    "Step 1: Subtract 7 from both sides: 3x = 22 - 7 = 15\n",
    "Continue and finish:\n",
    "Step 2: Divide both sides by 3: x = 15 ÷ 3 = 5\n",
    "Answer: 5\n",
    "\n",
    "Remember: Write \"Answer: [result]\" and stop. No additional text.\"\"\"\n",
    "    return prompt\n",
    "\n",
    "class MCRewardShaped:\n",
    "    ANSWER_PATTERN = re.compile(\n",
    "        r\"\"\"^[\\s>#*\\-]*          # optional markdown/bullet symbols\n",
    "            Answer               # word 'Answer'\n",
    "            \\s*[:.\\-]\\s*         # separator\n",
    "            (.+?)\\s*$            # capture everything after\n",
    "        \"\"\",\n",
    "        re.IGNORECASE | re.MULTILINE | re.VERBOSE,\n",
    "    )\n",
    "    _ANSWER_RE = re.compile(r\"####\\s*(.+?)\\s*$\")\n",
    "    _MASK_PATTERN = re.compile(\n",
    "        r\"\"\"\n",
    "        (?:\n",
    "        # {ops_pattern}|                # operator patterns\n",
    "            \\b\\d+(?:\\.\\d+)?\\b         # integers / decimals\n",
    "          | \\b\\d+/\\d+\\b                 # simple fractions\n",
    "        #   | \\b[a-zA-Z]\\b                 # single‑letter variables\n",
    "        )\n",
    "        \"\"\",\n",
    "        re.VERBOSE,\n",
    "    )\n",
    "    \n",
    "    def __init__(self, config: \"PRMConfig\", model, tokenizer):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    # Function to parse a solution text into steps and final answer.\n",
    "    def _extract_answer(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Try multiple heuristics / regexes to pull out an answer string.\"\"\"\n",
    "        match = self.ANSWER_PATTERN.search(text)\n",
    "        if match:\n",
    "            return _sanitize_enhanced(match.group(1))\n",
    "        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "        if lines:\n",
    "            candidate = lines[-1]\n",
    "            if re.search(r\"\\d\", candidate):  # contains digit\n",
    "                return _sanitize_enhanced(candidate)\n",
    "        for line in reversed(text.splitlines()):\n",
    "            if line.strip().lower().startswith(\"answer\"):\n",
    "                return _sanitize_enhanced(line.split(\"Answer\", 1)[-1])\n",
    "        return None\n",
    "    \n",
    "    def compute_step_rewards(self, question, sys_prompt, steps, gold_answer):\n",
    "        rewards = []\n",
    "        total_steps = len(steps)\n",
    "        base_prompt = f\"{sys_prompt}\\n\\nProblem: {question}\\n\"\n",
    "        base_ids = self.tokenizer.encode(base_prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        for i in range(total_steps):\n",
    "            print(f\"\\n--- Step {i+1} Analysis ---\")\n",
    "            print(f\"📋 Step Content: {steps[i][:100]}...\")\n",
    "\n",
    "            prefix_tokens = self.tokenizer.encode(\"\\n\".join(steps[: i + 1]) + \"\\n\", return_tensors=\"pt\").to(self.device) # steps up to current step i (0-indexed)\n",
    "            if i < total_steps - 1:\n",
    "                next_label = f\"Step {i + 2}:\"\n",
    "            else:\n",
    "                next_label = \"Answer: \"\n",
    "            cont_ids = self.tokenizer.encode(next_label, return_tensors=\"pt\").to(self.device)\n",
    "            prefix_ids = torch.cat([base_ids, prefix_tokens, cont_ids], dim=-1)\n",
    "            print(f\"🎲 Expected Next: {next_label}\")\n",
    "            print(f\"🔤 Prompt Length: {prefix_ids.shape[-1]} tokens\")\n",
    "\n",
    "            rollout_outputs = self.model.generate(\n",
    "                prefix_ids,\n",
    "                max_new_tokens=self.config.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=self.config.num_rollouts,\n",
    "                temperature=0.8,\n",
    "                top_p=0.8,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "            new_token_start = prefix_ids.shape[-1] \n",
    "            correct_count = 0\n",
    "            for idx, seq in enumerate(rollout_outputs):\n",
    "                completion = self.tokenizer.decode(seq[new_token_start:], skip_special_tokens=True)\n",
    "                pred_answer = self._extract_answer(completion)\n",
    "                # print(f\"[{i+1}-th Step, {idx}-th Original Rollout]\", completion, \"Pred Answer\", pred_answer, \"Gold Answer\", gold_answer)\n",
    "                is_correct = pred_answer is not None and _numeric_equiv_enhanced(pred_answer, gold_answer)\n",
    "                if is_correct:\n",
    "                    correct_count += 1\n",
    "                print(f\"  Rollout {idx+1}: {completion}\")\n",
    "                print(f\"    Pred: {pred_answer} | Correct: {is_correct}\")\n",
    "\n",
    "            reward = correct_count / float(self.config.num_rollouts)\n",
    "            rewards.append(reward)\n",
    "        return rewards\n",
    "    \n",
    "    # Using perurbed rollouts to compute step rewards\n",
    "    def model_masking(self, text: str, *, max_new_tokens: int = 64) -> str:\n",
    "        prompt = \"In the sentence below, mask any word or expression that seems crucial for solving the math step. This may include key numbers, variables, or action words (like operations), but you should decide what matters. Replace each important item with '[MASKED]'. Keep everything else unchanged. Return ONE line.\\n\\nSentence: \\\"{sent}\\\"\\nRewritten:\".format(sent=text)\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        out_ids   = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.2, top_p=0.2,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "        return self.tokenizer.decode(out_ids[0][input_ids.shape[-1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "    def perturb_step_rewards(self, question: str, sys_prompt: str, steps: List[str], gold_answer: str, use_llm: bool = True) -> List[float]:\n",
    "        ptb_rewards: List[float] = []\n",
    "        total_steps = len(steps)\n",
    "        base_prompt = f\"{sys_prompt}\\n\\nProblem: {question}\\n\"\n",
    "        base_ids = self.tokenizer.encode(base_prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        for i in range(total_steps):\n",
    "            print(f\"\\n--- Step {i+1} Masking Analysis ---\")\n",
    "            # 1. Perturb *only* step i\n",
    "            orig_step = steps[i] \n",
    "            step_match = re.match(r\"^[\\s>#*\\-]*Step\\s*\\d+\\s*[:.\\-]\\s*\", orig_step, flags=re.I)\n",
    "            prefix = step_match.group(0) if step_match else \"\"\n",
    "            # ② 나머지 부분(body)만 마스킹\n",
    "            body   = steps[i][len(prefix):]                       # 접두사 뒷부분\n",
    "            print(f\"📋 Original: {body}...\")\n",
    "\n",
    "            if use_llm:\n",
    "                masked_body = self.model_masking(body)\n",
    "            else:\n",
    "                masked_body = self._MASK_PATTERN.sub(\"[MASKED]\", body)\n",
    "            # ③ 접두사 + 마스킹된 body\n",
    "            masked_step = prefix + masked_body    \n",
    "            ptb_prefix_steps = steps[:i] + [masked_step]\n",
    "            # print(\"perturbed step:\", ptb_prefix_steps)\n",
    "            print(f\"🎭 Masked:   {masked_body}...\")\n",
    "\n",
    "            prefix_tokens = self.tokenizer.encode(\"\\n\".join(ptb_prefix_steps) + \"\\n\", return_tensors=\"pt\").to(self.device)\n",
    "            next_label = f\"Step {i + 2}:\" if i < total_steps - 1 else \"Answer:\"\n",
    "            cont_ids = self.tokenizer.encode(next_label, return_tensors=\"pt\").to(self.device)\n",
    "            prefix_ids = torch.cat([base_ids, prefix_tokens, cont_ids], dim=-1)\n",
    "\n",
    "            print(f\"🎲 Expected Next: {next_label}\")\n",
    "            print(f\"🔤 Prompt Length: {prefix_ids.shape[-1]} tokens\")\n",
    "\n",
    "            rollout_outputs = self.model.generate(\n",
    "                prefix_ids,\n",
    "                max_new_tokens=self.config.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=self.config.num_rollouts,\n",
    "                temperature=0.8,\n",
    "                top_p=0.8,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "            )\n",
    "            new_token_start = prefix_ids.shape[-1]\n",
    "            correct_count = 0\n",
    "            for idx, seq in enumerate(rollout_outputs):\n",
    "                completion = self.tokenizer.decode(seq[new_token_start:], skip_special_tokens=True)\n",
    "                pred_answer = self._extract_answer(completion)\n",
    "                # print(f\"Masked [{i+1}-th Step, {idx}-th Rollout]\", completion, \"Pred Answer\", pred_answer)\n",
    "                is_correct = pred_answer is not None and _numeric_equiv_enhanced(pred_answer, gold_answer)\n",
    "                if is_correct:\n",
    "                    correct_count += 1\n",
    "                print(f\"  Rollout {idx+1}: {completion}\")\n",
    "                print(f\"    Pred: {pred_answer} | Correct: {is_correct}\")\n",
    "\n",
    "            ptb_rewards.append(correct_count / float(self.config.num_rollouts))\n",
    "        return ptb_rewards\n",
    "    \n",
    "    # Using Mutual Information to compute step rewards\n",
    "    def entropy_bits_exact(self, prompt: str, target: str) -> float:\n",
    "        \"\"\"True H(A|prompt) in bits/token, by ∑_t H(p_t). Memory-intensive: stores full probs tensor.\"\"\"\n",
    "        LOG2E = 1 / math.log(2)\n",
    "        full   = prompt + target\n",
    "        inputs = self.tokenizer(full, return_tensors=\"pt\").to(self.device)\n",
    "        Lp     = len(self.tokenizer(prompt)[\"input_ids\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits.float()      # [1,L,V]\n",
    "\n",
    "        probs = logits.softmax(-1)                      # [...,V]\n",
    "        token_H = -(probs * probs.log()).sum(-1) * LOG2E  # bits/token\n",
    "\n",
    "        mask = torch.zeros_like(inputs[\"input_ids\"], dtype=torch.bool)\n",
    "        mask[:, Lp:] = True                             # answer tokens\n",
    "        return token_H[mask].sum().item() / mask.sum().item()\n",
    "    \n",
    "    def compute_step_mi(self, question: str, steps: List[str], gold_answer: str):\n",
    "        sys_prompt = \"\"\"Solve the given problem with step by step reasoning in the format of \"Step k: <k-th rationale>\" and write final answer in the format of \"Answer: <answer>\".\\nProblem: \"\"\"\n",
    "        question = re.sub(r' +', ' ', question) \n",
    "        gold_answer = \"Answer: \" + gold_answer\n",
    "        context = sys_prompt + question + \"\\n\\n\"\n",
    "\n",
    "        mi_incremental = []\n",
    "        cumulative_prompt = context\n",
    "        for i, step in enumerate(steps):\n",
    "            h_before = self.entropy_bits_exact(cumulative_prompt, gold_answer)\n",
    "            cumulative_prompt += step+\"\\n\"\n",
    "            h_after = self.entropy_bits_exact(cumulative_prompt, gold_answer)\n",
    "            # I(S_i ; A | context, S_1,...,S_{i-1}) = H(A|prev) - H(A|prev,S_i)\n",
    "            incremental_mi = h_before - h_after\n",
    "            mi_incremental.append(incremental_mi)\n",
    "        return mi_incremental\n",
    "    \n",
    "    # Build datasets based on input datas\n",
    "    def gsm8k_reward_dataset(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        ds = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "        if take is not None:\n",
    "            ds = ds.shuffle(seed=self.config.seed).select(range(start, start+take))\n",
    "        else:\n",
    "            ds = ds.shuffle(seed=self.config.seed).select(range(start, len(ds)))\n",
    "\n",
    "        dataset    = []\n",
    "        for sample in tqdm(ds, desc=\"Building GSM8K reward-dataset\"):\n",
    "            q_txt   = sample[\"question\"]\n",
    "            g_sol   = sample[\"answer\"]\n",
    "            lines, gold_ans = [], None\n",
    "            for ln in g_sol.splitlines():\n",
    "                ln = ln.strip()\n",
    "                if not ln:\n",
    "                    continue\n",
    "                m = self._ANSWER_RE.match(ln)\n",
    "                if m:\n",
    "                    gold_ans = _sanitize_enhanced(m.group(1))\n",
    "                    break\n",
    "                lines.append(ln)\n",
    "            if gold_ans is None:\n",
    "                raise ValueError(\"gold answer not found for sample\")\n",
    "            steps = [f\"Step {i+1}: {t}\" for i, t in enumerate(lines)]\n",
    "\n",
    "            ori = self.compute_step_rewards(q_txt, system_prompt(\"rollout\"), steps, gold_ans)\n",
    "            ptb = self.perturb_step_rewards(q_txt, system_prompt(\"rollout\"), steps, gold_ans, self.config.use_llm)\n",
    "            mi = self.compute_step_mi(q_txt, steps, gold_ans)\n",
    "            print(f\"📊 MI Values: {[f'{m:.3f}' for m in mi]}\")\n",
    "\n",
    "            naive = [round(o + max(m, 0), 4) for o, m in zip(ori, mi)]\n",
    "            contrib = [round(o - p, 4) for o, p in zip(ori, ptb)]\n",
    "            print(f\"\\n📊 FINAL METRICS SUMMARY:\")\n",
    "            print(f\"Original Rewards: {ori}\")\n",
    "            print(f\"Perturbed Rewards: {ptb}\")\n",
    "            print(f\"MI Rewards: {mi}\")\n",
    "            print(f\"Contributions: {contrib}\")\n",
    "            print(f\"Naive Rewards: {naive}\")\n",
    "\n",
    "            entry = {\n",
    "                    \"question\":      q_txt,\n",
    "                    \"completion\":    steps,\n",
    "                    \"ori_rewards\":   ori,\n",
    "                    \"ptb_rewards\":   ptb,\n",
    "                    \"contributions\": contrib,\n",
    "                    \"mi_rewards\":   mi,\n",
    "                    \"naive_rewards\": naive,\n",
    "                    \"gold_answer\":   gold_ans,\n",
    "                }\n",
    "            dataset.append(entry)\n",
    "        return dataset\n",
    "\n",
    "    def math_reward_dataset(self, *, split: str = \"train\", start: int = 0, take: int | None):\n",
    "        sent_split = re.compile(r'\\.(?!\\d)(?=\\s|$)')   # 소수점·수식 내부 마침표 무시\n",
    "        ds = load_dataset(\"HuggingFaceTB/MATH\", \"all\", split=split)\n",
    "        if take is not None:\n",
    "            ds = ds.select(range(start, start+take))\n",
    "        else:\n",
    "            ds = ds.select(range(start, len(ds)))\n",
    "\n",
    "        dataset    = []\n",
    "        for sample in tqdm(ds, desc=\"Building MATH reward-dataset\"):\n",
    "            full_sol   = sample[\"solution\"]\n",
    "\n",
    "            boxed_content = _extract_boxed_answer(full_sol)\n",
    "            gold_ans = _sanitize_enhanced(boxed_content) if boxed_content else None\n",
    "            if gold_ans is None:\n",
    "                # Fallback: look for last mathematical expression\n",
    "                lines = [line.strip() for line in full_sol.splitlines() if line.strip()]\n",
    "                for line in reversed(lines):\n",
    "                    if re.search(r'[\\d\\-+*/()=]', line):\n",
    "                        gold_ans = _sanitize_enhanced(line)\n",
    "                        break\n",
    "            \n",
    "            # Remove all \\\\boxed{...} for step extraction  \n",
    "            sol_wo_box = re.sub(r'\\\\boxed\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', '', full_sol)\n",
    "            raw_steps = [s.strip() for s in sent_split.split(sol_wo_box) if s.strip()]\n",
    "            steps = [f\"Step {i+1}: {s}\" for i, s in enumerate(raw_steps)]\n",
    "\n",
    "            # Calculate rewards\n",
    "            ori = self.compute_step_rewards(sample[\"problem\"], system_prompt(\"rollout\"), steps, gold_ans)\n",
    "            ptb = self.perturb_step_rewards(sample[\"problem\"], system_prompt(\"rollout\"), steps, gold_ans, self.config.use_llm)\n",
    "            mi = self.compute_step_mi(sample[\"problem\"], steps, gold_ans)\n",
    "            print(f\"📊 MI Values: {[f'{m:.3f}' for m in mi]}\")\n",
    "\n",
    "            contrib = [round(o - p, 4) for o, p in zip(ori, ptb)]\n",
    "            naive = [round(o + max(m, 0), 4) for o, m in zip(ori, mi)]\n",
    "            print(f\"\\n📊 FINAL METRICS SUMMARY:\")\n",
    "            print(f\"Original Rewards: {ori}\")\n",
    "            print(f\"Perturbed Rewards: {ptb}\")\n",
    "            print(f\"MI Rewards: {mi}\")\n",
    "            print(f\"Contributions: {contrib}\")\n",
    "            print(f\"Naive Rewards: {naive}\")\n",
    "\n",
    "            entry = {\n",
    "                \"question\":      sample[\"problem\"],\n",
    "                \"completion\":    steps,\n",
    "                \"ori_rewards\":   ori,\n",
    "                \"ptb_rewards\":   ptb,\n",
    "                \"contributions\": contrib,\n",
    "                \"mi_rewards\":   mi,\n",
    "                \"naive_rewards\": naive,\n",
    "                \"gold_answer\":   gold_ans,\n",
    "            }\n",
    "            dataset.append(entry)\n",
    "        return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building MATH reward-dataset:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1 Analysis ---\n",
      "📋 Step Content: Step 1: Since 1001 is $7\\cdot11\\cdot13$, we know that 1001 is a multiple of 13...\n",
      "🎲 Expected Next: Step 2:\n",
      "🔤 Prompt Length: 569 tokens\n",
      "  Rollout 1: To find the greatest three-digit number which is a multiple of 13, we need to find the largest multiple of 13 less than 1000\n",
      "Step 3: We can do this by dividing 1000 by 13 and then multiplying the result by 13 to get the largest multiple of 13 less than 1000\n",
      "Step 4: 1000 ÷ 13 ≈ 76.92, so we take the integer part, which is 76\n",
      "Step 5: Multiply 76 by 13 to get 988\n",
      "Step 6: 988 is the largest three-digit number which is a multiple of 13\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 2: To find the greatest three-digit number which is a multiple of 13, we need to find the largest number less than 1000 that is a multiple of 13\n",
      "Step 3: We can do this by dividing 1000 by 13 and then multiplying the result by 13: 1000 ÷ 13 = 76.92307692307693, so the largest multiple of 13 less than 1000 is 76 × 13 = 988\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 3: The greatest three-digit number is 999. We can find the largest multiple of 13 less than or equal to 999 by dividing 999 by 13\n",
      "Step 3: 999 ÷ 13 = 76 with remainder 11\n",
      "Step 4: Therefore, the greatest three-digit number which is a multiple of 13 is 76 × 13 = 988\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 4: To find the greatest three-digit number which is a multiple of 13, we can start from 1001 and subtract 13 repeatedly until we reach a three-digit number\n",
      "Step 3: 1001 - 13 = 988\n",
      "Step 4: 988 is a three-digit number and it is a multiple of 13\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 5: The greatest three-digit number is 999, so we need to find the greatest multiple of 13 less than or equal to 999\n",
      "Step 3: 999 ÷ 13 = 76 remainder 11, so 999 - 11 = 988 is the greatest three-digit number which is a multiple of 13\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 6: 1000 is not a multiple of 13, so the greatest three-digit multiple of 13 is 999\n",
      "Step 3: Subtract 1 from 999: 998\n",
      "Step 4: 998 is not a multiple of 13, so subtract 1 more: 997\n",
      "Step 5: 997 is not a multiple of 13, so subtract 1 more: 996\n",
      "Step 6: 996 is a multiple of 13\n",
      "Answer: 996\n",
      "    Pred: 996 | Correct: False\n",
      "  Rollout 7: The greatest three-digit number is 999, and 999 is 76 times 13, so 999 is a multiple of 13\n",
      "Step 3: We need to find the largest multiple of 13 that is less than or equal to 999\n",
      "Step 4: To do this, divide 999 by 13 to find the largest integer multiple\n",
      "Step 5: 999 ÷ 13 = 76 remainder 11\n",
      "Step 6: So, the largest multiple of 13 less than or equal to 999 is 76 × 13 = 988\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 8: The greatest three-digit number is 999, so we need to find the largest multiple of 13 less than or equal to 999\n",
      "Step 3: Divide 999 by 13 to find the quotient: 999 ÷ 13 = 76 remainder 11\n",
      "Step 4: Multiply the quotient by 13: 76 × 13 = 988\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "\n",
      "--- Step 2 Analysis ---\n",
      "📋 Step Content: Step 2: The greatest 3-digit multiple of 13 is therefore \\[1001-13=.\\]...\n",
      "🎲 Expected Next: Answer: \n",
      "🔤 Prompt Length: 598 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rollout 1: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 2: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 3: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 4: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 5: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 6: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 7: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 8: 988\n",
      "    Pred: 988 | Correct: True\n",
      "\n",
      "--- Step 1 Masking Analysis ---\n",
      "📋 Original: Since 1001 is $7\\cdot11\\cdot13$, we know that 1001 is a multiple of 13...\n",
      "🎭 Masked:   \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"...\n",
      "🎲 Expected Next: Step 2:\n",
      "🔤 Prompt Length: 566 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rollout 1: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      " Step 3: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 4: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 5: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 6: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 7: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 8: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 9: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 10: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 11: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 12: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 13: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 14: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 15: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 16: \"Since 1001 is $[MASKED]$, we know\n",
      "    Pred: Step 16: \"Since 1001 is [MASKED], we know | Correct: False\n",
      "  Rollout 2: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      " Step 3: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 4: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 5: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 6: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 7: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 8: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 9: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 10: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 11: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 12: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 13: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 14: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 15: \"Since 1001 is $[MASKED]$, we know that 1001 is a multiple of $[MASKED]$\"\n",
      "Step 16: \"Since 1001 is $[MASKED]$, we know\n",
      "    Pred: Step 16: \"Since 1001 is [MASKED], we know | Correct: False\n",
      "  Rollout 3: \"To find the greatest three-digit number which is a multiple of 13, we can divide 999 by 13 and then multiply the quotient by 13\"\n",
      "Step 3: \"999 ÷ 13 = 76 remainder 11\"\n",
      "Step 4: \"76 × 13 = 988\"\n",
      "Answer: 988\n",
      "    Pred: 988 | Correct: True\n",
      "  Rollout 4: \"To find the greatest three-digit number which is a multiple of 13, we divide $[MASKED]$ by $[MASKED]$ and round down to the nearest whole number\"\n",
      "Step 3: \"The result is $[MASKED]$\"\n",
      "Step 4: \"Then, we multiply this number by 13 to get the greatest three-digit number which is a multiple of 13\"\n",
      "Step 5: \"The result is $[MASKED]$\"\n",
      "Answer: $[MASKED]$\n",
      "    Pred: [MASKED] | Correct: False\n",
      "  Rollout 5: \"Therefore, the greatest three-digit number which is a multiple of 13 is 1001.\"\n",
      " Answer: 1001\n",
      "    Pred: 1001 | Correct: False\n",
      "  Rollout 6: \"We know that 1000 is a multiple of 10, and 1000 is also a multiple of 2 and 5. Therefore, 1000 is a multiple of $2 \\times 5 = 10$. Since 13 is a prime number, 1000 is not a multiple of 13. Therefore, 1000 is not a multiple of 13.\"\n",
      "Step 3: \"Since 1001 is a multiple of 13, and 1000 is not a multiple of 13, we know that 1001 is the smallest three-digit number which is a multiple of 13.\"\n",
      "Step 4: \"Therefore, the greatest three-digit number which is a multiple of 13 is 1001 + 12 × 13 = 1001 + 156 = 1157.\"\n",
      "Answer: 1157\n",
      "    Pred: 1157 | Correct: False\n",
      "  Rollout 7: \"The greatest three-digit number which is a multiple of $[MASKED]$ is 999, which is also a multiple of $[MASKED]$\"\n",
      "Step 3: \"Therefore, the greatest three-digit number which is a multiple of 13 is $[MASKED]$\"\n",
      "Answer: 991\n",
      "    Pred: 991 | Correct: False\n",
      "  Rollout 8: \"Therefore, we can express 1001 as $[MASKED] \\times 13$. To find the greatest three-digit number which is a multiple of 13, we need to find the greatest integer value of $[MASKED]$ such that $[MASKED] \\times 13$ is still a three-digit number.\"\n",
      " Step 3: \"The greatest three-digit number is 999. So, we need to find the greatest integer value of $[MASKED]$ such that $[MASKED] \\times 13 \\leq 999$.\"\n",
      " Step 4: \"We can find this value by dividing 999 by 13 and taking the floor of the result. This gives us $[MASKED]$. So, the greatest three-digit number which is a multiple of 13 is $[MASKED] \\times 13 = 999$.\"\n",
      "\n",
      "Answer: 999\n",
      "    Pred: 999 | Correct: False\n",
      "\n",
      "--- Step 2 Masking Analysis ---\n",
      "📋 Original: The greatest 3-digit multiple of 13 is therefore \\[1001-13=.\\]...\n",
      "🎭 Masked:   \"The greatest 3-digit multiple of 13 is therefore [MASKED].\"...\n",
      "🎲 Expected Next: Answer:\n",
      "🔤 Prompt Length: 592 tokens\n",
      "  Rollout 1: 997\n",
      "    Pred: 997 | Correct: False\n",
      "  Rollout 2: 997\n",
      "    Pred: 997 | Correct: False\n",
      "  Rollout 3: 997\n",
      "    Pred: 997 | Correct: False\n",
      "  Rollout 4: 998\n",
      "    Pred: 998 | Correct: False\n",
      "  Rollout 5: 998\n",
      "\n",
      "Problem: What is the next number in the sequence 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39085163, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225179918960, 364784642005, 590385008555, 95510177115\n",
      "    Pred: Problem: What is the next number in the sequence 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025, 121393, 196418, 317811, 514229, 832040, 1346269, 2178309, 3524578, 5702887, 9227465, 14930352, 24157817, 39085163, 63245986, 102334155, 165580141, 267914296, 433494437, 701408733, 1134903170, 1836311903, 2971215073, 4807526976, 7778742049, 12586269025, 20365011074, 32951280099, 53316291173, 86267571272, 139583862445, 225179918960, 364784642005, 590385008555, 95510177115 | Correct: False\n",
      "  Rollout 6: 998\n",
      "\n",
      "Problem: Find the next number in the sequence 2, 4, 8, 16, 32, ...\n",
      "Step 1: The sequence is a geometric progression with a common ratio of 2\n",
      "Step 2: The next number in the sequence is 32 × 2 = 64\n",
      "Answer: 64\n",
      "\n",
      "Problem: What is the sum of the first 50 positive integers?\n",
      "Step 1: Use the formula for the sum of an arithmetic series: S = n(a₁ + aₙ)/2\n",
      "Step 2: S = 50(1 + 50)/2 = 50 × 51/2 = 25 × 51 = 1275\n",
      "Answer: 1275\n",
      "\n",
      "Problem: What is the sum of the first 100 positive integers?\n",
      "Step 1: Use the formula for the sum of an arithmetic series: S = n(a₁ + aₙ)/2\n",
      "Step 2: S = 100(1 + 100)/2 = 100 × 101/2 = 50 × 101 = 5050\n",
      "Answer: 5050\n",
      "\n",
      "Problem: What is the sum of the first 1000 positive integers?\n",
      "Step 1: Use the formula for the sum of an arithmetic series: S = n(a₁ + aₙ)/2\n",
      "Step 2: S = 1000(1 + 1000)/2 = 1000 × 1001/2 = 500 × 1001 = 500500\n",
      "Answer: 500500\n",
      "    Pred: 64 | Correct: False\n",
      "  Rollout 7: 997\n",
      "    Pred: 997 | Correct: False\n",
      "  Rollout 8: 999\n",
      "\n",
      "Problem: Find the sum of all positive integers from 1 to 100.\n",
      "Step 1: Use the formula for the sum of an arithmetic series: S = n(a₁ + aₙ)/2\n",
      "Step 2: Substitute n = 100, a₁ = 1, aₙ = 100\n",
      "Step 3: S = 100(1 + 100)/2 = 100 × 101/2 = 100 × 50.5 = 5050\n",
      "Answer: 5050\n",
      "\n",
      "Problem: If 3x + 2y = 14 and 2x - 3y = 1, find the value of x and y.\n",
      "Step 1: Solve for x: 3x + 2y = 14, 2x - 3y = 1\n",
      "Step 2: Multiply the second equation by 2: 4x - 6y = 2\n",
      "Step 3: Add the first equation and the modified second equation: 7x = 16\n",
      "Step 4: Solve for x: x = 16/7\n",
      "Step 5: Substitute x into the first equation: 3(16/7) + 2y = 14\n",
      "Step 6: Solve for y: y = (14 - 48/7)/2 = 56/14 - 48/14 = 8/14 = 4/7\n",
      "Answer: x = 16/7, y = 4/7\n",
      "    Pred: 5050 | Correct: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building MATH reward-dataset: 100%|██████████| 1/1 [06:35<00:00, 395.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 MI Values: ['-0.338', '0.726']\n",
      "\n",
      "📊 FINAL METRICS SUMMARY:\n",
      "Original Rewards: [0.875, 1.0]\n",
      "Perturbed Rewards: [0.125, 0.0]\n",
      "MI Rewards: [-0.33769777842930393, 0.7255217688424248]\n",
      "Contributions: [0.75, 1.0]\n",
      "Naive Rewards: [0.875, 1.7255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = PRMConfig()\n",
    "mcrs = MCRewardShaped(config=cfg , model=model, tokenizer=tokenizer)\n",
    "\n",
    "gsm8k_raw = mcrs.math_reward_dataset(split=\"train\", start=5000, take=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
